{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    NB = '207'\n",
    "    dataset_NB = '103'\n",
    "\n",
    "    raw_data_dir = '../data/raw/'\n",
    "    processed_data_dir = '../data/processed/'\n",
    "    interim_dir = '../data/interim/'\n",
    "    submission_dir = '../data/submission/'\n",
    "\n",
    "    random_seed = 42\n",
    "    n_folds = 5\n",
    "\n",
    "    row_id = 'index'\n",
    "    target = 'genre'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "plotly_template = dict(\n",
    "    layout=go.Layout(\n",
    "        template='plotly_dark',\n",
    "        font=dict(\n",
    "            family=\"Franklin Gothic\",\n",
    "            size=12\n",
    "        ),\n",
    "        height=500,\n",
    "        width=1000,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "color_palette = {\n",
    "    'Bin': ['#016CC9','#E876A3'],\n",
    "    'Cat5': ['#E876A3', '#E0A224', '#63B70D', '#6BCFF6', '#13399E'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from imblearn import FunctionSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, confusion_matrix\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4046, 285)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_pickle(Config.processed_data_dir + f'nb{Config.dataset_NB}_train.pkl', compression='zip')\n",
    "df_test = pd.read_pickle(Config.processed_data_dir + f'nb{Config.dataset_NB}_test.pkl', compression='zip')\n",
    "\n",
    "submission = pd.read_csv(Config.raw_data_dir + 'sample_submit.csv', header=None)\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genre</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>positiveness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>tempo_int</th>\n",
       "      <th>region_A</th>\n",
       "      <th>region_B</th>\n",
       "      <th>region_C</th>\n",
       "      <th>region_D</th>\n",
       "      <th>region_E</th>\n",
       "      <th>region_F</th>\n",
       "      <th>region_G</th>\n",
       "      <th>region_H</th>\n",
       "      <th>region_I</th>\n",
       "      <th>region_J</th>\n",
       "      <th>region_K</th>\n",
       "      <th>region_L</th>\n",
       "      <th>region_M</th>\n",
       "      <th>region_N</th>\n",
       "      <th>region_O</th>\n",
       "      <th>region_P</th>\n",
       "      <th>region_Q</th>\n",
       "      <th>region_R</th>\n",
       "      <th>region_S</th>\n",
       "      <th>region_T</th>\n",
       "      <th>unknown</th>\n",
       "      <th>duration_long</th>\n",
       "      <th>popularity_add_duration_ms</th>\n",
       "      <th>popularity_sub_duration_ms</th>\n",
       "      <th>popularity_mul_duration_ms</th>\n",
       "      <th>popularity_bigger_duration_ms</th>\n",
       "      <th>popularity_add_acousticness</th>\n",
       "      <th>popularity_sub_acousticness</th>\n",
       "      <th>popularity_mul_acousticness</th>\n",
       "      <th>popularity_bigger_acousticness</th>\n",
       "      <th>popularity_add_positiveness</th>\n",
       "      <th>popularity_sub_positiveness</th>\n",
       "      <th>popularity_mul_positiveness</th>\n",
       "      <th>popularity_bigger_positiveness</th>\n",
       "      <th>popularity_add_danceability</th>\n",
       "      <th>popularity_sub_danceability</th>\n",
       "      <th>popularity_mul_danceability</th>\n",
       "      <th>popularity_bigger_danceability</th>\n",
       "      <th>popularity_add_loudness</th>\n",
       "      <th>popularity_sub_loudness</th>\n",
       "      <th>popularity_mul_loudness</th>\n",
       "      <th>popularity_bigger_loudness</th>\n",
       "      <th>popularity_add_energy</th>\n",
       "      <th>popularity_sub_energy</th>\n",
       "      <th>popularity_mul_energy</th>\n",
       "      <th>popularity_bigger_energy</th>\n",
       "      <th>popularity_add_liveness</th>\n",
       "      <th>popularity_sub_liveness</th>\n",
       "      <th>popularity_mul_liveness</th>\n",
       "      <th>popularity_bigger_liveness</th>\n",
       "      <th>popularity_add_speechiness</th>\n",
       "      <th>popularity_sub_speechiness</th>\n",
       "      <th>popularity_mul_speechiness</th>\n",
       "      <th>popularity_bigger_speechiness</th>\n",
       "      <th>popularity_add_instrumentalness</th>\n",
       "      <th>popularity_sub_instrumentalness</th>\n",
       "      <th>popularity_mul_instrumentalness</th>\n",
       "      <th>popularity_bigger_instrumentalness</th>\n",
       "      <th>popularity_add_tempo_int</th>\n",
       "      <th>popularity_sub_tempo_int</th>\n",
       "      <th>popularity_mul_tempo_int</th>\n",
       "      <th>popularity_bigger_tempo_int</th>\n",
       "      <th>duration_ms_add_acousticness</th>\n",
       "      <th>duration_ms_sub_acousticness</th>\n",
       "      <th>duration_ms_mul_acousticness</th>\n",
       "      <th>duration_ms_bigger_acousticness</th>\n",
       "      <th>duration_ms_add_positiveness</th>\n",
       "      <th>duration_ms_sub_positiveness</th>\n",
       "      <th>duration_ms_mul_positiveness</th>\n",
       "      <th>duration_ms_bigger_positiveness</th>\n",
       "      <th>duration_ms_add_danceability</th>\n",
       "      <th>duration_ms_sub_danceability</th>\n",
       "      <th>duration_ms_mul_danceability</th>\n",
       "      <th>duration_ms_bigger_danceability</th>\n",
       "      <th>duration_ms_add_loudness</th>\n",
       "      <th>duration_ms_sub_loudness</th>\n",
       "      <th>duration_ms_mul_loudness</th>\n",
       "      <th>duration_ms_bigger_loudness</th>\n",
       "      <th>duration_ms_add_energy</th>\n",
       "      <th>duration_ms_sub_energy</th>\n",
       "      <th>duration_ms_mul_energy</th>\n",
       "      <th>duration_ms_bigger_energy</th>\n",
       "      <th>duration_ms_add_liveness</th>\n",
       "      <th>duration_ms_sub_liveness</th>\n",
       "      <th>duration_ms_mul_liveness</th>\n",
       "      <th>duration_ms_bigger_liveness</th>\n",
       "      <th>duration_ms_add_speechiness</th>\n",
       "      <th>duration_ms_sub_speechiness</th>\n",
       "      <th>duration_ms_mul_speechiness</th>\n",
       "      <th>duration_ms_bigger_speechiness</th>\n",
       "      <th>duration_ms_add_instrumentalness</th>\n",
       "      <th>duration_ms_sub_instrumentalness</th>\n",
       "      <th>duration_ms_mul_instrumentalness</th>\n",
       "      <th>duration_ms_bigger_instrumentalness</th>\n",
       "      <th>duration_ms_add_tempo_int</th>\n",
       "      <th>duration_ms_sub_tempo_int</th>\n",
       "      <th>duration_ms_mul_tempo_int</th>\n",
       "      <th>duration_ms_bigger_tempo_int</th>\n",
       "      <th>acousticness_add_positiveness</th>\n",
       "      <th>acousticness_sub_positiveness</th>\n",
       "      <th>acousticness_mul_positiveness</th>\n",
       "      <th>acousticness_bigger_positiveness</th>\n",
       "      <th>acousticness_add_danceability</th>\n",
       "      <th>acousticness_sub_danceability</th>\n",
       "      <th>acousticness_mul_danceability</th>\n",
       "      <th>acousticness_bigger_danceability</th>\n",
       "      <th>acousticness_add_loudness</th>\n",
       "      <th>acousticness_sub_loudness</th>\n",
       "      <th>acousticness_mul_loudness</th>\n",
       "      <th>acousticness_bigger_loudness</th>\n",
       "      <th>acousticness_add_energy</th>\n",
       "      <th>acousticness_sub_energy</th>\n",
       "      <th>acousticness_mul_energy</th>\n",
       "      <th>acousticness_bigger_energy</th>\n",
       "      <th>acousticness_add_liveness</th>\n",
       "      <th>acousticness_sub_liveness</th>\n",
       "      <th>acousticness_mul_liveness</th>\n",
       "      <th>acousticness_bigger_liveness</th>\n",
       "      <th>acousticness_add_speechiness</th>\n",
       "      <th>acousticness_sub_speechiness</th>\n",
       "      <th>acousticness_mul_speechiness</th>\n",
       "      <th>acousticness_bigger_speechiness</th>\n",
       "      <th>acousticness_add_instrumentalness</th>\n",
       "      <th>acousticness_sub_instrumentalness</th>\n",
       "      <th>acousticness_mul_instrumentalness</th>\n",
       "      <th>acousticness_bigger_instrumentalness</th>\n",
       "      <th>acousticness_add_tempo_int</th>\n",
       "      <th>acousticness_sub_tempo_int</th>\n",
       "      <th>acousticness_mul_tempo_int</th>\n",
       "      <th>acousticness_bigger_tempo_int</th>\n",
       "      <th>positiveness_add_danceability</th>\n",
       "      <th>positiveness_sub_danceability</th>\n",
       "      <th>positiveness_mul_danceability</th>\n",
       "      <th>positiveness_bigger_danceability</th>\n",
       "      <th>positiveness_add_loudness</th>\n",
       "      <th>positiveness_sub_loudness</th>\n",
       "      <th>positiveness_mul_loudness</th>\n",
       "      <th>positiveness_bigger_loudness</th>\n",
       "      <th>positiveness_add_energy</th>\n",
       "      <th>positiveness_sub_energy</th>\n",
       "      <th>positiveness_mul_energy</th>\n",
       "      <th>positiveness_bigger_energy</th>\n",
       "      <th>positiveness_add_liveness</th>\n",
       "      <th>positiveness_sub_liveness</th>\n",
       "      <th>positiveness_mul_liveness</th>\n",
       "      <th>positiveness_bigger_liveness</th>\n",
       "      <th>positiveness_add_speechiness</th>\n",
       "      <th>positiveness_sub_speechiness</th>\n",
       "      <th>positiveness_mul_speechiness</th>\n",
       "      <th>positiveness_bigger_speechiness</th>\n",
       "      <th>positiveness_add_instrumentalness</th>\n",
       "      <th>positiveness_sub_instrumentalness</th>\n",
       "      <th>positiveness_mul_instrumentalness</th>\n",
       "      <th>positiveness_bigger_instrumentalness</th>\n",
       "      <th>positiveness_add_tempo_int</th>\n",
       "      <th>positiveness_sub_tempo_int</th>\n",
       "      <th>positiveness_mul_tempo_int</th>\n",
       "      <th>positiveness_bigger_tempo_int</th>\n",
       "      <th>danceability_add_loudness</th>\n",
       "      <th>danceability_sub_loudness</th>\n",
       "      <th>danceability_mul_loudness</th>\n",
       "      <th>danceability_bigger_loudness</th>\n",
       "      <th>danceability_add_energy</th>\n",
       "      <th>danceability_sub_energy</th>\n",
       "      <th>danceability_mul_energy</th>\n",
       "      <th>danceability_bigger_energy</th>\n",
       "      <th>danceability_add_liveness</th>\n",
       "      <th>danceability_sub_liveness</th>\n",
       "      <th>danceability_mul_liveness</th>\n",
       "      <th>danceability_bigger_liveness</th>\n",
       "      <th>danceability_add_speechiness</th>\n",
       "      <th>danceability_sub_speechiness</th>\n",
       "      <th>danceability_mul_speechiness</th>\n",
       "      <th>danceability_bigger_speechiness</th>\n",
       "      <th>danceability_add_instrumentalness</th>\n",
       "      <th>danceability_sub_instrumentalness</th>\n",
       "      <th>danceability_mul_instrumentalness</th>\n",
       "      <th>danceability_bigger_instrumentalness</th>\n",
       "      <th>danceability_add_tempo_int</th>\n",
       "      <th>danceability_sub_tempo_int</th>\n",
       "      <th>danceability_mul_tempo_int</th>\n",
       "      <th>danceability_bigger_tempo_int</th>\n",
       "      <th>loudness_add_energy</th>\n",
       "      <th>loudness_sub_energy</th>\n",
       "      <th>loudness_mul_energy</th>\n",
       "      <th>loudness_bigger_energy</th>\n",
       "      <th>loudness_add_liveness</th>\n",
       "      <th>loudness_sub_liveness</th>\n",
       "      <th>loudness_mul_liveness</th>\n",
       "      <th>loudness_bigger_liveness</th>\n",
       "      <th>loudness_add_speechiness</th>\n",
       "      <th>loudness_sub_speechiness</th>\n",
       "      <th>loudness_mul_speechiness</th>\n",
       "      <th>loudness_bigger_speechiness</th>\n",
       "      <th>loudness_add_instrumentalness</th>\n",
       "      <th>loudness_sub_instrumentalness</th>\n",
       "      <th>loudness_mul_instrumentalness</th>\n",
       "      <th>loudness_bigger_instrumentalness</th>\n",
       "      <th>loudness_add_tempo_int</th>\n",
       "      <th>loudness_sub_tempo_int</th>\n",
       "      <th>loudness_mul_tempo_int</th>\n",
       "      <th>loudness_bigger_tempo_int</th>\n",
       "      <th>energy_add_liveness</th>\n",
       "      <th>energy_sub_liveness</th>\n",
       "      <th>energy_mul_liveness</th>\n",
       "      <th>energy_bigger_liveness</th>\n",
       "      <th>energy_add_speechiness</th>\n",
       "      <th>energy_sub_speechiness</th>\n",
       "      <th>energy_mul_speechiness</th>\n",
       "      <th>energy_bigger_speechiness</th>\n",
       "      <th>energy_add_instrumentalness</th>\n",
       "      <th>energy_sub_instrumentalness</th>\n",
       "      <th>energy_mul_instrumentalness</th>\n",
       "      <th>energy_bigger_instrumentalness</th>\n",
       "      <th>energy_add_tempo_int</th>\n",
       "      <th>energy_sub_tempo_int</th>\n",
       "      <th>energy_mul_tempo_int</th>\n",
       "      <th>energy_bigger_tempo_int</th>\n",
       "      <th>liveness_add_speechiness</th>\n",
       "      <th>liveness_sub_speechiness</th>\n",
       "      <th>liveness_mul_speechiness</th>\n",
       "      <th>liveness_bigger_speechiness</th>\n",
       "      <th>liveness_add_instrumentalness</th>\n",
       "      <th>liveness_sub_instrumentalness</th>\n",
       "      <th>liveness_mul_instrumentalness</th>\n",
       "      <th>liveness_bigger_instrumentalness</th>\n",
       "      <th>liveness_add_tempo_int</th>\n",
       "      <th>liveness_sub_tempo_int</th>\n",
       "      <th>liveness_mul_tempo_int</th>\n",
       "      <th>liveness_bigger_tempo_int</th>\n",
       "      <th>speechiness_add_instrumentalness</th>\n",
       "      <th>speechiness_sub_instrumentalness</th>\n",
       "      <th>speechiness_mul_instrumentalness</th>\n",
       "      <th>speechiness_bigger_instrumentalness</th>\n",
       "      <th>speechiness_add_tempo_int</th>\n",
       "      <th>speechiness_sub_tempo_int</th>\n",
       "      <th>speechiness_mul_tempo_int</th>\n",
       "      <th>speechiness_bigger_tempo_int</th>\n",
       "      <th>instrumentalness_add_tempo_int</th>\n",
       "      <th>instrumentalness_sub_tempo_int</th>\n",
       "      <th>instrumentalness_mul_tempo_int</th>\n",
       "      <th>instrumentalness_bigger_tempo_int</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "      <th>PCA4</th>\n",
       "      <th>PCA5</th>\n",
       "      <th>PCA6</th>\n",
       "      <th>PCA7</th>\n",
       "      <th>PCA8</th>\n",
       "      <th>PCA9</th>\n",
       "      <th>PCA10</th>\n",
       "      <th>PCA11</th>\n",
       "      <th>PCA12</th>\n",
       "      <th>PCA13</th>\n",
       "      <th>PCA14</th>\n",
       "      <th>PCA15</th>\n",
       "      <th>PCA16</th>\n",
       "      <th>PCA17</th>\n",
       "      <th>PCA18</th>\n",
       "      <th>PCA19</th>\n",
       "      <th>PCA20</th>\n",
       "      <th>PCA21</th>\n",
       "      <th>PCA22</th>\n",
       "      <th>PCA23</th>\n",
       "      <th>PCA24</th>\n",
       "      <th>PCA25</th>\n",
       "      <th>PCA26</th>\n",
       "      <th>PCA27</th>\n",
       "      <th>PCA28</th>\n",
       "      <th>PCA29</th>\n",
       "      <th>PCA30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.00000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "      <td>4.046000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022.500000</td>\n",
       "      <td>7.281760</td>\n",
       "      <td>0.513847</td>\n",
       "      <td>0.427150</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.468205</td>\n",
       "      <td>0.519770</td>\n",
       "      <td>0.644845</td>\n",
       "      <td>0.602985</td>\n",
       "      <td>0.234547</td>\n",
       "      <td>0.302811</td>\n",
       "      <td>0.173380</td>\n",
       "      <td>134.532130</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.080326</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>0.049184</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.185863</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.056846</td>\n",
       "      <td>0.027929</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.086258</td>\n",
       "      <td>0.008898</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.091448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218106</td>\n",
       "      <td>0.225913</td>\n",
       "      <td>0.218106</td>\n",
       "      <td>0.68611</td>\n",
       "      <td>0.184147</td>\n",
       "      <td>0.310929</td>\n",
       "      <td>0.184147</td>\n",
       "      <td>0.711320</td>\n",
       "      <td>0.245723</td>\n",
       "      <td>0.266373</td>\n",
       "      <td>0.245723</td>\n",
       "      <td>0.552397</td>\n",
       "      <td>0.276778</td>\n",
       "      <td>0.221065</td>\n",
       "      <td>0.276778</td>\n",
       "      <td>0.478744</td>\n",
       "      <td>0.330583</td>\n",
       "      <td>0.249351</td>\n",
       "      <td>0.330583</td>\n",
       "      <td>0.319081</td>\n",
       "      <td>0.302921</td>\n",
       "      <td>0.283785</td>\n",
       "      <td>0.302921</td>\n",
       "      <td>0.410776</td>\n",
       "      <td>0.118140</td>\n",
       "      <td>0.346472</td>\n",
       "      <td>0.118140</td>\n",
       "      <td>0.836876</td>\n",
       "      <td>0.156906</td>\n",
       "      <td>0.293550</td>\n",
       "      <td>0.156906</td>\n",
       "      <td>0.783490</td>\n",
       "      <td>0.083207</td>\n",
       "      <td>4.109695e-01</td>\n",
       "      <td>0.083207</td>\n",
       "      <td>0.880129</td>\n",
       "      <td>69.041753</td>\n",
       "      <td>134.018283</td>\n",
       "      <td>69.041753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142524</td>\n",
       "      <td>0.291033</td>\n",
       "      <td>0.142524</td>\n",
       "      <td>0.650272</td>\n",
       "      <td>0.193655</td>\n",
       "      <td>0.270971</td>\n",
       "      <td>0.193655</td>\n",
       "      <td>0.452299</td>\n",
       "      <td>0.219816</td>\n",
       "      <td>0.239184</td>\n",
       "      <td>0.219816</td>\n",
       "      <td>0.335887</td>\n",
       "      <td>0.276127</td>\n",
       "      <td>0.279156</td>\n",
       "      <td>0.276127</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.257328</td>\n",
       "      <td>0.278120</td>\n",
       "      <td>0.257328</td>\n",
       "      <td>0.263964</td>\n",
       "      <td>0.100435</td>\n",
       "      <td>0.264279</td>\n",
       "      <td>0.100435</td>\n",
       "      <td>0.825754</td>\n",
       "      <td>0.126811</td>\n",
       "      <td>0.226689</td>\n",
       "      <td>0.126811</td>\n",
       "      <td>0.758774</td>\n",
       "      <td>0.074069</td>\n",
       "      <td>0.319594</td>\n",
       "      <td>0.074069</td>\n",
       "      <td>0.899654</td>\n",
       "      <td>57.686709</td>\n",
       "      <td>134.104981</td>\n",
       "      <td>57.686709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147264</td>\n",
       "      <td>0.367864</td>\n",
       "      <td>0.147264</td>\n",
       "      <td>0.338112</td>\n",
       "      <td>0.175315</td>\n",
       "      <td>0.348578</td>\n",
       "      <td>0.175315</td>\n",
       "      <td>0.283243</td>\n",
       "      <td>0.193129</td>\n",
       "      <td>0.457244</td>\n",
       "      <td>0.193129</td>\n",
       "      <td>0.231340</td>\n",
       "      <td>0.159125</td>\n",
       "      <td>0.488242</td>\n",
       "      <td>0.159125</td>\n",
       "      <td>0.281513</td>\n",
       "      <td>0.077056</td>\n",
       "      <td>0.278478</td>\n",
       "      <td>0.077056</td>\n",
       "      <td>0.583292</td>\n",
       "      <td>0.097219</td>\n",
       "      <td>2.857788e-01</td>\n",
       "      <td>0.097219</td>\n",
       "      <td>0.475779</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.287136</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.707612</td>\n",
       "      <td>45.212122</td>\n",
       "      <td>134.188046</td>\n",
       "      <td>45.212122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>1.901843e-01</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.420662</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>0.284319</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>0.290410</td>\n",
       "      <td>0.302636</td>\n",
       "      <td>0.253651</td>\n",
       "      <td>0.302636</td>\n",
       "      <td>0.333169</td>\n",
       "      <td>0.110767</td>\n",
       "      <td>0.320527</td>\n",
       "      <td>0.110767</td>\n",
       "      <td>0.775828</td>\n",
       "      <td>0.147390</td>\n",
       "      <td>2.740896e-01</td>\n",
       "      <td>0.147390</td>\n",
       "      <td>0.686604</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.393858</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.845774</td>\n",
       "      <td>63.412627</td>\n",
       "      <td>134.063926</td>\n",
       "      <td>63.412627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337171</td>\n",
       "      <td>0.254669</td>\n",
       "      <td>0.337171</td>\n",
       "      <td>0.327731</td>\n",
       "      <td>0.316844</td>\n",
       "      <td>0.261004</td>\n",
       "      <td>0.316844</td>\n",
       "      <td>0.420662</td>\n",
       "      <td>0.118520</td>\n",
       "      <td>0.353719</td>\n",
       "      <td>0.118520</td>\n",
       "      <td>0.836629</td>\n",
       "      <td>0.161451</td>\n",
       "      <td>0.291194</td>\n",
       "      <td>0.161451</td>\n",
       "      <td>0.796342</td>\n",
       "      <td>0.078199</td>\n",
       "      <td>0.428699</td>\n",
       "      <td>0.078199</td>\n",
       "      <td>0.886802</td>\n",
       "      <td>69.358547</td>\n",
       "      <td>134.012361</td>\n",
       "      <td>69.358547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421535</td>\n",
       "      <td>0.148117</td>\n",
       "      <td>0.421535</td>\n",
       "      <td>0.580326</td>\n",
       "      <td>0.153282</td>\n",
       "      <td>0.442677</td>\n",
       "      <td>0.153282</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.199755</td>\n",
       "      <td>0.377407</td>\n",
       "      <td>0.199755</td>\n",
       "      <td>0.895947</td>\n",
       "      <td>0.108233</td>\n",
       "      <td>0.512521</td>\n",
       "      <td>0.108233</td>\n",
       "      <td>0.924864</td>\n",
       "      <td>87.369172</td>\n",
       "      <td>133.887285</td>\n",
       "      <td>87.369172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148519</td>\n",
       "      <td>0.406282</td>\n",
       "      <td>0.148519</td>\n",
       "      <td>0.892486</td>\n",
       "      <td>0.191223</td>\n",
       "      <td>3.500123e-01</td>\n",
       "      <td>0.191223</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.105382</td>\n",
       "      <td>0.473166</td>\n",
       "      <td>0.105382</td>\n",
       "      <td>0.909540</td>\n",
       "      <td>82.262444</td>\n",
       "      <td>133.929145</td>\n",
       "      <td>82.262444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076055</td>\n",
       "      <td>0.187455</td>\n",
       "      <td>0.076055</td>\n",
       "      <td>0.339595</td>\n",
       "      <td>0.040346</td>\n",
       "      <td>0.188380</td>\n",
       "      <td>0.040346</td>\n",
       "      <td>0.663618</td>\n",
       "      <td>31.600806</td>\n",
       "      <td>134.297583</td>\n",
       "      <td>31.600806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>40.541308</td>\n",
       "      <td>134.229319</td>\n",
       "      <td>40.541308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.368508</td>\n",
       "      <td>134.358750</td>\n",
       "      <td>23.368508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.305630e-15</td>\n",
       "      <td>9.328727e-15</td>\n",
       "      <td>-1.770210e-15</td>\n",
       "      <td>-9.300629e-15</td>\n",
       "      <td>-1.152042e-15</td>\n",
       "      <td>6.434574e-15</td>\n",
       "      <td>8.766756e-15</td>\n",
       "      <td>-3.989998e-15</td>\n",
       "      <td>5.451124e-15</td>\n",
       "      <td>1.208239e-15</td>\n",
       "      <td>1.494844e-14</td>\n",
       "      <td>3.108405e-16</td>\n",
       "      <td>-1.134590e-15</td>\n",
       "      <td>-1.352244e-15</td>\n",
       "      <td>3.093039e-16</td>\n",
       "      <td>-1.467712e-15</td>\n",
       "      <td>-1.714891e-15</td>\n",
       "      <td>3.195115e-16</td>\n",
       "      <td>-6.058755e-17</td>\n",
       "      <td>1.028452e-16</td>\n",
       "      <td>-2.138126e-16</td>\n",
       "      <td>6.717316e-17</td>\n",
       "      <td>-1.475175e-16</td>\n",
       "      <td>1.016817e-15</td>\n",
       "      <td>3.354267e-16</td>\n",
       "      <td>7.711742e-16</td>\n",
       "      <td>4.814076e-16</td>\n",
       "      <td>8.848856e-16</td>\n",
       "      <td>-4.978716e-16</td>\n",
       "      <td>2.651803e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1168.123923</td>\n",
       "      <td>2.887542</td>\n",
       "      <td>0.211821</td>\n",
       "      <td>0.158453</td>\n",
       "      <td>0.283517</td>\n",
       "      <td>0.263596</td>\n",
       "      <td>0.223505</td>\n",
       "      <td>0.197972</td>\n",
       "      <td>0.243420</td>\n",
       "      <td>0.189897</td>\n",
       "      <td>0.182977</td>\n",
       "      <td>0.198511</td>\n",
       "      <td>30.432382</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.271831</td>\n",
       "      <td>0.142602</td>\n",
       "      <td>0.216280</td>\n",
       "      <td>0.380426</td>\n",
       "      <td>0.180254</td>\n",
       "      <td>0.120885</td>\n",
       "      <td>0.206748</td>\n",
       "      <td>0.389044</td>\n",
       "      <td>0.078373</td>\n",
       "      <td>0.231577</td>\n",
       "      <td>0.164789</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>0.103727</td>\n",
       "      <td>0.181528</td>\n",
       "      <td>0.280779</td>\n",
       "      <td>0.093919</td>\n",
       "      <td>0.110491</td>\n",
       "      <td>0.118883</td>\n",
       "      <td>0.200652</td>\n",
       "      <td>0.288281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118272</td>\n",
       "      <td>0.170918</td>\n",
       "      <td>0.118272</td>\n",
       "      <td>0.46413</td>\n",
       "      <td>0.176562</td>\n",
       "      <td>0.206620</td>\n",
       "      <td>0.176562</td>\n",
       "      <td>0.453205</td>\n",
       "      <td>0.176793</td>\n",
       "      <td>0.187577</td>\n",
       "      <td>0.176793</td>\n",
       "      <td>0.497308</td>\n",
       "      <td>0.175172</td>\n",
       "      <td>0.163030</td>\n",
       "      <td>0.175172</td>\n",
       "      <td>0.499610</td>\n",
       "      <td>0.177945</td>\n",
       "      <td>0.201425</td>\n",
       "      <td>0.177945</td>\n",
       "      <td>0.466178</td>\n",
       "      <td>0.175564</td>\n",
       "      <td>0.212983</td>\n",
       "      <td>0.175564</td>\n",
       "      <td>0.492035</td>\n",
       "      <td>0.111015</td>\n",
       "      <td>0.208924</td>\n",
       "      <td>0.111015</td>\n",
       "      <td>0.369525</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>0.184631</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>0.411917</td>\n",
       "      <td>0.105046</td>\n",
       "      <td>2.074966e-01</td>\n",
       "      <td>0.105046</td>\n",
       "      <td>0.324851</td>\n",
       "      <td>33.178434</td>\n",
       "      <td>30.435986</td>\n",
       "      <td>33.178434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130122</td>\n",
       "      <td>0.191248</td>\n",
       "      <td>0.130122</td>\n",
       "      <td>0.476943</td>\n",
       "      <td>0.122890</td>\n",
       "      <td>0.188448</td>\n",
       "      <td>0.122890</td>\n",
       "      <td>0.497781</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>0.175579</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>0.472358</td>\n",
       "      <td>0.132389</td>\n",
       "      <td>0.179979</td>\n",
       "      <td>0.132389</td>\n",
       "      <td>0.380426</td>\n",
       "      <td>0.143747</td>\n",
       "      <td>0.195934</td>\n",
       "      <td>0.143747</td>\n",
       "      <td>0.440835</td>\n",
       "      <td>0.099274</td>\n",
       "      <td>0.167078</td>\n",
       "      <td>0.099274</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>0.092797</td>\n",
       "      <td>0.166497</td>\n",
       "      <td>0.092797</td>\n",
       "      <td>0.427880</td>\n",
       "      <td>0.101604</td>\n",
       "      <td>0.163536</td>\n",
       "      <td>0.101604</td>\n",
       "      <td>0.300498</td>\n",
       "      <td>25.761500</td>\n",
       "      <td>30.425518</td>\n",
       "      <td>25.761500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.240001</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.473125</td>\n",
       "      <td>0.158610</td>\n",
       "      <td>0.216178</td>\n",
       "      <td>0.158610</td>\n",
       "      <td>0.450629</td>\n",
       "      <td>0.153652</td>\n",
       "      <td>0.241762</td>\n",
       "      <td>0.153652</td>\n",
       "      <td>0.421741</td>\n",
       "      <td>0.116032</td>\n",
       "      <td>0.254895</td>\n",
       "      <td>0.116032</td>\n",
       "      <td>0.449792</td>\n",
       "      <td>0.101610</td>\n",
       "      <td>0.241190</td>\n",
       "      <td>0.101610</td>\n",
       "      <td>0.493075</td>\n",
       "      <td>0.099732</td>\n",
       "      <td>2.186920e-01</td>\n",
       "      <td>0.099732</td>\n",
       "      <td>0.499475</td>\n",
       "      <td>0.110195</td>\n",
       "      <td>0.265631</td>\n",
       "      <td>0.110195</td>\n",
       "      <td>0.454916</td>\n",
       "      <td>38.620157</td>\n",
       "      <td>30.469120</td>\n",
       "      <td>38.620157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222949</td>\n",
       "      <td>1.442885e-01</td>\n",
       "      <td>0.222949</td>\n",
       "      <td>0.493726</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>0.203762</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>0.454008</td>\n",
       "      <td>0.221479</td>\n",
       "      <td>0.204724</td>\n",
       "      <td>0.221479</td>\n",
       "      <td>0.471404</td>\n",
       "      <td>0.120210</td>\n",
       "      <td>0.235560</td>\n",
       "      <td>0.120210</td>\n",
       "      <td>0.417087</td>\n",
       "      <td>0.141108</td>\n",
       "      <td>2.096513e-01</td>\n",
       "      <td>0.141108</td>\n",
       "      <td>0.463931</td>\n",
       "      <td>0.076794</td>\n",
       "      <td>0.257046</td>\n",
       "      <td>0.076794</td>\n",
       "      <td>0.361210</td>\n",
       "      <td>39.656076</td>\n",
       "      <td>30.419584</td>\n",
       "      <td>39.656076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.189530</td>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.469444</td>\n",
       "      <td>0.188037</td>\n",
       "      <td>0.202809</td>\n",
       "      <td>0.188037</td>\n",
       "      <td>0.493726</td>\n",
       "      <td>0.111282</td>\n",
       "      <td>0.221408</td>\n",
       "      <td>0.111282</td>\n",
       "      <td>0.369750</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.193860</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.402767</td>\n",
       "      <td>0.083538</td>\n",
       "      <td>0.222243</td>\n",
       "      <td>0.083538</td>\n",
       "      <td>0.316874</td>\n",
       "      <td>32.349596</td>\n",
       "      <td>30.451838</td>\n",
       "      <td>32.349596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231726</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.231726</td>\n",
       "      <td>0.493567</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.278212</td>\n",
       "      <td>0.145260</td>\n",
       "      <td>0.195547</td>\n",
       "      <td>0.145260</td>\n",
       "      <td>0.305368</td>\n",
       "      <td>0.135942</td>\n",
       "      <td>0.212915</td>\n",
       "      <td>0.135942</td>\n",
       "      <td>0.263643</td>\n",
       "      <td>34.562145</td>\n",
       "      <td>30.412747</td>\n",
       "      <td>34.562145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150619</td>\n",
       "      <td>0.227603</td>\n",
       "      <td>0.150619</td>\n",
       "      <td>0.309803</td>\n",
       "      <td>0.155064</td>\n",
       "      <td>2.074911e-01</td>\n",
       "      <td>0.155064</td>\n",
       "      <td>0.360261</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.240106</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.286875</td>\n",
       "      <td>39.976250</td>\n",
       "      <td>30.395813</td>\n",
       "      <td>39.976250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097270</td>\n",
       "      <td>0.170262</td>\n",
       "      <td>0.097270</td>\n",
       "      <td>0.473630</td>\n",
       "      <td>0.065540</td>\n",
       "      <td>0.210606</td>\n",
       "      <td>0.065540</td>\n",
       "      <td>0.472530</td>\n",
       "      <td>27.524141</td>\n",
       "      <td>30.431441</td>\n",
       "      <td>27.524141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075072</td>\n",
       "      <td>0.197153</td>\n",
       "      <td>0.075072</td>\n",
       "      <td>0.401305</td>\n",
       "      <td>26.715474</td>\n",
       "      <td>30.439390</td>\n",
       "      <td>26.715474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.999528</td>\n",
       "      <td>30.431607</td>\n",
       "      <td>27.999528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.229942e+02</td>\n",
       "      <td>6.944027e+01</td>\n",
       "      <td>5.914307e+01</td>\n",
       "      <td>4.036015e+01</td>\n",
       "      <td>3.862141e+01</td>\n",
       "      <td>3.661330e+01</td>\n",
       "      <td>3.322180e+01</td>\n",
       "      <td>3.291647e+01</td>\n",
       "      <td>2.848274e+01</td>\n",
       "      <td>2.650752e+01</td>\n",
       "      <td>2.075149e+01</td>\n",
       "      <td>5.450737e-01</td>\n",
       "      <td>4.932492e-01</td>\n",
       "      <td>4.426273e-01</td>\n",
       "      <td>4.275965e-01</td>\n",
       "      <td>4.225538e-01</td>\n",
       "      <td>4.101197e-01</td>\n",
       "      <td>3.867268e-01</td>\n",
       "      <td>3.791355e-01</td>\n",
       "      <td>3.720030e-01</td>\n",
       "      <td>3.661723e-01</td>\n",
       "      <td>3.503816e-01</td>\n",
       "      <td>3.402042e-01</td>\n",
       "      <td>3.324740e-01</td>\n",
       "      <td>3.286413e-01</td>\n",
       "      <td>3.248159e-01</td>\n",
       "      <td>3.194684e-01</td>\n",
       "      <td>3.113954e-01</td>\n",
       "      <td>3.056855e-01</td>\n",
       "      <td>2.999086e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.536055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.008829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.541326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.428007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.051619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.252893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.484971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.886720e+02</td>\n",
       "      <td>-1.110692e+02</td>\n",
       "      <td>-1.714855e+02</td>\n",
       "      <td>-1.279318e+02</td>\n",
       "      <td>-1.153427e+02</td>\n",
       "      <td>-1.212453e+02</td>\n",
       "      <td>-1.260679e+02</td>\n",
       "      <td>-1.295030e+02</td>\n",
       "      <td>-1.113049e+02</td>\n",
       "      <td>-1.142452e+02</td>\n",
       "      <td>-9.613118e+01</td>\n",
       "      <td>-1.812536e+00</td>\n",
       "      <td>-1.870845e+00</td>\n",
       "      <td>-1.438806e+00</td>\n",
       "      <td>-1.155813e+00</td>\n",
       "      <td>-1.403131e+00</td>\n",
       "      <td>-1.452708e+00</td>\n",
       "      <td>-1.126972e+00</td>\n",
       "      <td>-1.424939e+00</td>\n",
       "      <td>-8.547488e-01</td>\n",
       "      <td>-1.077573e+00</td>\n",
       "      <td>-1.389176e+00</td>\n",
       "      <td>-1.247187e+00</td>\n",
       "      <td>-1.361196e+00</td>\n",
       "      <td>-1.263367e+00</td>\n",
       "      <td>-1.177883e+00</td>\n",
       "      <td>-1.231024e+00</td>\n",
       "      <td>-1.297213e+00</td>\n",
       "      <td>-1.228253e+00</td>\n",
       "      <td>-1.037534e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1011.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.381579</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.112032</td>\n",
       "      <td>0.247631</td>\n",
       "      <td>0.360279</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.430235</td>\n",
       "      <td>0.114511</td>\n",
       "      <td>0.188647</td>\n",
       "      <td>0.081236</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136452</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.136452</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.047082</td>\n",
       "      <td>0.142144</td>\n",
       "      <td>0.047082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102787</td>\n",
       "      <td>0.115260</td>\n",
       "      <td>0.102787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139244</td>\n",
       "      <td>0.091270</td>\n",
       "      <td>0.139244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202091</td>\n",
       "      <td>0.091588</td>\n",
       "      <td>0.202091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171362</td>\n",
       "      <td>0.111318</td>\n",
       "      <td>0.171362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048278</td>\n",
       "      <td>0.173125</td>\n",
       "      <td>0.048278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076098</td>\n",
       "      <td>0.147216</td>\n",
       "      <td>0.076098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>2.607847e-01</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.736842</td>\n",
       "      <td>119.263158</td>\n",
       "      <td>46.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045592</td>\n",
       "      <td>0.143632</td>\n",
       "      <td>0.045592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097291</td>\n",
       "      <td>0.119057</td>\n",
       "      <td>0.097291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136692</td>\n",
       "      <td>0.099277</td>\n",
       "      <td>0.136692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195963</td>\n",
       "      <td>0.131727</td>\n",
       "      <td>0.195963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163355</td>\n",
       "      <td>0.118178</td>\n",
       "      <td>0.163355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042258</td>\n",
       "      <td>0.137616</td>\n",
       "      <td>0.042258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068902</td>\n",
       "      <td>0.101518</td>\n",
       "      <td>0.068902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029346</td>\n",
       "      <td>0.218631</td>\n",
       "      <td>0.029346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.097850</td>\n",
       "      <td>119.424150</td>\n",
       "      <td>41.097850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041032</td>\n",
       "      <td>0.156502</td>\n",
       "      <td>0.041032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049354</td>\n",
       "      <td>0.170186</td>\n",
       "      <td>0.049354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.257468</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071866</td>\n",
       "      <td>0.279791</td>\n",
       "      <td>0.071866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017826</td>\n",
       "      <td>0.078114</td>\n",
       "      <td>0.017826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027142</td>\n",
       "      <td>1.114441e-01</td>\n",
       "      <td>0.027142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.063277</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.881754</td>\n",
       "      <td>119.222846</td>\n",
       "      <td>14.881754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089038</td>\n",
       "      <td>7.283262e-02</td>\n",
       "      <td>0.089038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144319</td>\n",
       "      <td>0.116185</td>\n",
       "      <td>0.144319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110526</td>\n",
       "      <td>0.094640</td>\n",
       "      <td>0.110526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033062</td>\n",
       "      <td>0.121623</td>\n",
       "      <td>0.033062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051795</td>\n",
       "      <td>1.028609e-01</td>\n",
       "      <td>0.051795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025680</td>\n",
       "      <td>0.166071</td>\n",
       "      <td>0.025680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.130009</td>\n",
       "      <td>119.181118</td>\n",
       "      <td>31.130009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201302</td>\n",
       "      <td>0.105883</td>\n",
       "      <td>0.201302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163595</td>\n",
       "      <td>0.099871</td>\n",
       "      <td>0.163595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>0.168599</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073763</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>0.073763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033438</td>\n",
       "      <td>0.256558</td>\n",
       "      <td>0.033438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.011410</td>\n",
       "      <td>119.165270</td>\n",
       "      <td>46.011410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242391</td>\n",
       "      <td>0.058992</td>\n",
       "      <td>0.242391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063933</td>\n",
       "      <td>0.294177</td>\n",
       "      <td>0.063933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104968</td>\n",
       "      <td>0.226763</td>\n",
       "      <td>0.104968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045919</td>\n",
       "      <td>0.383698</td>\n",
       "      <td>0.045919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.963271</td>\n",
       "      <td>119.148078</td>\n",
       "      <td>63.963271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>0.215484</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>1.715020e-01</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037986</td>\n",
       "      <td>0.287673</td>\n",
       "      <td>0.037986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.337285</td>\n",
       "      <td>119.124830</td>\n",
       "      <td>53.337285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023409</td>\n",
       "      <td>0.065124</td>\n",
       "      <td>0.023409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.301250</td>\n",
       "      <td>119.568107</td>\n",
       "      <td>14.301250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017337</td>\n",
       "      <td>0.086097</td>\n",
       "      <td>0.017337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.744005</td>\n",
       "      <td>119.556523</td>\n",
       "      <td>23.744005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.039664</td>\n",
       "      <td>119.781870</td>\n",
       "      <td>10.039664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.573937e+01</td>\n",
       "      <td>-5.267799e+01</td>\n",
       "      <td>-4.116510e+01</td>\n",
       "      <td>-2.557952e+01</td>\n",
       "      <td>-2.306539e+01</td>\n",
       "      <td>-2.081497e+01</td>\n",
       "      <td>-2.058495e+01</td>\n",
       "      <td>-1.865693e+01</td>\n",
       "      <td>-1.827341e+01</td>\n",
       "      <td>-1.564752e+01</td>\n",
       "      <td>-1.344180e+01</td>\n",
       "      <td>-3.688912e-01</td>\n",
       "      <td>-3.327176e-01</td>\n",
       "      <td>-2.930228e-01</td>\n",
       "      <td>-2.634863e-01</td>\n",
       "      <td>-2.864660e-01</td>\n",
       "      <td>-2.780524e-01</td>\n",
       "      <td>-2.693093e-01</td>\n",
       "      <td>-2.457235e-01</td>\n",
       "      <td>-2.996339e-01</td>\n",
       "      <td>-2.576071e-01</td>\n",
       "      <td>-2.326647e-01</td>\n",
       "      <td>-2.327916e-01</td>\n",
       "      <td>-2.175430e-01</td>\n",
       "      <td>-2.185583e-01</td>\n",
       "      <td>-2.198702e-01</td>\n",
       "      <td>-2.122103e-01</td>\n",
       "      <td>-2.043557e-01</td>\n",
       "      <td>-1.986672e-01</td>\n",
       "      <td>-1.768900e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.416620</td>\n",
       "      <td>0.231268</td>\n",
       "      <td>0.450772</td>\n",
       "      <td>0.529204</td>\n",
       "      <td>0.669539</td>\n",
       "      <td>0.639780</td>\n",
       "      <td>0.176306</td>\n",
       "      <td>0.268539</td>\n",
       "      <td>0.118155</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>0.191911</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.119256</td>\n",
       "      <td>0.284066</td>\n",
       "      <td>0.119256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214140</td>\n",
       "      <td>0.235355</td>\n",
       "      <td>0.214140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261254</td>\n",
       "      <td>0.191310</td>\n",
       "      <td>0.261254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321311</td>\n",
       "      <td>0.198264</td>\n",
       "      <td>0.321311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288772</td>\n",
       "      <td>0.235855</td>\n",
       "      <td>0.288772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087411</td>\n",
       "      <td>0.337764</td>\n",
       "      <td>0.087411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129447</td>\n",
       "      <td>0.276081</td>\n",
       "      <td>0.129447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058362</td>\n",
       "      <td>4.183971e-01</td>\n",
       "      <td>0.058362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.947368</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>66.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096648</td>\n",
       "      <td>0.268827</td>\n",
       "      <td>0.096648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177755</td>\n",
       "      <td>0.243467</td>\n",
       "      <td>0.177755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215831</td>\n",
       "      <td>0.207633</td>\n",
       "      <td>0.215831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274207</td>\n",
       "      <td>0.261655</td>\n",
       "      <td>0.274207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249894</td>\n",
       "      <td>0.251675</td>\n",
       "      <td>0.249894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071491</td>\n",
       "      <td>0.251516</td>\n",
       "      <td>0.071491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106001</td>\n",
       "      <td>0.196904</td>\n",
       "      <td>0.106001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047157</td>\n",
       "      <td>0.303938</td>\n",
       "      <td>0.047157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.218718</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>55.218718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101474</td>\n",
       "      <td>0.345779</td>\n",
       "      <td>0.101474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127062</td>\n",
       "      <td>0.336344</td>\n",
       "      <td>0.127062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142172</td>\n",
       "      <td>0.479534</td>\n",
       "      <td>0.142172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128386</td>\n",
       "      <td>0.496785</td>\n",
       "      <td>0.128386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043985</td>\n",
       "      <td>0.202985</td>\n",
       "      <td>0.043985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062335</td>\n",
       "      <td>2.297548e-01</td>\n",
       "      <td>0.062335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>0.178816</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.994379</td>\n",
       "      <td>119.999867</td>\n",
       "      <td>30.994379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219348</td>\n",
       "      <td>1.642473e-01</td>\n",
       "      <td>0.219348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284020</td>\n",
       "      <td>0.253547</td>\n",
       "      <td>0.284020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270540</td>\n",
       "      <td>0.204250</td>\n",
       "      <td>0.270540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072399</td>\n",
       "      <td>0.270036</td>\n",
       "      <td>0.072399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107557</td>\n",
       "      <td>2.207003e-01</td>\n",
       "      <td>0.107557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049610</td>\n",
       "      <td>0.374472</td>\n",
       "      <td>0.049610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.639908</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>58.639908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333621</td>\n",
       "      <td>0.214249</td>\n",
       "      <td>0.333621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310338</td>\n",
       "      <td>0.218462</td>\n",
       "      <td>0.310338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>0.335220</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128148</td>\n",
       "      <td>0.268584</td>\n",
       "      <td>0.128148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058592</td>\n",
       "      <td>0.436518</td>\n",
       "      <td>0.058592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.666718</td>\n",
       "      <td>119.908753</td>\n",
       "      <td>69.666718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427004</td>\n",
       "      <td>0.124596</td>\n",
       "      <td>0.427004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111542</td>\n",
       "      <td>0.457065</td>\n",
       "      <td>0.111542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168446</td>\n",
       "      <td>0.382508</td>\n",
       "      <td>0.168446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.541665</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>86.608177</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>86.608177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098888</td>\n",
       "      <td>0.413849</td>\n",
       "      <td>0.098888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152638</td>\n",
       "      <td>3.484550e-01</td>\n",
       "      <td>0.152638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068132</td>\n",
       "      <td>0.497452</td>\n",
       "      <td>0.068132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.615860</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>81.615860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046320</td>\n",
       "      <td>0.141486</td>\n",
       "      <td>0.046320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.107832</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.646902</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>23.646902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>0.169710</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.919424</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>34.919424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.350679</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>15.350679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.027652e+00</td>\n",
       "      <td>-1.863096e+01</td>\n",
       "      <td>-2.670537e+00</td>\n",
       "      <td>-3.057021e-01</td>\n",
       "      <td>-4.507955e+00</td>\n",
       "      <td>-4.809670e+00</td>\n",
       "      <td>-9.958473e-01</td>\n",
       "      <td>-7.483429e-01</td>\n",
       "      <td>-7.272713e-01</td>\n",
       "      <td>-3.050716e-02</td>\n",
       "      <td>-4.089575e-01</td>\n",
       "      <td>-6.236360e-03</td>\n",
       "      <td>-4.672502e-03</td>\n",
       "      <td>5.274793e-03</td>\n",
       "      <td>-3.501363e-02</td>\n",
       "      <td>9.163934e-03</td>\n",
       "      <td>-1.182609e-02</td>\n",
       "      <td>-2.075138e-02</td>\n",
       "      <td>2.499268e-03</td>\n",
       "      <td>-1.329774e-01</td>\n",
       "      <td>-2.439341e-02</td>\n",
       "      <td>-1.437039e-02</td>\n",
       "      <td>-2.850868e-03</td>\n",
       "      <td>-9.849603e-03</td>\n",
       "      <td>-7.281657e-03</td>\n",
       "      <td>-2.393234e-03</td>\n",
       "      <td>-6.127750e-04</td>\n",
       "      <td>1.215520e-02</td>\n",
       "      <td>2.546144e-03</td>\n",
       "      <td>-1.729942e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3033.750000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.500899</td>\n",
       "      <td>0.552802</td>\n",
       "      <td>0.680469</td>\n",
       "      <td>0.681067</td>\n",
       "      <td>0.786531</td>\n",
       "      <td>0.803927</td>\n",
       "      <td>0.298840</td>\n",
       "      <td>0.365878</td>\n",
       "      <td>0.161997</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291503</td>\n",
       "      <td>0.323598</td>\n",
       "      <td>0.291503</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.286462</td>\n",
       "      <td>0.450938</td>\n",
       "      <td>0.286462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.354333</td>\n",
       "      <td>0.384544</td>\n",
       "      <td>0.354333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.391773</td>\n",
       "      <td>0.320822</td>\n",
       "      <td>0.391773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.442422</td>\n",
       "      <td>0.367092</td>\n",
       "      <td>0.442422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.415315</td>\n",
       "      <td>0.413706</td>\n",
       "      <td>0.415315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150529</td>\n",
       "      <td>0.494854</td>\n",
       "      <td>0.150529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200123</td>\n",
       "      <td>0.419084</td>\n",
       "      <td>0.200123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090362</td>\n",
       "      <td>5.562510e-01</td>\n",
       "      <td>0.090362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>151.592105</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211466</td>\n",
       "      <td>0.395884</td>\n",
       "      <td>0.211466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.271606</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0.271606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.295211</td>\n",
       "      <td>0.340277</td>\n",
       "      <td>0.295211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346241</td>\n",
       "      <td>0.399855</td>\n",
       "      <td>0.346241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336481</td>\n",
       "      <td>0.400162</td>\n",
       "      <td>0.336481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122949</td>\n",
       "      <td>0.358783</td>\n",
       "      <td>0.122949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.158959</td>\n",
       "      <td>0.312882</td>\n",
       "      <td>0.158959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071155</td>\n",
       "      <td>0.399818</td>\n",
       "      <td>0.071155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.558884</td>\n",
       "      <td>151.638994</td>\n",
       "      <td>70.558884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206809</td>\n",
       "      <td>0.555424</td>\n",
       "      <td>0.206809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.264396</td>\n",
       "      <td>0.501269</td>\n",
       "      <td>0.264396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289657</td>\n",
       "      <td>0.647301</td>\n",
       "      <td>0.289657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224519</td>\n",
       "      <td>0.701533</td>\n",
       "      <td>0.224519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096891</td>\n",
       "      <td>0.429181</td>\n",
       "      <td>0.096891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138556</td>\n",
       "      <td>4.238117e-01</td>\n",
       "      <td>0.138556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065435</td>\n",
       "      <td>0.488317</td>\n",
       "      <td>0.065435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.179228</td>\n",
       "      <td>151.885097</td>\n",
       "      <td>69.179228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425962</td>\n",
       "      <td>2.724867e-01</td>\n",
       "      <td>0.425962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453563</td>\n",
       "      <td>0.419043</td>\n",
       "      <td>0.453563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461597</td>\n",
       "      <td>0.355989</td>\n",
       "      <td>0.461597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141942</td>\n",
       "      <td>0.495040</td>\n",
       "      <td>0.141942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196240</td>\n",
       "      <td>4.103904e-01</td>\n",
       "      <td>0.196240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086508</td>\n",
       "      <td>0.601704</td>\n",
       "      <td>0.086508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.648462</td>\n",
       "      <td>151.731522</td>\n",
       "      <td>89.648462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459664</td>\n",
       "      <td>0.366172</td>\n",
       "      <td>0.459664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453581</td>\n",
       "      <td>0.372383</td>\n",
       "      <td>0.453581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152456</td>\n",
       "      <td>0.511627</td>\n",
       "      <td>0.152456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.201362</td>\n",
       "      <td>0.425412</td>\n",
       "      <td>0.201362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091436</td>\n",
       "      <td>0.586747</td>\n",
       "      <td>0.091436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.771233</td>\n",
       "      <td>151.588363</td>\n",
       "      <td>91.771233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597281</td>\n",
       "      <td>0.212057</td>\n",
       "      <td>0.597281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197337</td>\n",
       "      <td>0.598561</td>\n",
       "      <td>0.197337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254018</td>\n",
       "      <td>0.521563</td>\n",
       "      <td>0.254018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109277</td>\n",
       "      <td>0.667130</td>\n",
       "      <td>0.109277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>111.105095</td>\n",
       "      <td>151.417215</td>\n",
       "      <td>111.105095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191518</td>\n",
       "      <td>0.585308</td>\n",
       "      <td>0.191518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254482</td>\n",
       "      <td>5.071929e-01</td>\n",
       "      <td>0.254482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105648</td>\n",
       "      <td>0.668790</td>\n",
       "      <td>0.105648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>109.706306</td>\n",
       "      <td>151.508957</td>\n",
       "      <td>109.706306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089521</td>\n",
       "      <td>0.248982</td>\n",
       "      <td>0.089521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040574</td>\n",
       "      <td>0.246925</td>\n",
       "      <td>0.040574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.556622</td>\n",
       "      <td>151.874841</td>\n",
       "      <td>39.556622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053466</td>\n",
       "      <td>0.290306</td>\n",
       "      <td>0.053466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.178558</td>\n",
       "      <td>151.805970</td>\n",
       "      <td>50.178558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.498492</td>\n",
       "      <td>151.912237</td>\n",
       "      <td>22.498492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.784358e+01</td>\n",
       "      <td>4.023905e+01</td>\n",
       "      <td>3.376015e+01</td>\n",
       "      <td>2.556389e+01</td>\n",
       "      <td>1.621593e+01</td>\n",
       "      <td>1.294016e+01</td>\n",
       "      <td>1.963346e+01</td>\n",
       "      <td>1.722486e+01</td>\n",
       "      <td>1.721280e+01</td>\n",
       "      <td>1.568059e+01</td>\n",
       "      <td>1.271048e+01</td>\n",
       "      <td>3.658082e-01</td>\n",
       "      <td>3.164830e-01</td>\n",
       "      <td>3.061084e-01</td>\n",
       "      <td>2.513082e-01</td>\n",
       "      <td>2.927919e-01</td>\n",
       "      <td>2.772060e-01</td>\n",
       "      <td>2.619235e-01</td>\n",
       "      <td>2.631090e-01</td>\n",
       "      <td>3.909325e-01</td>\n",
       "      <td>2.401957e-01</td>\n",
       "      <td>2.267318e-01</td>\n",
       "      <td>2.256634e-01</td>\n",
       "      <td>2.128364e-01</td>\n",
       "      <td>2.163098e-01</td>\n",
       "      <td>2.178044e-01</td>\n",
       "      <td>2.031693e-01</td>\n",
       "      <td>2.106144e-01</td>\n",
       "      <td>1.970278e-01</td>\n",
       "      <td>1.599871e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4045.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842548</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890378</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.890378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>219.394737</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964195</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.964195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>219.659969</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924222</td>\n",
       "      <td>0.983985</td>\n",
       "      <td>0.924222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930415</td>\n",
       "      <td>0.978570</td>\n",
       "      <td>0.930415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.929697e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>219.920696</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.496157e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983583</td>\n",
       "      <td>0.996306</td>\n",
       "      <td>0.983583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>219.819983</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>185.130503</td>\n",
       "      <td>219.796370</td>\n",
       "      <td>185.130503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946596</td>\n",
       "      <td>0.991962</td>\n",
       "      <td>0.946596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>219.786776</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>218.918515</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>218.918515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996113</td>\n",
       "      <td>0.966270</td>\n",
       "      <td>0.996113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>219.837625</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>219.823937</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>219.980909</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.304270e+02</td>\n",
       "      <td>3.449739e+02</td>\n",
       "      <td>2.763462e+02</td>\n",
       "      <td>1.563338e+02</td>\n",
       "      <td>2.663832e+02</td>\n",
       "      <td>2.390963e+02</td>\n",
       "      <td>2.057707e+02</td>\n",
       "      <td>1.808422e+02</td>\n",
       "      <td>1.812115e+02</td>\n",
       "      <td>1.327488e+02</td>\n",
       "      <td>1.350540e+02</td>\n",
       "      <td>2.253403e+00</td>\n",
       "      <td>3.181155e+00</td>\n",
       "      <td>2.225019e+00</td>\n",
       "      <td>1.337326e+00</td>\n",
       "      <td>1.553355e+00</td>\n",
       "      <td>1.570804e+00</td>\n",
       "      <td>1.551564e+00</td>\n",
       "      <td>1.609956e+00</td>\n",
       "      <td>1.003781e+00</td>\n",
       "      <td>1.310329e+00</td>\n",
       "      <td>1.642654e+00</td>\n",
       "      <td>1.276857e+00</td>\n",
       "      <td>1.632823e+00</td>\n",
       "      <td>1.444511e+00</td>\n",
       "      <td>1.790409e+00</td>\n",
       "      <td>1.378429e+00</td>\n",
       "      <td>1.535372e+00</td>\n",
       "      <td>1.258885e+00</td>\n",
       "      <td>1.225825e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index        genre   popularity  duration_ms  acousticness  positiveness  danceability     loudness       energy     liveness  speechiness  instrumentalness    tempo_int     region_A     region_B     region_C     region_D     region_E     region_F     region_G     region_H     region_I     region_J     region_K     region_L     region_M     region_N     region_O     region_P     region_Q     region_R     region_S     region_T      unknown  duration_long  popularity_add_duration_ms  popularity_sub_duration_ms  popularity_mul_duration_ms  popularity_bigger_duration_ms  popularity_add_acousticness  popularity_sub_acousticness  popularity_mul_acousticness  popularity_bigger_acousticness  popularity_add_positiveness  popularity_sub_positiveness  popularity_mul_positiveness  popularity_bigger_positiveness  popularity_add_danceability  popularity_sub_danceability  popularity_mul_danceability  popularity_bigger_danceability  popularity_add_loudness  popularity_sub_loudness  \\\n",
       "count  4046.000000  4046.000000  4046.000000  4046.000000   4046.000000   4046.000000   4046.000000  4046.000000  4046.000000  4046.000000  4046.000000       4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000  4046.000000         4046.0                 4046.000000                 4046.000000                 4046.000000                     4046.00000                  4046.000000                  4046.000000                  4046.000000                     4046.000000                  4046.000000                  4046.000000                  4046.000000                     4046.000000                  4046.000000                  4046.000000                  4046.000000                     4046.000000              4046.000000              4046.000000   \n",
       "mean   2022.500000     7.281760     0.513847     0.427150      0.344084      0.468205      0.519770     0.644845     0.602985     0.234547     0.302811          0.173380   134.532130     0.003213     0.080326     0.020761     0.049184     0.175482     0.033613     0.014829     0.044736     0.185863     0.006179     0.056846     0.027929     0.000741     0.010875     0.034108     0.086258     0.008898     0.012358     0.014335     0.042017     0.091448            0.0                    0.218106                    0.225913                    0.218106                        0.68611                     0.184147                     0.310929                     0.184147                        0.711320                     0.245723                     0.266373                     0.245723                        0.552397                     0.276778                     0.221065                     0.276778                        0.478744                 0.330583                 0.249351   \n",
       "std    1168.123923     2.887542     0.211821     0.158453      0.283517      0.263596      0.223505     0.197972     0.243420     0.189897     0.182977          0.198511    30.432382     0.056600     0.271831     0.142602     0.216280     0.380426     0.180254     0.120885     0.206748     0.389044     0.078373     0.231577     0.164789     0.027223     0.103727     0.181528     0.280779     0.093919     0.110491     0.118883     0.200652     0.288281            0.0                    0.118272                    0.170918                    0.118272                        0.46413                     0.176562                     0.206620                     0.176562                        0.453205                     0.176793                     0.187577                     0.176793                        0.497308                     0.175172                     0.163030                     0.175172                        0.499610                 0.177945                 0.201425   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000      0.000000      0.000000     0.000000     0.000000     0.000000     0.000000          0.000000    40.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000            0.0                    0.000000                    0.000083                    0.000000                        0.00000                     0.000000                     0.000000                     0.000000                        0.000000                     0.000000                     0.000000                     0.000000                        0.000000                     0.000000                     0.000000                     0.000000                        0.000000                 0.000000                 0.000000   \n",
       "25%    1011.250000     7.000000     0.381579     0.344101      0.112032      0.247631      0.360279     0.538739     0.430235     0.114511     0.188647          0.081236   120.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000            0.0                    0.136452                    0.090067                    0.136452                        0.00000                     0.047082                     0.142144                     0.047082                        0.000000                     0.102787                     0.115260                     0.102787                        0.000000                     0.139244                     0.091270                     0.139244                        0.000000                 0.202091                 0.091588   \n",
       "50%    2022.500000     8.000000     0.526316     0.416620      0.231268      0.450772      0.529204     0.669539     0.639780     0.176306     0.268539          0.118155   120.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000            0.0                    0.213219                    0.191911                    0.213219                        1.00000                     0.119256                     0.284066                     0.119256                        1.000000                     0.214140                     0.235355                     0.214140                        1.000000                     0.261254                     0.191310                     0.261254                        0.000000                 0.321311                 0.198264   \n",
       "75%    3033.750000    10.000000     0.657895     0.500899      0.552802      0.680469      0.681067     0.786531     0.803927     0.298840     0.365878          0.161997   152.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000            0.0                    0.291503                    0.323598                    0.291503                        1.00000                     0.286462                     0.450938                     0.286462                        1.000000                     0.354333                     0.384544                     0.354333                        1.000000                     0.391773                     0.320822                     0.391773                        1.000000                 0.442422                 0.367092   \n",
       "max    4045.000000    10.000000     1.000000     1.000000      1.000000      1.000000      1.000000     1.000000     1.000000     1.000000     1.000000          1.000000   220.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000            0.0                    0.842548                    1.000000                    0.842548                        1.00000                     1.000000                     1.000000                     1.000000                        1.000000                     1.000000                     1.000000                     1.000000                        1.000000                     1.000000                     1.000000                     1.000000                        1.000000                 0.994298                 1.000000   \n",
       "\n",
       "       popularity_mul_loudness  popularity_bigger_loudness  popularity_add_energy  popularity_sub_energy  popularity_mul_energy  popularity_bigger_energy  popularity_add_liveness  popularity_sub_liveness  popularity_mul_liveness  popularity_bigger_liveness  popularity_add_speechiness  popularity_sub_speechiness  popularity_mul_speechiness  popularity_bigger_speechiness  popularity_add_instrumentalness  popularity_sub_instrumentalness  popularity_mul_instrumentalness  popularity_bigger_instrumentalness  popularity_add_tempo_int  popularity_sub_tempo_int  popularity_mul_tempo_int  popularity_bigger_tempo_int  duration_ms_add_acousticness  duration_ms_sub_acousticness  duration_ms_mul_acousticness  duration_ms_bigger_acousticness  duration_ms_add_positiveness  duration_ms_sub_positiveness  duration_ms_mul_positiveness  duration_ms_bigger_positiveness  duration_ms_add_danceability  duration_ms_sub_danceability  duration_ms_mul_danceability  duration_ms_bigger_danceability  \\\n",
       "count              4046.000000                 4046.000000            4046.000000            4046.000000            4046.000000               4046.000000              4046.000000              4046.000000              4046.000000                 4046.000000                 4046.000000                 4046.000000                 4046.000000                    4046.000000                      4046.000000                     4.046000e+03                      4046.000000                         4046.000000               4046.000000               4046.000000               4046.000000                       4046.0                   4046.000000                   4046.000000                   4046.000000                      4046.000000                   4046.000000                   4046.000000                   4046.000000                      4046.000000                   4046.000000                   4046.000000                   4046.000000                      4046.000000   \n",
       "mean                  0.330583                    0.319081               0.302921               0.283785               0.302921                  0.410776                 0.118140                 0.346472                 0.118140                    0.836876                    0.156906                    0.293550                    0.156906                       0.783490                         0.083207                     4.109695e-01                         0.083207                            0.880129                 69.041753                134.018283                 69.041753                          0.0                      0.142524                      0.291033                      0.142524                         0.650272                      0.193655                      0.270971                      0.193655                         0.452299                      0.219816                      0.239184                      0.219816                         0.335887   \n",
       "std                   0.177945                    0.466178               0.175564               0.212983               0.175564                  0.492035                 0.111015                 0.208924                 0.111015                    0.369525                    0.128539                    0.184631                    0.128539                       0.411917                         0.105046                     2.074966e-01                         0.105046                            0.324851                 33.178434                 30.435986                 33.178434                          0.0                      0.130122                      0.191248                      0.130122                         0.476943                      0.122890                      0.188448                      0.122890                         0.497781                      0.116641                      0.175579                      0.116641                         0.472358   \n",
       "min                   0.000000                    0.000000               0.000000               0.000048               0.000000                  0.000000                 0.000000                 0.000020                 0.000000                    0.000000                    0.000000                    0.000000                    0.000000                       0.000000                         0.000000                     1.110223e-16                         0.000000                            0.000000                  0.000000                 39.315789                  0.000000                          0.0                      0.000000                      0.000069                      0.000000                         0.000000                      0.000000                      0.000000                      0.000000                         0.000000                      0.000000                      0.000000                      0.000000                         0.000000   \n",
       "25%                   0.202091                    0.000000               0.171362               0.111318               0.171362                  0.000000                 0.048278                 0.173125                 0.048278                    1.000000                    0.076098                    0.147216                    0.076098                       1.000000                         0.033529                     2.607847e-01                         0.033529                            1.000000                 46.736842                119.263158                 46.736842                          0.0                      0.045592                      0.143632                      0.045592                         0.000000                      0.097291                      0.119057                      0.097291                         0.000000                      0.136692                      0.099277                      0.136692                         0.000000   \n",
       "50%                   0.321311                    0.000000               0.288772               0.235855               0.288772                  0.000000                 0.087411                 0.337764                 0.087411                    1.000000                    0.129447                    0.276081                    0.129447                       1.000000                         0.058362                     4.183971e-01                         0.058362                            1.000000                 66.947368                120.000000                 66.947368                          0.0                      0.096648                      0.268827                      0.096648                         1.000000                      0.177755                      0.243467                      0.177755                         0.000000                      0.215831                      0.207633                      0.215831                         0.000000   \n",
       "75%                   0.442422                    1.000000               0.415315               0.413706               0.415315                  1.000000                 0.150529                 0.494854                 0.150529                    1.000000                    0.200123                    0.419084                    0.200123                       1.000000                         0.090362                     5.562510e-01                         0.090362                            1.000000                 90.000000                151.592105                 90.000000                          0.0                      0.211466                      0.395884                      0.211466                         1.000000                      0.271606                      0.392424                      0.271606                         1.000000                      0.295211                      0.340277                      0.295211                         1.000000   \n",
       "max                   0.994298                    1.000000               0.921053               1.000000               0.921053                  1.000000                 0.890378                 0.973684                 0.890378                    1.000000                    1.000000                    1.000000                    1.000000                       1.000000                         1.000000                     1.000000e+00                         1.000000                            1.000000                208.000000                219.394737                208.000000                          0.0                      0.964195                      0.991171                      0.964195                         1.000000                      1.000000                      1.000000                      1.000000                         1.000000                      1.000000                      1.000000                      1.000000                         1.000000   \n",
       "\n",
       "       duration_ms_add_loudness  duration_ms_sub_loudness  duration_ms_mul_loudness  duration_ms_bigger_loudness  duration_ms_add_energy  duration_ms_sub_energy  duration_ms_mul_energy  duration_ms_bigger_energy  duration_ms_add_liveness  duration_ms_sub_liveness  duration_ms_mul_liveness  duration_ms_bigger_liveness  duration_ms_add_speechiness  duration_ms_sub_speechiness  duration_ms_mul_speechiness  duration_ms_bigger_speechiness  duration_ms_add_instrumentalness  duration_ms_sub_instrumentalness  duration_ms_mul_instrumentalness  duration_ms_bigger_instrumentalness  duration_ms_add_tempo_int  duration_ms_sub_tempo_int  duration_ms_mul_tempo_int  duration_ms_bigger_tempo_int  acousticness_add_positiveness  acousticness_sub_positiveness  acousticness_mul_positiveness  acousticness_bigger_positiveness  acousticness_add_danceability  acousticness_sub_danceability  acousticness_mul_danceability  acousticness_bigger_danceability  acousticness_add_loudness  acousticness_sub_loudness  \\\n",
       "count               4046.000000               4046.000000               4046.000000                  4046.000000             4046.000000             4046.000000             4046.000000                4046.000000               4046.000000               4046.000000               4046.000000                  4046.000000                  4046.000000                  4046.000000                  4046.000000                     4046.000000                       4046.000000                       4046.000000                       4046.000000                          4046.000000                4046.000000                4046.000000                4046.000000                        4046.0                    4046.000000                    4046.000000                    4046.000000                       4046.000000                    4046.000000                    4046.000000                    4046.000000                       4046.000000                4046.000000                4046.000000   \n",
       "mean                   0.276127                  0.279156                  0.276127                     0.175482                0.257328                0.278120                0.257328                   0.263964                  0.100435                  0.264279                  0.100435                     0.825754                     0.126811                     0.226689                     0.126811                        0.758774                          0.074069                          0.319594                          0.074069                             0.899654                  57.686709                 134.104981                  57.686709                           0.0                       0.147264                       0.367864                       0.147264                          0.338112                       0.175315                       0.348578                       0.175315                          0.283243                   0.193129                   0.457244   \n",
       "std                    0.132389                  0.179979                  0.132389                     0.380426                0.143747                0.195934                0.143747                   0.440835                  0.099274                  0.167078                  0.099274                     0.379368                     0.092797                     0.166497                     0.092797                        0.427880                          0.101604                          0.163536                          0.101604                             0.300498                  25.761500                  30.425518                  25.761500                           0.0                       0.144328                       0.240001                       0.144328                          0.473125                       0.158610                       0.216178                       0.158610                          0.450629                   0.153652                   0.241762   \n",
       "min                    0.000000                  0.000000                  0.000000                     0.000000                0.000000                0.000000                0.000000                   0.000000                  0.000000                  0.000000                  0.000000                     0.000000                     0.000000                     0.000114                     0.000000                        0.000000                          0.000000                          0.000068                          0.000000                             0.000000                   0.000000                  39.536055                   0.000000                           0.0                       0.000000                       0.000383                       0.000000                          0.000000                       0.000000                       0.000000                       0.000000                          0.000000                   0.000000                   0.000527   \n",
       "25%                    0.195963                  0.131727                  0.195963                     0.000000                0.163355                0.118178                0.163355                   0.000000                  0.042258                  0.137616                  0.042258                     1.000000                     0.068902                     0.101518                     0.068902                        1.000000                          0.029346                          0.218631                          0.029346                             1.000000                  41.097850                 119.424150                  41.097850                           0.0                       0.041032                       0.156502                       0.041032                          0.000000                       0.049354                       0.170186                       0.049354                          0.000000                   0.073740                   0.257468   \n",
       "50%                    0.274207                  0.261655                  0.274207                     0.000000                0.249894                0.251675                0.249894                   0.000000                  0.071491                  0.251516                  0.071491                     1.000000                     0.106001                     0.196904                     0.106001                        1.000000                          0.047157                          0.303938                          0.047157                             1.000000                  55.218718                 120.000000                  55.218718                           0.0                       0.101474                       0.345779                       0.101474                          0.000000                       0.127062                       0.336344                       0.127062                          0.000000                   0.142172                   0.479534   \n",
       "75%                    0.346241                  0.399855                  0.346241                     0.000000                0.336481                0.400162                0.336481                   1.000000                  0.122949                  0.358783                  0.122949                     1.000000                     0.158959                     0.312882                     0.158959                        1.000000                          0.071155                          0.399818                          0.071155                             1.000000                  70.558884                 151.638994                  70.558884                           0.0                       0.206809                       0.555424                       0.206809                          1.000000                       0.264396                       0.501269                       0.264396                          1.000000                   0.289657                   0.647301   \n",
       "max                    0.979616                  1.000000                  0.979616                     1.000000                0.944988                1.000000                0.944988                   1.000000                  1.000000                  0.999573                  1.000000                     1.000000                     0.943012                     1.000000                     0.943012                        1.000000                          0.945146                          1.000000                          0.945146                             1.000000                 192.000000                 219.659969                 192.000000                           0.0                       0.924222                       0.983985                       0.924222                          1.000000                       0.903439                       1.000000                       0.903439                          1.000000                   0.850599                   1.000000   \n",
       "\n",
       "       acousticness_mul_loudness  acousticness_bigger_loudness  acousticness_add_energy  acousticness_sub_energy  acousticness_mul_energy  acousticness_bigger_energy  acousticness_add_liveness  acousticness_sub_liveness  acousticness_mul_liveness  acousticness_bigger_liveness  acousticness_add_speechiness  acousticness_sub_speechiness  acousticness_mul_speechiness  acousticness_bigger_speechiness  acousticness_add_instrumentalness  acousticness_sub_instrumentalness  acousticness_mul_instrumentalness  acousticness_bigger_instrumentalness  acousticness_add_tempo_int  acousticness_sub_tempo_int  acousticness_mul_tempo_int  acousticness_bigger_tempo_int  positiveness_add_danceability  positiveness_sub_danceability  positiveness_mul_danceability  positiveness_bigger_danceability  positiveness_add_loudness  positiveness_sub_loudness  positiveness_mul_loudness  positiveness_bigger_loudness  positiveness_add_energy  positiveness_sub_energy  positiveness_mul_energy  \\\n",
       "count                4046.000000                   4046.000000              4046.000000              4046.000000              4046.000000                 4046.000000                4046.000000                4046.000000                4046.000000                   4046.000000                   4046.000000                  4.046000e+03                   4046.000000                      4046.000000                        4046.000000                        4046.000000                        4046.000000                           4046.000000                 4046.000000                 4046.000000                 4046.000000                         4046.0                    4046.000000                   4.046000e+03                    4046.000000                       4046.000000                4046.000000                4046.000000                4046.000000                   4046.000000              4046.000000              4046.000000              4046.000000   \n",
       "mean                    0.193129                      0.231340                 0.159125                 0.488242                 0.159125                    0.281513                   0.077056                   0.278478                   0.077056                      0.583292                      0.097219                  2.857788e-01                      0.097219                         0.475779                           0.057612                           0.287136                           0.057612                              0.707612                   45.212122                  134.188046                   45.212122                            0.0                       0.275900                   1.901843e-01                       0.275900                          0.420662                   0.310672                   0.284319                   0.310672                      0.290410                 0.302636                 0.253651                 0.302636   \n",
       "std                     0.153652                      0.421741                 0.116032                 0.254895                 0.116032                    0.449792                   0.101610                   0.241190                   0.101610                      0.493075                      0.099732                  2.186920e-01                      0.099732                         0.499475                           0.110195                           0.265631                           0.110195                              0.454916                   38.620157                   30.469120                   38.620157                            0.0                       0.222949                   1.442885e-01                       0.222949                          0.493726                   0.206497                   0.203762                   0.206497                      0.454008                 0.221479                 0.204724                 0.221479   \n",
       "min                     0.000000                      0.000000                 0.000000                 0.000777                 0.000000                    0.000000                   0.000000                   0.000111                   0.000000                      0.000000                      0.000000                  1.110223e-16                      0.000000                         0.000000                           0.000000                           0.000000                           0.000000                              0.000000                    0.000000                   39.008829                    0.000000                            0.0                       0.000000                   2.220446e-16                       0.000000                          0.000000                   0.000000                   0.000000                   0.000000                      0.000000                 0.000000                 0.000000                 0.000000   \n",
       "25%                     0.073740                      0.000000                 0.071866                 0.279791                 0.071866                    0.000000                   0.017826                   0.078114                   0.017826                      0.000000                      0.027142                  1.114441e-01                      0.027142                         0.000000                           0.011987                           0.063277                           0.011987                              0.000000                   14.881754                  119.222846                   14.881754                            0.0                       0.089038                   7.283262e-02                       0.089038                          0.000000                   0.144319                   0.116185                   0.144319                      0.000000                 0.110526                 0.094640                 0.110526   \n",
       "50%                     0.142172                      0.000000                 0.128386                 0.496785                 0.128386                    0.000000                   0.043985                   0.202985                   0.043985                      1.000000                      0.062335                  2.297548e-01                      0.062335                         0.000000                           0.027911                           0.178816                           0.027911                              1.000000                   30.994379                  119.999867                   30.994379                            0.0                       0.219348                   1.642473e-01                       0.219348                          0.000000                   0.284020                   0.253547                   0.284020                      0.000000                 0.270540                 0.204250                 0.270540   \n",
       "75%                     0.289657                      0.000000                 0.224519                 0.701533                 0.224519                    1.000000                   0.096891                   0.429181                   0.096891                      1.000000                      0.138556                  4.238117e-01                      0.138556                         1.000000                           0.065435                           0.488317                           0.065435                              1.000000                   69.179228                  151.885097                   69.179228                            0.0                       0.425962                   2.724867e-01                       0.425962                          1.000000                   0.453563                   0.419043                   0.453563                      1.000000                 0.461597                 0.355989                 0.461597   \n",
       "max                     0.850599                      1.000000                 0.732629                 1.000000                 0.732629                    1.000000                   0.930415                   0.978570                   0.930415                      1.000000                      1.000000                  9.929697e-01                      1.000000                         1.000000                           1.000000                           1.000000                           1.000000                              1.000000                  192.000000                  219.920696                  192.000000                            0.0                       1.000000                   8.496157e-01                       1.000000                          1.000000                   1.000000                   1.000000                   1.000000                      1.000000                 0.983583                 0.996306                 0.983583   \n",
       "\n",
       "       positiveness_bigger_energy  positiveness_add_liveness  positiveness_sub_liveness  positiveness_mul_liveness  positiveness_bigger_liveness  positiveness_add_speechiness  positiveness_sub_speechiness  positiveness_mul_speechiness  positiveness_bigger_speechiness  positiveness_add_instrumentalness  positiveness_sub_instrumentalness  positiveness_mul_instrumentalness  positiveness_bigger_instrumentalness  positiveness_add_tempo_int  positiveness_sub_tempo_int  positiveness_mul_tempo_int  positiveness_bigger_tempo_int  danceability_add_loudness  danceability_sub_loudness  danceability_mul_loudness  danceability_bigger_loudness  danceability_add_energy  danceability_sub_energy  danceability_mul_energy  danceability_bigger_energy  danceability_add_liveness  danceability_sub_liveness  danceability_mul_liveness  danceability_bigger_liveness  danceability_add_speechiness  danceability_sub_speechiness  danceability_mul_speechiness  danceability_bigger_speechiness  \\\n",
       "count                 4046.000000                4046.000000                4046.000000                4046.000000                   4046.000000                   4046.000000                  4.046000e+03                   4046.000000                      4046.000000                        4046.000000                        4046.000000                        4046.000000                           4046.000000                 4046.000000                 4046.000000                 4046.000000                         4046.0                4046.000000                4046.000000                4046.000000                   4046.000000              4046.000000              4046.000000              4046.000000                 4046.000000                4046.000000                4046.000000                4046.000000                   4046.000000                   4046.000000                   4046.000000                   4046.000000                      4046.000000   \n",
       "mean                     0.333169                   0.110767                   0.320527                   0.110767                      0.775828                      0.147390                  2.740896e-01                      0.147390                         0.686604                           0.068479                           0.393858                           0.068479                              0.845774                   63.412627                  134.063926                   63.412627                            0.0                   0.337171                   0.254669                   0.337171                      0.327731                 0.316844                 0.261004                 0.316844                    0.420662                   0.118520                   0.353719                   0.118520                      0.836629                      0.161451                      0.291194                      0.161451                         0.796342   \n",
       "std                      0.471404                   0.120210                   0.235560                   0.120210                      0.417087                      0.141108                  2.096513e-01                      0.141108                         0.463931                           0.076794                           0.257046                           0.076794                              0.361210                   39.656076                   30.419584                   39.656076                            0.0                   0.180932                   0.189530                   0.180932                      0.469444                 0.188037                 0.202809                 0.188037                    0.493726                   0.111282                   0.221408                   0.111282                      0.369750                      0.140969                      0.193860                      0.140969                         0.402767   \n",
       "min                      0.000000                   0.000000                   0.000051                   0.000000                      0.000000                      0.000000                  1.110223e-16                      0.000000                         0.000000                           0.000000                           0.000041                           0.000000                              0.000000                    0.000000                   39.541326                    0.000000                            0.0                   0.000000                   0.000000                   0.000000                      0.000000                 0.000000                 0.000036                 0.000000                    0.000000                   0.000000                   0.000098                   0.000000                      0.000000                      0.000000                      0.000000                      0.000000                         0.000000   \n",
       "25%                      0.000000                   0.033062                   0.121623                   0.033062                      1.000000                      0.051795                  1.028609e-01                      0.051795                         0.000000                           0.025680                           0.166071                           0.025680                              1.000000                   31.130009                  119.181118                   31.130009                            0.0                   0.201302                   0.105883                   0.201302                      0.000000                 0.163595                 0.099871                 0.163595                    0.000000                   0.046622                   0.168599                   0.046622                      1.000000                      0.073763                      0.128980                      0.073763                         1.000000   \n",
       "50%                      0.000000                   0.072399                   0.270036                   0.072399                      1.000000                      0.107557                  2.207003e-01                      0.107557                         1.000000                           0.049610                           0.374472                           0.049610                              1.000000                   58.639908                  120.000000                   58.639908                            0.0                   0.333621                   0.214249                   0.333621                      0.000000                 0.310338                 0.218462                 0.310338                    0.000000                   0.087306                   0.335220                   0.087306                      1.000000                      0.128148                      0.268584                      0.128148                         1.000000   \n",
       "75%                      1.000000                   0.141942                   0.495040                   0.141942                      1.000000                      0.196240                  4.103904e-01                      0.196240                         1.000000                           0.086508                           0.601704                           0.086508                              1.000000                   89.648462                  151.731522                   89.648462                            0.0                   0.459664                   0.366172                   0.459664                      1.000000                 0.453581                 0.372383                 0.453581                    1.000000                   0.152456                   0.511627                   0.152456                      1.000000                      0.201362                      0.425412                      0.201362                         1.000000   \n",
       "max                      1.000000                   0.926729                   1.000000                   0.926729                      1.000000                      1.000000                  1.000000e+00                      1.000000                         1.000000                           0.869862                           1.000000                           0.869862                              1.000000                  208.000000                  219.819983                  208.000000                            0.0                   1.000000                   1.000000                   1.000000                      1.000000                 0.954504                 1.000000                 0.954504                    1.000000                   0.959881                   1.000000                   0.959881                      1.000000                      1.000000                      1.000000                      1.000000                         1.000000   \n",
       "\n",
       "       danceability_add_instrumentalness  danceability_sub_instrumentalness  danceability_mul_instrumentalness  danceability_bigger_instrumentalness  danceability_add_tempo_int  danceability_sub_tempo_int  danceability_mul_tempo_int  danceability_bigger_tempo_int  loudness_add_energy  loudness_sub_energy  loudness_mul_energy  loudness_bigger_energy  loudness_add_liveness  loudness_sub_liveness  loudness_mul_liveness  loudness_bigger_liveness  loudness_add_speechiness  loudness_sub_speechiness  loudness_mul_speechiness  loudness_bigger_speechiness  loudness_add_instrumentalness  loudness_sub_instrumentalness  loudness_mul_instrumentalness  loudness_bigger_instrumentalness  loudness_add_tempo_int  loudness_sub_tempo_int  loudness_mul_tempo_int  loudness_bigger_tempo_int  energy_add_liveness  energy_sub_liveness  energy_mul_liveness  energy_bigger_liveness  energy_add_speechiness  energy_sub_speechiness  energy_mul_speechiness  energy_bigger_speechiness  energy_add_instrumentalness  \\\n",
       "count                        4046.000000                        4046.000000                        4046.000000                           4046.000000                 4046.000000                 4046.000000                 4046.000000                         4046.0          4046.000000          4046.000000          4046.000000             4046.000000            4046.000000            4046.000000            4046.000000               4046.000000               4046.000000               4046.000000               4046.000000                  4046.000000                    4046.000000                    4046.000000                    4046.000000                       4046.000000             4046.000000             4046.000000             4046.000000                     4046.0          4046.000000          4046.000000          4046.000000             4046.000000             4046.000000            4.046000e+03             4046.000000                4046.000000                  4046.000000   \n",
       "mean                            0.078199                           0.428699                           0.078199                              0.886802                   69.358547                  134.012361                   69.358547                            0.0             0.421535             0.148117             0.421535                0.580326               0.153282               0.442677               0.153282                  0.915472                  0.199755                  0.377407                  0.199755                     0.895947                       0.108233                       0.512521                       0.108233                          0.924864               87.369172              133.887285               87.369172                        0.0             0.148519             0.406282             0.148519                0.892486                0.191223            3.500123e-01                0.191223                   0.846762                     0.105382   \n",
       "std                             0.083538                           0.222243                           0.083538                              0.316874                   32.349596                   30.451838                   32.349596                            0.0             0.231726             0.113281             0.231726                0.493567               0.138462               0.208700               0.138462                  0.278212                  0.145260                  0.195547                  0.145260                     0.305368                       0.135942                       0.212915                       0.135942                          0.263643               34.562145               30.412747               34.562145                        0.0             0.150619             0.227603             0.150619                0.309803                0.155064            2.074911e-01                0.155064                   0.360261                     0.144796   \n",
       "min                             0.000000                           0.000243                           0.000000                              0.000000                    0.000000                   39.428007                    0.000000                            0.0             0.000000             0.000000             0.000000                0.000000               0.000000               0.000000               0.000000                  0.000000                  0.000000                  0.000464                  0.000000                     0.000000                       0.000000                       0.000000                       0.000000                          0.000000                0.000000               39.000000                0.000000                        0.0             0.000000             0.000000             0.000000                0.000000                0.000000            1.110223e-16                0.000000                   0.000000                     0.000000   \n",
       "25%                             0.033438                           0.256558                           0.033438                              1.000000                   46.011410                  119.165270                   46.011410                            0.0             0.242391             0.058992             0.242391                0.000000               0.063933               0.294177               0.063933                  1.000000                  0.104968                  0.226763                  0.104968                     1.000000                       0.045919                       0.383698                       0.045919                          1.000000               63.963271              119.148078               63.963271                        0.0             0.051649             0.215484             0.051649                1.000000                0.082000            1.715020e-01                0.082000                   1.000000                     0.037986   \n",
       "50%                             0.058592                           0.436518                           0.058592                              1.000000                   69.666718                  119.908753                   69.666718                            0.0             0.427004             0.124596             0.427004                1.000000               0.111542               0.457065               0.111542                  1.000000                  0.168446                  0.382508                  0.168446                     1.000000                       0.074689                       0.541665                       0.074689                          1.000000               86.608177              120.000000               86.608177                        0.0             0.098888             0.413849             0.098888                1.000000                0.152638            3.484550e-01                0.152638                   1.000000                     0.068132   \n",
       "75%                             0.091436                           0.586747                           0.091436                              1.000000                   91.771233                  151.588363                   91.771233                            0.0             0.597281             0.212057             0.597281                1.000000               0.197337               0.598561               0.197337                  1.000000                  0.254018                  0.521563                  0.254018                     1.000000                       0.109277                       0.667130                       0.109277                          1.000000              111.105095              151.417215              111.105095                        0.0             0.191518             0.585308             0.191518                1.000000                0.254482            5.071929e-01                0.254482                   1.000000                     0.105648   \n",
       "max                             0.811908                           1.000000                           0.811908                              1.000000                  185.130503                  219.796370                  185.130503                            0.0             1.000000             0.808457             1.000000                1.000000               1.000000               0.959834               1.000000                  1.000000                  0.946596                  0.991962                  0.946596                     1.000000                       1.000000                       1.000000                       1.000000                          1.000000              208.000000              219.786776              208.000000                        0.0             1.000000             0.998358             1.000000                1.000000                1.000000            1.000000e+00                1.000000                   1.000000                     0.989612   \n",
       "\n",
       "       energy_sub_instrumentalness  energy_mul_instrumentalness  energy_bigger_instrumentalness  energy_add_tempo_int  energy_sub_tempo_int  energy_mul_tempo_int  energy_bigger_tempo_int  liveness_add_speechiness  liveness_sub_speechiness  liveness_mul_speechiness  liveness_bigger_speechiness  liveness_add_instrumentalness  liveness_sub_instrumentalness  liveness_mul_instrumentalness  liveness_bigger_instrumentalness  liveness_add_tempo_int  liveness_sub_tempo_int  liveness_mul_tempo_int  liveness_bigger_tempo_int  speechiness_add_instrumentalness  speechiness_sub_instrumentalness  speechiness_mul_instrumentalness  speechiness_bigger_instrumentalness  speechiness_add_tempo_int  speechiness_sub_tempo_int  speechiness_mul_tempo_int  speechiness_bigger_tempo_int  instrumentalness_add_tempo_int  instrumentalness_sub_tempo_int  instrumentalness_mul_tempo_int  instrumentalness_bigger_tempo_int          PCA1          PCA2          PCA3          PCA4          PCA5          PCA6  \\\n",
       "count                  4046.000000                  4046.000000                     4046.000000           4046.000000           4046.000000           4046.000000                   4046.0               4046.000000               4046.000000               4046.000000                  4046.000000                    4046.000000                    4046.000000                    4046.000000                       4046.000000             4046.000000             4046.000000             4046.000000                     4046.0                       4046.000000                       4046.000000                       4046.000000                          4046.000000                4046.000000                4046.000000                4046.000000                        4046.0                     4046.000000                     4046.000000                     4046.000000                             4046.0  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03   \n",
       "mean                      0.473166                     0.105382                        0.909540             82.262444            133.929145             82.262444                      0.0                  0.076055                  0.187455                  0.076055                     0.339595                       0.040346                       0.188380                       0.040346                          0.663618               31.600806              134.297583               31.600806                        0.0                          0.052525                          0.225200                          0.052525                             0.798319                  40.541308                 134.229319                  40.541308                           0.0                       23.368508                      134.358750                       23.368508                                0.0 -7.305630e-15  9.328727e-15 -1.770210e-15 -9.300629e-15 -1.152042e-15  6.434574e-15   \n",
       "std                       0.240106                     0.144796                        0.286875             39.976250             30.395813             39.976250                      0.0                  0.097270                  0.170262                  0.097270                     0.473630                       0.065540                       0.210606                       0.065540                          0.472530               27.524141               30.431441               27.524141                        0.0                          0.075072                          0.197153                          0.075072                             0.401305                  26.715474                  30.439390                  26.715474                           0.0                       27.999528                       30.431607                       27.999528                                0.0  1.229942e+02  6.944027e+01  5.914307e+01  4.036015e+01  3.862141e+01  3.661330e+01   \n",
       "min                       0.000249                     0.000000                        0.000000              0.000000             39.051619              0.000000                      0.0                  0.000000                  0.000073                  0.000000                     0.000000                       0.000000                       0.000000                       0.000000                          0.000000                0.000000               39.252893                0.000000                        0.0                          0.000000                          0.000061                          0.000000                             0.000000                   0.000000                  39.484971                   0.000000                           0.0                        0.000000                       39.000000                        0.000000                                0.0 -3.886720e+02 -1.110692e+02 -1.714855e+02 -1.279318e+02 -1.153427e+02 -1.212453e+02   \n",
       "25%                       0.287673                     0.037986                        1.000000             53.337285            119.124830             53.337285                      0.0                  0.023409                  0.065124                  0.023409                     0.000000                       0.010843                       0.048077                       0.010843                          0.000000               14.301250              119.568107               14.301250                        0.0                          0.017337                          0.086097                          0.017337                             1.000000                  23.744005                 119.556523                  23.744005                           0.0                       10.039664                      119.781870                       10.039664                                0.0 -9.573937e+01 -5.267799e+01 -4.116510e+01 -2.557952e+01 -2.306539e+01 -2.081497e+01   \n",
       "50%                       0.497452                     0.068132                        1.000000             81.615860            120.000000             81.615860                      0.0                  0.046320                  0.141486                  0.046320                     0.000000                       0.020820                       0.107832                       0.020820                          1.000000               23.646902              120.000000               23.646902                        0.0                          0.030980                          0.169710                          0.030980                             1.000000                  34.919424                 120.000000                  34.919424                           0.0                       15.350679                      120.000000                       15.350679                                0.0 -7.027652e+00 -1.863096e+01 -2.670537e+00 -3.057021e-01 -4.507955e+00 -4.809670e+00   \n",
       "75%                       0.668790                     0.105648                        1.000000            109.706306            151.508957            109.706306                      0.0                  0.089521                  0.248982                  0.089521                     1.000000                       0.040574                       0.246925                       0.040574                          1.000000               39.556622              151.874841               39.556622                        0.0                          0.053466                          0.290306                          0.053466                             1.000000                  50.178558                 151.805970                  50.178558                           0.0                       22.498492                      151.912237                       22.498492                                0.0  8.784358e+01  4.023905e+01  3.376015e+01  2.556389e+01  1.621593e+01  1.294016e+01   \n",
       "max                       1.000000                     0.989612                        1.000000            218.918515            220.000000            218.918515                      0.0                  0.996113                  0.966270                  0.996113                     1.000000                       0.827783                       1.000000                       0.827783                          1.000000              208.000000              219.837625              208.000000                        0.0                          0.826666                          1.000000                          0.826666                             1.000000                 220.000000                 219.823937                 220.000000                           0.0                      208.000000                      219.980909                      208.000000                                0.0  4.304270e+02  3.449739e+02  2.763462e+02  1.563338e+02  2.663832e+02  2.390963e+02   \n",
       "\n",
       "               PCA7          PCA8          PCA9         PCA10         PCA11         PCA12         PCA13         PCA14         PCA15         PCA16         PCA17         PCA18         PCA19         PCA20         PCA21         PCA22         PCA23         PCA24         PCA25         PCA26         PCA27         PCA28         PCA29         PCA30  \n",
       "count  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  4.046000e+03  \n",
       "mean   8.766756e-15 -3.989998e-15  5.451124e-15  1.208239e-15  1.494844e-14  3.108405e-16 -1.134590e-15 -1.352244e-15  3.093039e-16 -1.467712e-15 -1.714891e-15  3.195115e-16 -6.058755e-17  1.028452e-16 -2.138126e-16  6.717316e-17 -1.475175e-16  1.016817e-15  3.354267e-16  7.711742e-16  4.814076e-16  8.848856e-16 -4.978716e-16  2.651803e-16  \n",
       "std    3.322180e+01  3.291647e+01  2.848274e+01  2.650752e+01  2.075149e+01  5.450737e-01  4.932492e-01  4.426273e-01  4.275965e-01  4.225538e-01  4.101197e-01  3.867268e-01  3.791355e-01  3.720030e-01  3.661723e-01  3.503816e-01  3.402042e-01  3.324740e-01  3.286413e-01  3.248159e-01  3.194684e-01  3.113954e-01  3.056855e-01  2.999086e-01  \n",
       "min   -1.260679e+02 -1.295030e+02 -1.113049e+02 -1.142452e+02 -9.613118e+01 -1.812536e+00 -1.870845e+00 -1.438806e+00 -1.155813e+00 -1.403131e+00 -1.452708e+00 -1.126972e+00 -1.424939e+00 -8.547488e-01 -1.077573e+00 -1.389176e+00 -1.247187e+00 -1.361196e+00 -1.263367e+00 -1.177883e+00 -1.231024e+00 -1.297213e+00 -1.228253e+00 -1.037534e+00  \n",
       "25%   -2.058495e+01 -1.865693e+01 -1.827341e+01 -1.564752e+01 -1.344180e+01 -3.688912e-01 -3.327176e-01 -2.930228e-01 -2.634863e-01 -2.864660e-01 -2.780524e-01 -2.693093e-01 -2.457235e-01 -2.996339e-01 -2.576071e-01 -2.326647e-01 -2.327916e-01 -2.175430e-01 -2.185583e-01 -2.198702e-01 -2.122103e-01 -2.043557e-01 -1.986672e-01 -1.768900e-01  \n",
       "50%   -9.958473e-01 -7.483429e-01 -7.272713e-01 -3.050716e-02 -4.089575e-01 -6.236360e-03 -4.672502e-03  5.274793e-03 -3.501363e-02  9.163934e-03 -1.182609e-02 -2.075138e-02  2.499268e-03 -1.329774e-01 -2.439341e-02 -1.437039e-02 -2.850868e-03 -9.849603e-03 -7.281657e-03 -2.393234e-03 -6.127750e-04  1.215520e-02  2.546144e-03 -1.729942e-02  \n",
       "75%    1.963346e+01  1.722486e+01  1.721280e+01  1.568059e+01  1.271048e+01  3.658082e-01  3.164830e-01  3.061084e-01  2.513082e-01  2.927919e-01  2.772060e-01  2.619235e-01  2.631090e-01  3.909325e-01  2.401957e-01  2.267318e-01  2.256634e-01  2.128364e-01  2.163098e-01  2.178044e-01  2.031693e-01  2.106144e-01  1.970278e-01  1.599871e-01  \n",
       "max    2.057707e+02  1.808422e+02  1.812115e+02  1.327488e+02  1.350540e+02  2.253403e+00  3.181155e+00  2.225019e+00  1.337326e+00  1.553355e+00  1.570804e+00  1.551564e+00  1.609956e+00  1.003781e+00  1.310329e+00  1.642654e+00  1.276857e+00  1.632823e+00  1.444511e+00  1.790409e+00  1.378429e+00  1.535372e+00  1.258885e+00  1.225825e+00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df_train.columns if col not in [Config.row_id, Config.target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool値をintに変換\n",
    "col_list = [col for col in df_train.columns if df_train[col].dtypes == bool]\n",
    "\n",
    "for df in [df_train, df_test]:\n",
    "    df[col_list] = df[col_list] * 1\n",
    "\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4046, 283)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test[features]\n",
    "\n",
    "'''\n",
    "for c in TARGET_ENCODING_CATEGORY:\n",
    "    data_tmp = pd.DataFrame({c: df_train[c], 'target': df_train[TARGET]})\n",
    "    target_mean = data_tmp.groupby(c)['target'].mean()\n",
    "    X_test.loc[:, c] = X_test[c].map(target_mean)\n",
    "'''\n",
    "\n",
    "X_test = (X_test.values).astype(np.float32)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron\n",
    "- 隠れ層3層のMLP\n",
    "- kernel_initializerにHeの初期化を採用\n",
    "- Batch Normalizationを採用\n",
    "- 活性化関数にReLUを採用\n",
    "- Optimizerを採用（SGD、Adamなど。）\n",
    "- Dropoutを採用\n",
    "  - DropoutとBatchNormalizationを同時に使うと学習がうまくできない場合がある。\n",
    "  - その場合、Dropoutを外す\n",
    "- モデルの順序は、BatchNormalization、活性化関数、Dropoutであることに注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.sqrt(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true)))\n",
    "\n",
    "def setup_model():\n",
    "    activation = 'relu'\n",
    "    kernel_initializer = 'he_normal'\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(192, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(128, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(64, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(32, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "    # optimizer = optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "    # model.compile(optimizer=optimizer, loss=root_mean_squared_error, metrics=[root_mean_squared_error])\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_crossentropy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_callbacks():\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, patience=5, verbose=1)\n",
    "    callbacks = [es, lr]\n",
    "\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "mlp_param = {\n",
    "    'epochs': 300,\n",
    "    'batch_size': 100,\n",
    "    'verbose': 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation with TargetEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 283 features...\n",
      "Epoch 1/300\n",
      "118/118 [==============================] - 2s 8ms/step - loss: 1.5692 - categorical_crossentropy: 1.5692 - val_loss: 2.9320 - val_categorical_crossentropy: 2.9320 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.2697 - categorical_crossentropy: 1.2697 - val_loss: 1.8301 - val_categorical_crossentropy: 1.8301 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.1144 - categorical_crossentropy: 1.1144 - val_loss: 1.8781 - val_categorical_crossentropy: 1.8781 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.0144 - categorical_crossentropy: 1.0144 - val_loss: 1.7091 - val_categorical_crossentropy: 1.7091 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.9694 - categorical_crossentropy: 0.9694 - val_loss: 1.8598 - val_categorical_crossentropy: 1.8598 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.9158 - categorical_crossentropy: 0.9158 - val_loss: 1.8810 - val_categorical_crossentropy: 1.8810 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.8410 - categorical_crossentropy: 0.8410 - val_loss: 1.6324 - val_categorical_crossentropy: 1.6324 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.8229 - categorical_crossentropy: 0.8229 - val_loss: 1.7926 - val_categorical_crossentropy: 1.7926 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.7923 - categorical_crossentropy: 0.7923 - val_loss: 2.4155 - val_categorical_crossentropy: 2.4155 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.7779 - categorical_crossentropy: 0.7779 - val_loss: 1.7569 - val_categorical_crossentropy: 1.7569 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.7181 - categorical_crossentropy: 0.7181 - val_loss: 1.7611 - val_categorical_crossentropy: 1.7611 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "113/118 [===========================>..] - ETA: 0s - loss: 0.7169 - categorical_crossentropy: 0.7169\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.006999999843537807.\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.7175 - categorical_crossentropy: 0.7175 - val_loss: 1.8936 - val_categorical_crossentropy: 1.8936 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.6341 - categorical_crossentropy: 0.6341 - val_loss: 1.5769 - val_categorical_crossentropy: 1.5769 - lr: 0.0070\n",
      "Epoch 14/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6046 - categorical_crossentropy: 0.6046 - val_loss: 1.6003 - val_categorical_crossentropy: 1.6003 - lr: 0.0070\n",
      "Epoch 15/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.5933 - categorical_crossentropy: 0.5933 - val_loss: 1.5658 - val_categorical_crossentropy: 1.5658 - lr: 0.0070\n",
      "Epoch 16/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5727 - categorical_crossentropy: 0.5727 - val_loss: 1.7517 - val_categorical_crossentropy: 1.7517 - lr: 0.0070\n",
      "Epoch 17/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5583 - categorical_crossentropy: 0.5583 - val_loss: 1.6730 - val_categorical_crossentropy: 1.6730 - lr: 0.0070\n",
      "Epoch 18/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5585 - categorical_crossentropy: 0.5585 - val_loss: 1.5893 - val_categorical_crossentropy: 1.5893 - lr: 0.0070\n",
      "Epoch 19/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5239 - categorical_crossentropy: 0.5239 - val_loss: 1.7023 - val_categorical_crossentropy: 1.7023 - lr: 0.0070\n",
      "Epoch 20/300\n",
      "116/118 [============================>.] - ETA: 0s - loss: 0.5369 - categorical_crossentropy: 0.5369\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.004899999825283885.\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5374 - categorical_crossentropy: 0.5374 - val_loss: 1.6507 - val_categorical_crossentropy: 1.6507 - lr: 0.0070\n",
      "Epoch 21/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4817 - categorical_crossentropy: 0.4817 - val_loss: 1.6577 - val_categorical_crossentropy: 1.6577 - lr: 0.0049\n",
      "Epoch 22/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4587 - categorical_crossentropy: 0.4587 - val_loss: 1.6412 - val_categorical_crossentropy: 1.6412 - lr: 0.0049\n",
      "Epoch 23/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4424 - categorical_crossentropy: 0.4424 - val_loss: 1.7493 - val_categorical_crossentropy: 1.7493 - lr: 0.0049\n",
      "Epoch 24/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4366 - categorical_crossentropy: 0.4366 - val_loss: 1.6669 - val_categorical_crossentropy: 1.6669 - lr: 0.0049\n",
      "Epoch 25/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4399 - categorical_crossentropy: 0.4399 - val_loss: 1.5585 - val_categorical_crossentropy: 1.5585 - lr: 0.0049\n",
      "Epoch 26/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4295 - categorical_crossentropy: 0.4295 - val_loss: 1.8851 - val_categorical_crossentropy: 1.8851 - lr: 0.0049\n",
      "Epoch 27/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4108 - categorical_crossentropy: 0.4108 - val_loss: 1.6579 - val_categorical_crossentropy: 1.6579 - lr: 0.0049\n",
      "Epoch 28/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4035 - categorical_crossentropy: 0.4035 - val_loss: 1.6823 - val_categorical_crossentropy: 1.6823 - lr: 0.0049\n",
      "Epoch 29/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4094 - categorical_crossentropy: 0.4094 - val_loss: 1.7124 - val_categorical_crossentropy: 1.7124 - lr: 0.0049\n",
      "Epoch 30/300\n",
      "115/118 [============================>.] - ETA: 0s - loss: 0.4017 - categorical_crossentropy: 0.4017\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0034300000406801696.\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4020 - categorical_crossentropy: 0.4020 - val_loss: 1.7191 - val_categorical_crossentropy: 1.7191 - lr: 0.0049\n",
      "Epoch 31/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3642 - categorical_crossentropy: 0.3642 - val_loss: 1.6398 - val_categorical_crossentropy: 1.6398 - lr: 0.0034\n",
      "Epoch 32/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3604 - categorical_crossentropy: 0.3604 - val_loss: 1.7436 - val_categorical_crossentropy: 1.7436 - lr: 0.0034\n",
      "Epoch 33/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3548 - categorical_crossentropy: 0.3548 - val_loss: 1.7370 - val_categorical_crossentropy: 1.7370 - lr: 0.0034\n",
      "Epoch 34/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3536 - categorical_crossentropy: 0.3536 - val_loss: 1.7764 - val_categorical_crossentropy: 1.7764 - lr: 0.0034\n",
      "Epoch 35/300\n",
      "108/118 [==========================>...] - ETA: 0s - loss: 0.3368 - categorical_crossentropy: 0.3368\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.002401000028476119.\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3378 - categorical_crossentropy: 0.3378 - val_loss: 1.7188 - val_categorical_crossentropy: 1.7188 - lr: 0.0034\n",
      "Epoch 00035: early stopping\n",
      "================================== training 1 fin. ==================================\n",
      "================================== validation-data predicting ... ==================================\n",
      "================================== test-data predicting ... ==================================\n",
      "Fold 1 CV result\n",
      "metric : 0.36272237466195895\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 283 features...\n",
      "Epoch 1/300\n",
      "118/118 [==============================] - 2s 8ms/step - loss: 1.5414 - categorical_crossentropy: 1.5414 - val_loss: 2.9844 - val_categorical_crossentropy: 2.9844 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.2090 - categorical_crossentropy: 1.2090 - val_loss: 2.3119 - val_categorical_crossentropy: 2.3119 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.0905 - categorical_crossentropy: 1.0905 - val_loss: 2.2254 - val_categorical_crossentropy: 2.2254 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.9978 - categorical_crossentropy: 0.9978 - val_loss: 1.9193 - val_categorical_crossentropy: 1.9193 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.9423 - categorical_crossentropy: 0.9423 - val_loss: 1.9258 - val_categorical_crossentropy: 1.9258 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.9084 - categorical_crossentropy: 0.9084 - val_loss: 2.2489 - val_categorical_crossentropy: 2.2489 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.8617 - categorical_crossentropy: 0.8617 - val_loss: 1.8827 - val_categorical_crossentropy: 1.8827 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.8124 - categorical_crossentropy: 0.8124 - val_loss: 1.9379 - val_categorical_crossentropy: 1.9379 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.7962 - categorical_crossentropy: 0.7962 - val_loss: 1.9582 - val_categorical_crossentropy: 1.9582 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.7498 - categorical_crossentropy: 0.7498 - val_loss: 1.9504 - val_categorical_crossentropy: 1.9504 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.7136 - categorical_crossentropy: 0.7136 - val_loss: 1.8012 - val_categorical_crossentropy: 1.8012 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.6953 - categorical_crossentropy: 0.6953 - val_loss: 1.8220 - val_categorical_crossentropy: 1.8220 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.6768 - categorical_crossentropy: 0.6768 - val_loss: 1.8610 - val_categorical_crossentropy: 1.8610 - lr: 0.0100\n",
      "Epoch 14/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.6526 - categorical_crossentropy: 0.6526 - val_loss: 1.7698 - val_categorical_crossentropy: 1.7698 - lr: 0.0100\n",
      "Epoch 15/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6330 - categorical_crossentropy: 0.6330 - val_loss: 1.7724 - val_categorical_crossentropy: 1.7724 - lr: 0.0100\n",
      "Epoch 16/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.6122 - categorical_crossentropy: 0.6122 - val_loss: 2.0581 - val_categorical_crossentropy: 2.0581 - lr: 0.0100\n",
      "Epoch 17/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.5918 - categorical_crossentropy: 0.5918 - val_loss: 1.7523 - val_categorical_crossentropy: 1.7523 - lr: 0.0100\n",
      "Epoch 18/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.5804 - categorical_crossentropy: 0.5804 - val_loss: 2.1339 - val_categorical_crossentropy: 2.1339 - lr: 0.0100\n",
      "Epoch 19/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5691 - categorical_crossentropy: 0.5691 - val_loss: 1.9157 - val_categorical_crossentropy: 1.9157 - lr: 0.0100\n",
      "Epoch 20/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.5530 - categorical_crossentropy: 0.5530 - val_loss: 1.9180 - val_categorical_crossentropy: 1.9180 - lr: 0.0100\n",
      "Epoch 21/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5302 - categorical_crossentropy: 0.5302 - val_loss: 1.8440 - val_categorical_crossentropy: 1.8440 - lr: 0.0100\n",
      "Epoch 22/300\n",
      "111/118 [===========================>..] - ETA: 0s - loss: 0.5260 - categorical_crossentropy: 0.5260\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.006999999843537807.\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.5315 - categorical_crossentropy: 0.5315 - val_loss: 1.9644 - val_categorical_crossentropy: 1.9644 - lr: 0.0100\n",
      "Epoch 23/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4725 - categorical_crossentropy: 0.4725 - val_loss: 1.8470 - val_categorical_crossentropy: 1.8470 - lr: 0.0070\n",
      "Epoch 24/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4453 - categorical_crossentropy: 0.4453 - val_loss: 1.9013 - val_categorical_crossentropy: 1.9013 - lr: 0.0070\n",
      "Epoch 25/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.4478 - categorical_crossentropy: 0.4478 - val_loss: 1.9179 - val_categorical_crossentropy: 1.9179 - lr: 0.0070\n",
      "Epoch 26/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4468 - categorical_crossentropy: 0.4468 - val_loss: 1.9306 - val_categorical_crossentropy: 1.9306 - lr: 0.0070\n",
      "Epoch 27/300\n",
      "115/118 [============================>.] - ETA: 0s - loss: 0.4384 - categorical_crossentropy: 0.4384\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.004899999825283885.\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4401 - categorical_crossentropy: 0.4401 - val_loss: 1.8583 - val_categorical_crossentropy: 1.8583 - lr: 0.0070\n",
      "Epoch 00027: early stopping\n",
      "================================== training 2 fin. ==================================\n",
      "================================== validation-data predicting ... ==================================\n",
      "================================== test-data predicting ... ==================================\n",
      "Fold 2 CV result\n",
      "metric : 0.3040569388965244\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 283 features...\n",
      "Epoch 1/300\n",
      "118/118 [==============================] - 2s 8ms/step - loss: 1.5588 - categorical_crossentropy: 1.5588 - val_loss: 2.3545 - val_categorical_crossentropy: 2.3545 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.2570 - categorical_crossentropy: 1.2570 - val_loss: 2.1804 - val_categorical_crossentropy: 2.1804 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.1164 - categorical_crossentropy: 1.1164 - val_loss: 2.2440 - val_categorical_crossentropy: 2.2440 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.0162 - categorical_crossentropy: 1.0162 - val_loss: 1.7153 - val_categorical_crossentropy: 1.7153 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.9571 - categorical_crossentropy: 0.9571 - val_loss: 1.7519 - val_categorical_crossentropy: 1.7519 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.9023 - categorical_crossentropy: 0.9023 - val_loss: 1.8056 - val_categorical_crossentropy: 1.8056 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.8583 - categorical_crossentropy: 0.8583 - val_loss: 1.9415 - val_categorical_crossentropy: 1.9415 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.8229 - categorical_crossentropy: 0.8229 - val_loss: 1.8365 - val_categorical_crossentropy: 1.8365 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "113/118 [===========================>..] - ETA: 0s - loss: 0.7796 - categorical_crossentropy: 0.7796\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.006999999843537807.\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.7784 - categorical_crossentropy: 0.7784 - val_loss: 1.8606 - val_categorical_crossentropy: 1.8606 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.7017 - categorical_crossentropy: 0.7017 - val_loss: 1.7513 - val_categorical_crossentropy: 1.7513 - lr: 0.0070\n",
      "Epoch 11/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.6675 - categorical_crossentropy: 0.6675 - val_loss: 1.8753 - val_categorical_crossentropy: 1.8753 - lr: 0.0070\n",
      "Epoch 12/300\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6514 - categorical_crossentropy: 0.6514 - val_loss: 1.7275 - val_categorical_crossentropy: 1.7275 - lr: 0.0070\n",
      "Epoch 13/300\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.6314 - categorical_crossentropy: 0.6314 - val_loss: 1.8511 - val_categorical_crossentropy: 1.8511 - lr: 0.0070\n",
      "Epoch 14/300\n",
      "115/118 [============================>.] - ETA: 0s - loss: 0.6238 - categorical_crossentropy: 0.6238\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.004899999825283885.\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6263 - categorical_crossentropy: 0.6263 - val_loss: 1.8030 - val_categorical_crossentropy: 1.8030 - lr: 0.0070\n",
      "Epoch 00014: early stopping\n",
      "================================== training 3 fin. ==================================\n",
      "================================== validation-data predicting ... ==================================\n",
      "================================== test-data predicting ... ==================================\n",
      "Fold 3 CV result\n",
      "metric : 0.3077107608299379\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 283 features...\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qr/28b40stn0vvfvznrz793zqgw0000gn/T/ipykernel_25144/2089026365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'================================== training {fold+1} fin. =================================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    956\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 780\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    781\u001b[0m             *args, **kwds))\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3155\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3157\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3390\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3392\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3393\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1119\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    463\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    869\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2890\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2892\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3693\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3694\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3695\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    814\u001b[0m           'and therefore expects target data to be passed in `fit()`.')\n\u001b[1;32m    815\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;31m# Collect metrics to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m--> 530\u001b[0;31m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[1;32m    531\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0m_ShapesFullySpecifiedAndEqual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       grad.dtype in (dtypes.int32, dtypes.float32)):\n\u001b[0;32m-> 1373\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" vs. \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6587\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6588\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6589\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   6590\u001b[0m         \"Mul\", x=x, y=y, name=name)\n\u001b[1;32m   6591\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    745\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3704\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3706\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3707\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3785\u001b[0m     \u001b[0;31m# and is independent of the op's _class attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3787\u001b[0;31m     \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_code_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_snapshot_colocation_stack_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3788\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_snapshot_colocation_stack_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_snapshot_colocation_stack_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5305\u001b[0m     \u001b[0;34m\"\"\"Return colocation stack metadata as a dictionary.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5306\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m   5307\u001b[0m         \u001b[0mtraceable_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraceable_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtraceable_obj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_traceable_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(Config.random_seed)\n",
    "tf.random.set_seed(Config.random_seed)\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros((len(df_test), Config.n_folds))\n",
    "\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(df_train))\n",
    "\n",
    "feature_importance_df = pd.DataFrame(index=features)\n",
    "y_valids, val_preds =[],[]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=Config.n_folds, shuffle=True, random_state=Config.random_seed)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(df_train, df_train[Config.target])):\n",
    "\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold+1} with {len(features)} features...')\n",
    "\n",
    "    X_train, X_val = df_train[features].iloc[train_idx], df_train[features].iloc[valid_idx]\n",
    "    y_train, y_val = df_train[Config.target].iloc[train_idx], df_train[Config.target].iloc[valid_idx]\n",
    "\n",
    "    # Over Sampling\n",
    "    sm = SMOTE(random_state=Config.random_seed)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    # print(y_train.value_counts())\n",
    "\n",
    "    dummy_y_train = np_utils.to_categorical(y_train)\n",
    "    dummy_y_val = np_utils.to_categorical(y_val)\n",
    "\n",
    "    # training\n",
    "    model = setup_model()\n",
    "    callbacks = setup_callbacks()\n",
    "    hist = model.fit(X_train, dummy_y_train, validation_data=(X_val, dummy_y_val), epochs=mlp_param['epochs'], batch_size=mlp_param['batch_size'], callbacks=callbacks, verbose=mlp_param['verbose'])\n",
    "\n",
    "    print(f'================================== training {fold+1} fin. ==================================')\n",
    "\n",
    "    # Predict validation data\n",
    "    print(f'================================== validation-data predicting ... ==================================')\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_pred = np.argmax(val_pred, axis=1)\n",
    "    oof_predictions[valid_idx] = val_pred\n",
    "\n",
    "    # Predict test data\n",
    "    print(f'================================== test-data predicting ... ==================================')\n",
    "    test_pred = model.predict(df_test[features])\n",
    "    test_pred = np.argmax(test_pred, axis=1)\n",
    "\n",
    "    test_predictions[:, fold] += test_pred\n",
    "\n",
    "    # save results\n",
    "    y_valids.append(y_val)\n",
    "    val_preds.append(val_pred)\n",
    "    # feature_importance_df[\"Importance_Fold\"+str(fold+1)]=model.feature_importance(importance_type='gain')\n",
    "\n",
    "    # Compute fold metric\n",
    "    val_pred = pd.DataFrame(data={'prediction': val_pred})\n",
    "    y_val = pd.DataFrame(data={'target': y_val.reset_index(drop=True)})\n",
    "    score = f1_score(y_val, val_pred, average='macro')\n",
    "\n",
    "    print(f'Fold {fold+1} CV result')\n",
    "    print(f'metric : {score}')\n",
    "\n",
    "    del X_train, X_val, y_train, y_val\n",
    "    _ = gc.collect()\n",
    "\n",
    "# Compute out of folds metric\n",
    "oof_predictions = pd.DataFrame(data={'prediction': oof_predictions})\n",
    "y_true = pd.DataFrame(data={Config.target: df_train[Config.target]})\n",
    "\n",
    "print(' ')\n",
    "print('-'*50)\n",
    "print(f'TOTAL socre : {f1_score(df_train[Config.target], oof_predictions[\"prediction\"], average=\"macro\")}')\n",
    "print('-'*50)\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({Config.row_id: df_train[Config.row_id], Config.target: df_train[Config.target], 'prediction': oof_predictions['prediction']})\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_predictions, _ = stats.mode(test_predictions, axis=1)\n",
    "test_predictions = test_predictions.reshape(-1)\n",
    "\n",
    "test_df = pd.DataFrame({Config.row_id: df_test[Config.row_id], Config.target: test_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "oof_df_tmp = oof_df.drop(columns=[Config.target])\n",
    "oof_df_tmp.columns = [Config.row_id, f'nb{Config.NB}']\n",
    "oof_df_tmp.to_csv(Config.interim_dir + f'nb{Config.NB}.csv', index=False)\n",
    "oof_df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ],
         "reversescale": false,
         "showscale": false,
         "type": "heatmap",
         "x": [
          "Target_0",
          "Target_1",
          "Target_2",
          "Target_3",
          "Target_4",
          "Target_5",
          "Target_6",
          "Target_7",
          "Target_8",
          "Target_9",
          "Target_10"
         ],
         "y": [
          "Target_0",
          "Target_1",
          "Target_2",
          "Target_3",
          "Target_4",
          "Target_5",
          "Target_6",
          "Target_7",
          "Target_8",
          "Target_9",
          "Target_10"
         ],
         "z": [
          [
           0.15625,
           0,
           0,
           0.03125,
           0,
           0,
           0,
           0,
           0.34375,
           0.1875,
           0.28125
          ],
          [
           0,
           0.16585365853658537,
           0.05365853658536585,
           0.13170731707317074,
           0,
           0.00975609756097561,
           0.01951219512195122,
           0.04878048780487805,
           0.23414634146341465,
           0.00975609756097561,
           0.32682926829268294
          ],
          [
           0,
           0.08376963350785341,
           0.10471204188481675,
           0.12041884816753927,
           0.015706806282722512,
           0.041884816753926704,
           0.031413612565445025,
           0.14659685863874344,
           0.23036649214659685,
           0,
           0.225130890052356
          ],
          [
           0.0027624309392265192,
           0.03867403314917127,
           0.027624309392265192,
           0.6574585635359116,
           0.011049723756906077,
           0.013812154696132596,
           0,
           0.019337016574585635,
           0.1685082872928177,
           0.0055248618784530384,
           0.055248618784530384
          ],
          [
           0,
           0,
           0.08888888888888889,
           0.06666666666666667,
           0.28888888888888886,
           0.044444444444444446,
           0.08888888888888889,
           0.15555555555555556,
           0.24444444444444444,
           0.022222222222222223,
           0
          ],
          [
           0,
           0.047619047619047616,
           0.023809523809523808,
           0.1111111111111111,
           0.023809523809523808,
           0.1746031746031746,
           0.023809523809523808,
           0.18253968253968253,
           0.20634920634920634,
           0.007936507936507936,
           0.1984126984126984
          ],
          [
           0,
           0.04,
           0,
           0.02,
           0.08,
           0.02,
           0.2,
           0.28,
           0.14,
           0,
           0.22
          ],
          [
           0,
           0.023952095808383235,
           0.04790419161676647,
           0.041916167664670656,
           0.014970059880239521,
           0.041916167664670656,
           0.023952095808383235,
           0.3203592814371258,
           0.39520958083832336,
           0,
           0.08982035928143713
          ],
          [
           0.0053639846743295016,
           0.056704980842911874,
           0.0367816091954023,
           0.06360153256704981,
           0.012260536398467433,
           0.019157088122605363,
           0.01839080459770115,
           0.08659003831417625,
           0.5325670498084292,
           0.007662835249042145,
           0.16091954022988506
          ],
          [
           0.05084745762711865,
           0.03389830508474576,
           0,
           0,
           0,
           0,
           0,
           0,
           0.288135593220339,
           0.5423728813559322,
           0.0847457627118644
          ],
          [
           0.0074794315632011965,
           0.05235602094240838,
           0.02692595362752431,
           0.037397157816005985,
           0.0029917726252804786,
           0.01795063575168287,
           0.0074794315632011965,
           0.056843679880329095,
           0.19521316379955123,
           0.0037397157816005983,
           0.5916230366492147
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.15625",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.03125",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.34375",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1875",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.28125",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.16585365853658537",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.05365853658536585",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.13170731707317074",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.00975609756097561",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.01951219512195122",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.04878048780487805",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.23414634146341465",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.00975609756097561",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.32682926829268294",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.08376963350785341",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.10471204188481675",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.12041884816753927",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.015706806282722512",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.041884816753926704",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.031413612565445025",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.14659685863874344",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.23036649214659685",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.225130890052356",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0027624309392265192",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.03867403314917127",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.027624309392265192",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.6574585635359116",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.011049723756906077",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.013812154696132596",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.019337016574585635",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1685082872928177",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0055248618784530384",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.055248618784530384",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.08888888888888889",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.06666666666666667",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.28888888888888886",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.044444444444444446",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.08888888888888889",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.15555555555555556",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.24444444444444444",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.022222222222222223",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_4",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.047619047619047616",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.023809523809523808",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1111111111111111",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.023809523809523808",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1746031746031746",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.023809523809523808",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.18253968253968253",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.20634920634920634",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.007936507936507936",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1984126984126984",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_5",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.04",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.02",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.08",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.02",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.2",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.28",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.14",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.22",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_6",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.023952095808383235",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.04790419161676647",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.041916167664670656",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.014970059880239521",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.041916167664670656",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.023952095808383235",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.3203592814371258",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.39520958083832336",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.08982035928143713",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_7",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0053639846743295016",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.056704980842911874",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0367816091954023",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.06360153256704981",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.012260536398467433",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.019157088122605363",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.01839080459770115",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.08659003831417625",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5325670498084292",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.007662835249042145",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.16091954022988506",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_8",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.05084745762711865",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.03389830508474576",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.288135593220339",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5423728813559322",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0847457627118644",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_9",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0074794315632011965",
          "x": "Target_0",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.05235602094240838",
          "x": "Target_1",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.02692595362752431",
          "x": "Target_2",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.037397157816005985",
          "x": "Target_3",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0029917726252804786",
          "x": "Target_4",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.01795063575168287",
          "x": "Target_5",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0074794315632011965",
          "x": "Target_6",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.056843679880329095",
          "x": "Target_7",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.19521316379955123",
          "x": "Target_8",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0037397157816005983",
          "x": "Target_9",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5916230366492147",
          "x": "Target_10",
          "xref": "x",
          "y": "Target_10",
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": "",
         "title": {
          "text": "Pred Label"
         }
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  ",
         "title": {
          "text": "True Label"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(oof_df[Config.target], oof_df['prediction'], normalize='true')\n",
    "\n",
    "names = [f'Target_{i}' for i in range(11)]\n",
    "\n",
    "fig = ff.create_annotated_heatmap(cm, x=names, y=names)\n",
    "fig.update_layout(\n",
    "    yaxis_title='True Label',\n",
    "    xaxis_title='Pred Label',\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "histnorm": "probability",
         "marker": {
          "color": "#016CC9"
         },
         "name": "Prediction",
         "type": "histogram",
         "x": [
          5,
          10,
          8,
          7,
          8,
          7,
          8,
          4,
          3,
          10,
          8,
          10,
          8,
          8,
          7,
          4,
          8,
          10,
          3,
          3,
          8,
          7,
          10,
          10,
          10,
          10,
          8,
          3,
          10,
          8,
          10,
          8,
          10,
          8,
          7,
          3,
          7,
          10,
          9,
          10,
          8,
          8,
          7,
          8,
          10,
          7,
          10,
          8,
          3,
          8,
          10,
          8,
          8,
          1,
          5,
          10,
          4,
          8,
          10,
          7,
          10,
          8,
          3,
          3,
          2,
          5,
          1,
          10,
          0,
          8,
          8,
          3,
          10,
          8,
          10,
          8,
          1,
          8,
          10,
          7,
          10,
          5,
          10,
          10,
          5,
          8,
          3,
          10,
          8,
          8,
          8,
          2,
          5,
          4,
          3,
          5,
          10,
          10,
          7,
          3,
          8,
          8,
          1,
          8,
          10,
          8,
          7,
          8,
          10,
          3,
          10,
          3,
          5,
          3,
          8,
          8,
          10,
          1,
          8,
          7,
          8,
          1,
          2,
          8,
          10,
          8,
          10,
          10,
          5,
          3,
          3,
          10,
          8,
          3,
          7,
          10,
          5,
          10,
          3,
          7,
          8,
          10,
          3,
          2,
          3,
          3,
          8,
          0,
          8,
          3,
          8,
          10,
          5,
          10,
          7,
          4,
          10,
          7,
          7,
          7,
          10,
          10,
          8,
          10,
          8,
          10,
          10,
          10,
          10,
          7,
          3,
          8,
          8,
          10,
          7,
          8,
          3,
          9,
          2,
          10,
          8,
          3,
          10,
          3,
          6,
          6,
          3,
          10,
          10,
          8,
          10,
          8,
          8,
          1,
          8,
          10,
          8,
          10,
          10,
          8,
          10,
          3,
          8,
          10,
          8,
          5,
          10,
          3,
          8,
          10,
          8,
          8,
          7,
          8,
          8,
          10,
          8,
          6,
          8,
          8,
          3,
          8,
          8,
          8,
          8,
          10,
          10,
          8,
          10,
          10,
          10,
          7,
          10,
          3,
          10,
          3,
          10,
          7,
          3,
          8,
          10,
          5,
          8,
          1,
          8,
          3,
          8,
          10,
          10,
          8,
          8,
          8,
          9,
          8,
          10,
          10,
          7,
          2,
          8,
          8,
          8,
          10,
          8,
          5,
          10,
          7,
          7,
          6,
          7,
          8,
          10,
          10,
          8,
          10,
          3,
          5,
          6,
          8,
          8,
          8,
          8,
          8,
          8,
          2,
          8,
          1,
          8,
          7,
          8,
          8,
          10,
          8,
          8,
          8,
          8,
          2,
          10,
          3,
          7,
          8,
          8,
          3,
          8,
          10,
          10,
          8,
          8,
          9,
          7,
          3,
          6,
          5,
          10,
          10,
          1,
          10,
          8,
          10,
          8,
          8,
          7,
          5,
          8,
          10,
          5,
          5,
          8,
          8,
          8,
          10,
          7,
          8,
          8,
          10,
          9,
          10,
          7,
          10,
          2,
          10,
          8,
          10,
          3,
          10,
          3,
          8,
          10,
          8,
          10,
          3,
          10,
          3,
          8,
          10,
          8,
          8,
          10,
          10,
          10,
          5,
          8,
          8,
          1,
          10,
          5,
          8,
          10,
          10,
          3,
          8,
          10,
          10,
          10,
          8,
          8,
          9,
          1,
          3,
          9,
          7,
          7,
          8,
          8,
          7,
          8,
          10,
          10,
          8,
          8,
          1,
          3,
          8,
          8,
          9,
          3,
          10,
          7,
          10,
          1,
          10,
          10,
          9,
          8,
          8,
          8,
          5,
          1,
          10,
          8,
          8,
          7,
          8,
          8,
          7,
          8,
          6,
          8,
          8,
          8,
          8,
          8,
          10,
          8,
          10,
          10,
          7,
          10,
          8,
          10,
          1,
          7,
          8,
          10,
          7,
          3,
          10,
          8,
          10,
          8,
          7,
          10,
          10,
          3,
          3,
          8,
          8,
          5,
          10,
          8,
          8,
          8,
          8,
          10,
          8,
          8,
          1,
          10,
          10,
          10,
          10,
          8,
          10,
          8,
          10,
          3,
          8,
          2,
          1,
          3,
          8,
          6,
          10,
          5,
          1,
          8,
          2,
          8,
          10,
          10,
          5,
          8,
          10,
          10,
          7,
          10,
          10,
          3,
          1,
          10,
          5,
          10,
          10,
          8,
          8,
          8,
          8,
          10,
          8,
          7,
          3,
          10,
          10,
          10,
          7,
          10,
          8,
          7,
          10,
          7,
          8,
          7,
          1,
          6,
          3,
          10,
          3,
          3,
          10,
          8,
          10,
          8,
          10,
          3,
          3,
          7,
          8,
          5,
          8,
          10,
          6,
          10,
          8,
          10,
          8,
          10,
          8,
          8,
          8,
          3,
          3,
          8,
          3,
          8,
          10,
          8,
          8,
          10,
          10,
          3,
          6,
          10,
          10,
          10,
          10,
          7,
          8,
          10,
          8,
          8,
          8,
          8,
          3,
          1,
          8,
          10,
          8,
          8,
          8,
          7,
          8,
          3,
          8,
          8,
          10,
          8,
          2,
          10,
          5,
          8,
          10,
          8,
          2,
          3,
          3,
          10,
          10,
          10,
          9,
          10,
          8,
          10,
          8,
          10,
          8,
          8,
          7,
          7,
          10,
          10,
          10,
          10,
          7,
          10,
          7,
          7,
          10,
          3,
          8,
          10,
          2,
          10,
          8,
          10,
          1,
          8,
          7,
          8,
          1,
          10,
          8,
          7,
          8,
          10,
          3,
          10,
          8,
          10,
          4,
          10,
          10,
          10,
          8,
          8,
          3,
          3,
          3,
          3,
          10,
          10,
          7,
          8,
          1,
          10,
          9,
          5,
          7,
          10,
          8,
          10,
          8,
          10,
          8,
          5,
          10,
          8,
          5,
          8,
          10,
          0,
          8,
          10,
          3,
          10,
          8,
          3,
          10,
          7,
          2,
          3,
          10,
          7,
          10,
          10,
          3,
          10,
          8,
          8,
          10,
          8,
          8,
          8,
          8,
          8,
          8,
          10,
          8,
          10,
          8,
          3,
          10,
          8,
          8,
          10,
          3,
          8,
          3,
          8,
          10,
          10,
          10,
          10,
          8,
          8,
          8,
          8,
          8,
          8,
          1,
          3,
          7,
          8,
          10,
          10,
          8,
          10,
          8,
          10,
          8,
          8,
          3,
          10,
          8,
          10,
          10,
          8,
          3,
          3,
          7,
          7,
          8,
          3,
          3,
          10,
          3,
          8,
          3,
          10,
          8,
          8,
          10,
          3,
          10,
          10,
          3,
          10,
          3,
          3,
          7,
          10,
          8,
          8,
          0,
          10,
          7,
          7,
          5,
          8,
          10,
          10,
          8,
          8,
          7,
          10,
          3,
          10,
          10,
          10,
          8,
          8,
          8,
          10,
          8,
          1,
          8,
          10,
          7,
          5,
          7,
          10,
          8,
          3,
          7,
          7,
          7,
          8,
          10,
          10,
          10,
          10,
          8,
          8,
          8,
          7,
          2,
          8,
          7,
          10,
          10,
          10,
          1,
          8,
          8,
          10,
          8,
          10,
          10,
          8,
          1,
          10,
          7,
          8,
          10,
          10,
          10,
          8,
          8,
          8,
          1,
          8,
          8,
          10,
          10,
          9,
          10,
          3,
          7,
          8,
          10,
          10,
          8,
          10,
          8,
          8,
          10,
          8,
          7,
          10,
          1,
          10,
          10,
          10,
          10,
          10,
          7,
          8,
          10,
          8,
          8,
          10,
          7,
          2,
          8,
          7,
          1,
          8,
          10,
          10,
          10,
          10,
          8,
          2,
          5,
          10,
          3,
          8,
          8,
          10,
          8,
          10,
          10,
          10,
          8,
          3,
          8,
          4,
          10,
          2,
          8,
          10,
          10,
          8,
          8,
          3,
          3,
          3,
          1,
          7,
          7,
          7,
          10,
          10,
          8,
          10,
          8,
          1,
          3,
          10,
          10,
          3,
          8,
          1,
          8,
          5,
          5,
          7,
          2,
          1,
          10,
          8,
          2,
          10,
          10,
          5,
          10,
          10,
          1,
          8,
          8,
          10,
          10,
          3,
          10,
          1,
          8,
          8,
          7,
          1,
          10,
          8,
          3,
          0,
          8,
          10,
          7,
          8,
          5,
          10,
          10,
          8,
          8,
          3,
          3,
          3,
          5,
          10,
          8,
          8,
          8,
          3,
          7,
          10,
          10,
          8,
          1,
          1,
          8,
          10,
          7,
          10,
          2,
          10,
          8,
          8,
          8,
          2,
          10,
          10,
          10,
          10,
          8,
          8,
          10,
          8,
          3,
          8,
          10,
          10,
          3,
          10,
          8,
          8,
          3,
          10,
          10,
          10,
          9,
          10,
          8,
          3,
          10,
          8,
          10,
          1,
          10,
          1,
          10,
          8,
          10,
          8,
          10,
          8,
          7,
          10,
          3,
          10,
          10,
          10,
          3,
          8,
          3,
          2,
          10,
          10,
          3,
          3,
          10,
          8,
          1,
          10,
          10,
          2,
          8,
          10,
          8,
          9,
          2,
          7,
          8,
          8,
          8,
          10,
          10,
          8,
          10,
          8,
          8,
          3,
          3,
          3,
          8,
          10,
          10,
          2,
          10,
          10,
          1,
          10,
          3,
          8,
          8,
          8,
          8,
          8,
          8,
          1,
          10,
          8,
          8,
          10,
          4,
          8,
          10,
          10,
          3,
          7,
          8,
          7,
          8,
          8,
          7,
          10,
          10,
          8,
          10,
          10,
          8,
          8,
          8,
          5,
          5,
          3,
          2,
          8,
          7,
          8,
          8,
          10,
          8,
          10,
          9,
          10,
          8,
          10,
          3,
          8,
          10,
          8,
          7,
          3,
          10,
          8,
          2,
          3,
          10,
          10,
          10,
          10,
          7,
          8,
          8,
          5,
          10,
          10,
          3,
          10,
          3,
          10,
          10,
          8,
          8,
          10,
          1,
          4,
          10,
          8,
          10,
          5,
          3,
          8,
          8,
          8,
          7,
          10,
          7,
          3,
          3,
          10,
          3,
          10,
          8,
          8,
          1,
          10,
          10,
          7,
          3,
          9,
          8,
          0,
          7,
          8,
          8,
          3,
          8,
          8,
          7,
          8,
          10,
          10,
          8,
          8,
          10,
          10,
          8,
          3,
          8,
          2,
          8,
          10,
          8,
          10,
          3,
          8,
          10,
          9,
          10,
          10,
          8,
          8,
          10,
          2,
          8,
          1,
          8,
          8,
          10,
          8,
          10,
          8,
          10,
          10,
          7,
          1,
          8,
          8,
          8,
          10,
          7,
          8,
          8,
          10,
          5,
          10,
          8,
          10,
          3,
          0,
          10,
          8,
          3,
          8,
          7,
          5,
          3,
          10,
          7,
          3,
          10,
          10,
          10,
          0,
          10,
          10,
          10,
          2,
          10,
          10,
          8,
          8,
          5,
          7,
          10,
          8,
          7,
          10,
          9,
          8,
          7,
          8,
          2,
          10,
          10,
          2,
          7,
          10,
          8,
          8,
          1,
          10,
          5,
          3,
          10,
          8,
          7,
          8,
          10,
          8,
          2,
          8,
          8,
          3,
          8,
          8,
          8,
          8,
          10,
          10,
          8,
          8,
          8,
          8,
          7,
          10,
          7,
          2,
          10,
          2,
          8,
          6,
          8,
          3,
          8,
          10,
          8,
          10,
          10,
          4,
          8,
          8,
          10,
          7,
          8,
          10,
          8,
          8,
          10,
          10,
          10,
          3,
          10,
          10,
          8,
          5,
          8,
          3,
          10,
          10,
          2,
          3,
          8,
          8,
          8,
          8,
          8,
          10,
          8,
          6,
          8,
          8,
          7,
          10,
          7,
          8,
          7,
          10,
          10,
          10,
          7,
          8,
          1,
          8,
          2,
          1,
          10,
          8,
          10,
          8,
          4,
          10,
          10,
          10,
          1,
          8,
          3,
          5,
          8,
          8,
          10,
          2,
          8,
          3,
          10,
          8,
          1,
          10,
          8,
          8,
          1,
          2,
          8,
          8,
          10,
          10,
          10,
          7,
          10,
          9,
          10,
          8,
          4,
          10,
          1,
          10,
          3,
          8,
          8,
          8,
          3,
          3,
          3,
          7,
          8,
          8,
          7,
          10,
          8,
          10,
          9,
          7,
          10,
          8,
          8,
          2,
          10,
          10,
          10,
          8,
          5,
          2,
          10,
          10,
          8,
          3,
          1,
          10,
          8,
          10,
          8,
          10,
          10,
          10,
          10,
          8,
          3,
          7,
          8,
          8,
          3,
          8,
          10,
          8,
          10,
          3,
          3,
          10,
          8,
          10,
          8,
          10,
          10,
          3,
          8,
          3,
          3,
          3,
          8,
          7,
          8,
          9,
          10,
          10,
          3,
          7,
          1,
          8,
          3,
          8,
          8,
          10,
          8,
          10,
          3,
          8,
          10,
          10,
          7,
          10,
          7,
          7,
          10,
          10,
          10,
          10,
          10,
          10,
          3,
          4,
          7,
          8,
          3,
          10,
          10,
          8,
          10,
          3,
          7,
          8,
          8,
          1,
          8,
          10,
          7,
          10,
          8,
          4,
          3,
          8,
          8,
          10,
          10,
          5,
          8,
          0,
          7,
          8,
          3,
          8,
          10,
          2,
          7,
          10,
          8,
          10,
          7,
          8,
          6,
          10,
          10,
          3,
          8,
          8,
          8,
          10,
          6,
          3,
          10,
          10,
          8,
          10,
          8,
          8,
          10,
          10,
          8,
          8,
          7,
          8,
          8,
          10,
          8,
          7,
          3,
          3,
          7,
          1,
          8,
          8,
          7,
          8,
          8,
          1,
          7,
          9,
          8,
          10,
          8,
          10,
          8,
          10,
          8,
          7,
          0,
          10,
          8,
          8,
          3,
          2,
          10,
          10,
          7,
          8,
          10,
          10,
          10,
          8,
          8,
          8,
          8,
          10,
          10,
          8,
          10,
          8,
          10,
          3,
          3,
          8,
          8,
          8,
          8,
          10,
          7,
          10,
          7,
          10,
          3,
          10,
          10,
          8,
          8,
          8,
          7,
          8,
          8,
          3,
          8,
          10,
          1,
          10,
          1,
          8,
          3,
          8,
          10,
          8,
          8,
          3,
          8,
          3,
          3,
          3,
          8,
          10,
          7,
          8,
          7,
          10,
          7,
          7,
          8,
          2,
          8,
          7,
          10,
          10,
          10,
          10,
          8,
          3,
          3,
          7,
          3,
          10,
          5,
          10,
          10,
          8,
          7,
          10,
          2,
          8,
          10,
          8,
          3,
          10,
          8,
          7,
          4,
          8,
          10,
          10,
          8,
          10,
          8,
          8,
          10,
          8,
          8,
          7,
          8,
          1,
          8,
          10,
          8,
          8,
          10,
          10,
          8,
          8,
          10,
          8,
          10,
          1,
          8,
          8,
          8,
          10,
          3,
          3,
          8,
          10,
          3,
          6,
          7,
          7,
          2,
          5,
          3,
          6,
          8,
          8,
          1,
          8,
          5,
          10,
          10,
          8,
          3,
          10,
          3,
          3,
          8,
          10,
          10,
          8,
          10,
          10,
          10,
          3,
          10,
          10,
          10,
          7,
          8,
          6,
          10,
          8,
          2,
          7,
          8,
          9,
          7,
          8,
          8,
          10,
          8,
          6,
          8,
          10,
          8,
          3,
          10,
          3,
          8,
          10,
          8,
          8,
          3,
          7,
          8,
          10,
          5,
          8,
          8,
          7,
          7,
          0,
          3,
          10,
          8,
          10,
          7,
          8,
          7,
          8,
          3,
          8,
          8,
          3,
          8,
          3,
          8,
          7,
          5,
          8,
          8,
          8,
          10,
          8,
          8,
          3,
          5,
          2,
          10,
          2,
          10,
          1,
          3,
          10,
          8,
          10,
          8,
          8,
          8,
          2,
          8,
          8,
          7,
          7,
          6,
          10,
          3,
          8,
          1,
          8,
          8,
          8,
          4,
          8,
          3,
          10,
          8,
          8,
          2,
          7,
          10,
          8,
          10,
          8,
          8,
          10,
          1,
          8,
          3,
          10,
          10,
          10,
          5,
          8,
          10,
          3,
          7,
          7,
          3,
          10,
          8,
          1,
          8,
          3,
          3,
          8,
          10,
          8,
          3,
          10,
          8,
          10,
          10,
          3,
          7,
          6,
          8,
          2,
          10,
          8,
          10,
          10,
          10,
          1,
          10,
          10,
          8,
          8,
          7,
          8,
          8,
          8,
          1,
          1,
          10,
          10,
          8,
          6,
          10,
          3,
          8,
          10,
          8,
          5,
          8,
          8,
          2,
          8,
          7,
          7,
          8,
          10,
          10,
          6,
          8,
          3,
          10,
          3,
          7,
          8,
          8,
          8,
          10,
          3,
          10,
          10,
          8,
          9,
          8,
          4,
          10,
          10,
          3,
          10,
          7,
          8,
          1,
          8,
          1,
          8,
          10,
          3,
          8,
          7,
          8,
          8,
          3,
          7,
          8,
          10,
          8,
          8,
          10,
          3,
          7,
          10,
          7,
          3,
          10,
          8,
          8,
          2,
          8,
          7,
          7,
          8,
          3,
          10,
          10,
          10,
          4,
          8,
          2,
          8,
          10,
          7,
          10,
          10,
          7,
          10,
          8,
          8,
          8,
          3,
          8,
          10,
          8,
          8,
          10,
          8,
          10,
          7,
          10,
          4,
          8,
          10,
          10,
          7,
          10,
          6,
          8,
          10,
          9,
          8,
          10,
          8,
          3,
          8,
          7,
          2,
          2,
          10,
          8,
          10,
          7,
          8,
          1,
          8,
          10,
          8,
          8,
          1,
          10,
          8,
          3,
          3,
          2,
          0,
          1,
          8,
          10,
          10,
          6,
          10,
          10,
          8,
          5,
          7,
          8,
          1,
          8,
          10,
          2,
          7,
          8,
          6,
          8,
          3,
          10,
          10,
          10,
          3,
          8,
          10,
          7,
          8,
          8,
          3,
          1,
          1,
          3,
          10,
          8,
          7,
          3,
          8,
          10,
          10,
          8,
          8,
          8,
          7,
          10,
          8,
          5,
          5,
          10,
          10,
          8,
          3,
          8,
          8,
          10,
          8,
          8,
          10,
          7,
          10,
          2,
          9,
          7,
          8,
          10,
          6,
          10,
          8,
          7,
          10,
          10,
          8,
          3,
          8,
          10,
          8,
          3,
          4,
          3,
          8,
          3,
          7,
          8,
          10,
          10,
          10,
          10,
          10,
          1,
          6,
          7,
          10,
          10,
          8,
          7,
          3,
          3,
          10,
          8,
          10,
          10,
          7,
          10,
          7,
          10,
          10,
          8,
          3,
          8,
          3,
          8,
          7,
          8,
          7,
          7,
          10,
          10,
          8,
          3,
          3,
          7,
          7,
          8,
          7,
          8,
          8,
          7,
          10,
          10,
          10,
          8,
          2,
          10,
          10,
          8,
          10,
          10,
          8,
          8,
          8,
          10,
          7,
          4,
          7,
          8,
          7,
          10,
          10,
          8,
          7,
          2,
          8,
          10,
          1,
          10,
          8,
          8,
          10,
          10,
          8,
          3,
          7,
          8,
          8,
          7,
          8,
          8,
          3,
          10,
          10,
          10,
          8,
          10,
          3,
          10,
          10,
          1,
          10,
          10,
          7,
          8,
          8,
          10,
          8,
          8,
          10,
          10,
          3,
          8,
          8,
          10,
          10,
          9,
          10,
          8,
          8,
          10,
          8,
          3,
          10,
          10,
          10,
          2,
          2,
          7,
          8,
          8,
          8,
          8,
          6,
          8,
          1,
          10,
          8,
          10,
          6,
          10,
          8,
          7,
          8,
          3,
          10,
          8,
          8,
          10,
          10,
          7,
          8,
          10,
          7,
          10,
          8,
          3,
          10,
          3,
          8,
          7,
          10,
          7,
          10,
          8,
          10,
          10,
          10,
          8,
          10,
          5,
          10,
          8,
          8,
          10,
          3,
          8,
          10,
          8,
          8,
          8,
          8,
          10,
          10,
          10,
          2,
          3,
          10,
          8,
          8,
          10,
          7,
          8,
          2,
          10,
          10,
          8,
          7,
          8,
          8,
          1,
          7,
          8,
          8,
          3,
          10,
          8,
          10,
          8,
          8,
          8,
          8,
          8,
          8,
          10,
          3,
          8,
          6,
          8,
          9,
          8,
          8,
          10,
          10,
          8,
          8,
          8,
          10,
          10,
          8,
          7,
          10,
          8,
          10,
          8,
          1,
          10,
          10,
          10,
          8,
          10,
          10,
          3,
          10,
          3,
          8,
          8,
          10,
          2,
          10,
          8,
          3,
          8,
          1,
          10,
          10,
          3,
          3,
          7,
          8,
          10,
          10,
          1,
          1,
          8,
          8,
          10,
          10,
          10,
          10,
          8,
          10,
          3,
          7,
          8,
          3,
          8,
          8,
          5,
          10,
          8,
          8,
          8,
          8,
          10,
          7,
          9,
          3,
          3,
          10,
          1,
          10,
          8,
          10,
          8,
          7,
          8,
          8,
          8,
          10,
          10,
          3,
          10,
          8,
          5,
          7,
          10,
          5,
          10,
          3,
          8,
          3,
          7,
          8,
          7,
          10,
          2,
          8,
          10,
          3,
          3,
          3,
          8,
          8,
          8,
          3,
          10,
          10,
          8,
          10,
          7,
          7,
          3,
          8,
          8,
          10,
          10,
          10,
          10,
          7,
          3,
          3,
          10,
          0,
          7,
          1,
          7,
          3,
          8,
          6,
          7,
          10,
          8,
          10,
          10,
          8,
          3,
          7,
          9,
          7,
          1,
          2,
          10,
          10,
          7,
          8,
          10,
          10,
          8,
          3,
          2,
          9,
          9,
          7,
          1,
          2,
          5,
          10,
          8,
          8,
          10,
          1,
          10,
          8,
          8,
          10,
          10,
          8,
          3,
          1,
          1,
          7,
          3,
          10,
          10,
          1,
          5,
          8,
          10,
          3,
          8,
          10,
          10,
          10,
          7,
          0,
          8,
          2,
          1,
          10,
          7,
          9,
          3,
          3,
          8,
          3,
          8,
          5,
          5,
          5,
          6,
          10,
          3,
          7,
          3,
          7,
          8,
          8,
          10,
          7,
          10,
          8,
          3,
          1,
          3,
          0,
          8,
          8,
          10,
          8,
          5,
          8,
          8,
          8,
          10,
          9,
          7,
          10,
          8,
          5,
          7,
          8,
          8,
          8,
          2,
          10,
          10,
          8,
          10,
          8,
          8,
          10,
          7,
          8,
          10,
          8,
          8,
          3,
          3,
          8,
          10,
          8,
          10,
          10,
          8,
          8,
          10,
          8,
          1,
          10,
          3,
          7,
          2,
          3,
          8,
          1,
          8,
          10,
          8,
          10,
          10,
          8,
          10,
          2,
          10,
          10,
          6,
          10,
          7,
          2,
          10,
          8,
          2,
          1,
          8,
          8,
          10,
          8,
          10,
          3,
          3,
          10,
          8,
          8,
          8,
          8,
          8,
          8,
          3,
          10,
          10,
          8,
          8,
          7,
          3,
          1,
          10,
          7,
          8,
          1,
          8,
          10,
          10,
          8,
          7,
          8,
          3,
          8,
          7,
          3,
          8,
          7,
          1,
          10,
          10,
          10,
          2,
          3,
          10,
          3,
          8,
          10,
          8,
          10,
          10,
          1,
          7,
          10,
          8,
          5,
          8,
          8,
          7,
          3,
          7,
          1,
          9,
          3,
          8,
          10,
          8,
          10,
          5,
          3,
          7,
          1,
          8,
          10,
          7,
          2,
          7,
          8,
          3,
          2,
          3,
          8,
          10,
          10,
          8,
          6,
          6,
          8,
          10,
          8,
          4,
          6,
          10,
          10,
          7,
          8,
          10,
          8,
          1,
          10,
          5,
          3,
          8,
          10,
          8,
          10,
          8,
          9,
          7,
          8,
          8,
          8,
          8,
          3,
          10,
          8,
          3,
          3,
          8,
          10,
          7,
          10,
          10,
          8,
          1,
          8,
          1,
          3,
          8,
          8,
          10,
          8,
          10,
          9,
          3,
          3,
          3,
          8,
          8,
          10,
          8,
          8,
          10,
          10,
          3,
          6,
          10,
          10,
          10,
          1,
          8,
          10,
          8,
          8,
          10,
          7,
          3,
          10,
          10,
          8,
          8,
          3,
          8,
          10,
          10,
          8,
          8,
          8,
          8,
          8,
          2,
          7,
          10,
          10,
          10,
          1,
          1,
          10,
          8,
          6,
          8,
          8,
          8,
          5,
          5,
          10,
          3,
          2,
          10,
          5,
          8,
          9,
          3,
          10,
          10,
          8,
          10,
          10,
          3,
          8,
          3,
          8,
          6,
          7,
          3,
          8,
          8,
          7,
          8,
          8,
          3,
          8,
          10,
          8,
          10,
          10,
          8,
          8,
          9,
          8,
          8,
          7,
          7,
          10,
          1,
          3,
          10,
          8,
          10,
          7,
          8,
          8,
          8,
          3,
          6,
          10,
          1,
          8,
          6,
          8,
          3,
          2,
          2,
          8,
          10,
          8,
          10,
          10,
          10,
          10,
          8,
          3,
          3,
          8,
          8,
          10,
          3,
          10,
          10,
          7,
          3,
          8,
          7,
          7,
          6,
          2,
          2,
          8,
          10,
          2,
          6,
          8,
          10,
          3,
          5,
          8,
          3,
          10,
          7,
          6,
          6,
          8,
          3,
          6,
          10,
          8,
          8,
          3,
          8,
          10,
          8,
          10,
          10,
          2,
          8,
          3,
          3,
          9,
          3,
          7,
          10,
          10,
          2,
          7,
          3,
          10,
          7,
          10,
          7,
          8,
          9,
          8,
          10,
          3,
          1,
          8,
          10,
          10,
          10,
          9,
          8,
          10,
          10,
          10,
          3,
          10,
          3,
          8,
          3,
          5,
          8,
          8,
          8,
          1,
          10,
          8,
          1,
          7,
          8,
          8,
          7,
          10,
          10,
          7,
          1,
          7,
          10,
          10,
          10,
          10,
          8,
          10,
          10,
          4,
          3,
          3,
          2,
          3,
          1,
          10,
          7,
          3,
          7,
          8,
          8,
          1,
          2,
          8,
          3,
          8,
          8,
          1,
          8,
          8,
          3,
          10,
          8,
          10,
          8,
          8,
          10,
          10,
          8,
          8,
          8,
          9,
          3,
          10,
          8,
          8,
          3,
          8,
          10,
          7,
          2,
          10,
          8,
          10,
          8,
          8,
          10,
          3,
          8,
          5,
          6,
          10,
          4,
          9,
          8,
          8,
          10,
          8,
          9,
          10,
          10,
          10,
          10,
          8,
          10,
          8,
          8,
          10,
          10,
          3,
          10,
          3,
          10,
          8,
          8,
          10,
          8,
          10,
          8,
          3,
          8,
          7,
          3,
          8,
          8,
          8,
          8,
          5,
          8,
          3,
          6,
          10,
          10,
          8,
          8,
          1,
          8,
          3,
          8,
          1,
          3,
          9,
          6,
          3,
          10,
          10,
          8,
          8,
          5,
          8,
          8,
          7,
          8,
          10,
          10,
          3,
          8,
          8,
          4,
          3,
          8,
          3,
          1,
          10,
          10,
          3,
          10,
          10,
          8,
          10,
          8,
          10,
          7,
          8,
          3,
          8,
          7,
          10,
          8,
          10,
          10,
          8,
          2,
          10,
          10,
          8,
          7,
          10,
          10,
          8,
          8,
          8,
          10,
          10,
          10,
          3,
          8,
          8,
          8,
          3,
          5,
          8,
          8,
          10,
          3,
          10,
          3,
          8,
          8,
          10,
          5,
          8,
          10,
          8,
          7,
          7,
          10,
          3,
          3,
          10,
          10,
          8,
          8,
          8,
          8,
          10,
          2,
          7,
          10,
          8,
          8,
          7,
          9,
          10,
          4,
          8,
          8,
          10,
          10,
          10,
          7,
          10,
          7,
          10,
          10,
          10,
          10,
          8,
          10,
          8,
          10,
          8,
          5,
          2,
          8,
          8,
          7,
          8,
          10,
          7,
          8,
          3,
          8,
          7,
          3,
          8,
          3,
          10,
          2,
          7,
          4,
          8,
          8,
          10,
          8,
          10,
          7,
          3,
          8,
          10,
          10,
          8,
          3,
          8,
          7,
          10,
          8,
          10,
          10,
          10,
          3,
          10,
          1,
          3,
          2,
          7,
          2,
          10,
          8,
          10,
          8,
          7,
          8,
          3,
          3,
          7,
          8,
          8,
          10,
          8,
          7,
          10,
          3,
          10,
          10,
          8,
          3,
          3,
          1,
          10,
          8,
          7,
          8,
          10,
          3,
          4,
          10,
          8,
          8,
          10,
          2,
          8,
          8,
          9,
          8,
          7,
          10,
          8,
          10,
          2,
          10,
          8,
          5,
          8,
          1,
          8,
          8,
          8,
          10,
          8,
          8,
          7,
          2,
          8,
          8,
          10,
          7,
          8,
          10,
          8,
          3,
          3,
          10,
          8,
          2,
          8,
          8,
          2,
          10,
          8,
          3,
          1,
          10,
          8,
          10,
          3,
          10,
          8,
          8,
          8,
          10,
          8,
          10,
          8,
          8,
          3,
          1,
          7,
          8,
          8,
          10,
          8,
          8,
          8,
          8,
          8,
          8,
          10,
          10,
          10,
          8,
          8,
          5,
          10,
          10,
          8,
          10,
          10,
          10,
          8,
          10,
          10,
          8,
          3,
          8,
          4,
          10,
          8,
          10,
          10,
          3,
          8,
          10,
          8,
          3,
          8,
          6,
          10,
          8,
          10,
          8,
          3,
          10,
          10,
          10,
          8,
          2,
          1,
          10,
          10,
          5,
          8,
          10,
          8,
          8,
          8,
          3,
          8,
          8,
          5,
          8,
          5,
          10,
          8,
          10,
          10,
          1,
          10,
          8,
          5,
          10,
          4,
          8,
          8,
          10,
          7,
          8,
          10,
          8,
          8,
          8,
          8,
          10,
          8,
          3,
          1,
          10,
          3,
          3,
          6,
          10,
          8,
          9,
          10,
          10,
          1,
          8,
          10,
          8,
          8,
          1,
          10,
          7,
          7,
          8,
          10,
          3,
          3,
          8,
          5,
          7,
          3,
          10,
          8,
          10,
          8,
          10,
          10,
          3,
          10,
          8,
          8,
          8,
          10,
          8,
          10,
          8,
          7,
          8,
          10,
          1,
          8,
          10,
          10,
          8,
          7,
          7,
          8,
          3,
          8,
          8,
          10,
          8,
          8,
          8,
          8,
          8,
          8,
          1,
          8,
          8,
          7,
          7,
          1,
          3,
          8,
          3,
          3,
          8,
          10,
          8,
          9,
          10,
          8,
          3,
          5,
          10,
          3,
          6,
          2,
          3,
          8,
          8,
          10,
          10,
          10,
          10,
          8,
          10,
          10,
          10,
          7,
          3,
          6,
          8,
          7,
          8,
          10,
          8,
          8,
          8,
          10,
          10,
          10,
          10,
          10,
          10,
          8,
          8,
          5,
          10,
          8,
          10,
          8,
          8,
          7,
          10,
          8,
          10,
          8,
          3,
          7,
          2,
          8,
          8,
          4,
          6,
          4,
          8,
          8,
          8,
          7,
          3,
          3,
          10,
          3,
          8,
          3,
          10,
          7,
          8,
          8,
          7,
          10,
          3,
          1,
          3,
          9,
          10,
          3,
          8,
          10,
          7,
          8,
          8,
          10,
          10,
          8,
          8,
          8,
          8,
          7,
          8,
          8,
          10,
          3,
          8,
          7,
          1,
          6,
          5,
          4,
          8,
          8,
          7,
          3,
          10,
          10,
          8,
          8,
          9,
          7,
          10,
          8,
          3,
          8,
          2,
          10,
          10,
          8,
          10,
          7,
          1,
          10,
          10,
          10,
          8,
          8,
          10,
          1,
          8,
          8,
          8,
          1,
          3,
          8,
          8,
          10,
          8,
          10,
          8,
          7,
          6,
          3,
          8,
          10,
          10,
          8,
          8,
          10,
          10,
          3,
          8,
          3,
          1,
          8,
          3,
          10,
          7,
          7,
          1,
          10,
          4,
          3,
          10,
          3,
          8,
          8,
          10,
          3,
          10,
          8,
          10,
          8,
          10,
          8,
          8,
          3,
          10,
          5,
          7,
          8,
          10,
          3,
          3,
          3,
          7,
          7,
          10,
          8,
          3,
          10,
          8,
          8,
          3,
          10,
          10,
          8,
          10,
          6,
          10,
          3,
          7,
          8,
          8,
          7,
          7,
          1,
          7,
          7,
          8,
          6,
          10,
          10,
          10,
          8,
          8,
          8,
          1,
          3,
          8,
          7,
          8,
          8,
          10,
          2,
          10,
          8,
          8,
          8,
          8,
          10,
          8,
          8,
          7,
          8,
          3,
          8,
          8,
          3,
          7,
          1,
          10,
          10,
          10,
          3,
          8,
          10,
          8,
          8,
          7,
          8,
          10,
          10,
          3,
          8,
          8,
          8,
          3,
          10,
          8,
          10,
          8,
          7,
          10,
          8,
          8,
          10,
          8,
          2,
          3,
          7,
          1,
          10,
          10,
          10,
          10,
          8,
          8,
          10,
          8,
          7,
          8,
          3,
          8,
          10,
          1,
          2,
          10,
          7,
          8,
          10,
          1,
          10,
          10,
          2,
          10,
          1,
          8,
          10,
          5,
          10,
          3,
          9,
          8,
          10,
          6,
          8,
          10,
          10,
          7,
          10,
          8,
          10,
          10,
          8,
          8,
          10,
          8,
          7,
          10,
          6,
          8,
          10,
          10,
          8,
          8,
          7,
          10,
          8,
          8,
          1,
          10,
          10,
          4,
          7,
          8,
          8,
          8,
          3,
          8,
          7,
          10,
          2,
          10,
          10,
          8,
          2,
          10,
          8,
          7,
          8,
          6,
          8,
          7,
          8,
          10,
          3,
          3,
          10,
          3,
          10,
          10,
          10,
          3,
          5,
          8,
          10,
          10,
          10,
          8,
          8,
          10,
          10,
          8,
          4,
          10,
          10,
          8,
          8,
          8,
          10,
          7,
          10,
          7,
          4,
          2,
          2,
          3,
          6,
          8,
          10,
          8,
          3,
          1,
          3,
          8,
          10,
          8,
          8,
          8,
          8,
          5,
          8,
          10,
          8,
          2,
          8,
          8,
          3,
          8,
          8,
          10,
          3,
          8,
          10,
          8,
          3,
          8,
          10,
          3,
          10,
          8,
          10,
          2,
          8,
          8,
          10,
          10,
          8,
          3,
          10,
          7,
          8,
          3,
          8,
          7,
          10,
          10,
          10,
          8,
          8,
          4,
          10,
          7,
          8,
          8,
          8,
          10,
          3,
          3,
          8,
          10,
          3,
          1,
          10,
          7,
          10,
          8,
          3,
          8,
          10,
          10,
          10,
          8,
          8,
          8,
          3,
          7,
          2,
          8,
          3,
          10,
          1,
          9,
          6,
          3,
          10,
          3,
          7,
          7,
          8,
          10,
          10,
          1,
          1,
          8,
          7,
          7,
          10,
          8,
          6,
          3,
          10,
          8,
          7,
          8,
          10,
          8,
          8,
          10,
          10,
          8,
          10,
          7,
          3,
          5,
          10,
          8,
          10,
          10,
          8,
          10,
          7,
          3,
          10,
          10,
          3,
          10,
          8,
          10,
          10,
          7,
          10,
          10,
          10,
          8,
          3,
          8,
          8,
          1,
          8,
          8,
          10,
          7,
          7,
          8,
          10,
          8,
          3,
          8,
          10,
          10,
          10,
          2,
          10,
          10,
          8,
          1,
          4,
          8,
          10,
          8,
          10,
          10,
          3,
          3,
          10,
          7,
          7,
          10,
          10,
          3,
          3,
          8,
          1,
          7,
          10,
          1,
          8,
          10,
          10,
          8,
          8,
          8,
          8,
          8,
          10,
          8,
          8,
          10,
          8,
          3,
          8,
          10,
          10,
          10,
          8,
          10,
          7,
          7,
          10,
          7,
          10,
          10,
          3,
          8,
          10,
          5,
          10,
          3,
          8,
          8,
          8,
          10,
          8,
          8,
          8,
          4
         ]
        },
        {
         "histnorm": "probability",
         "marker": {
          "color": "#E876A3"
         },
         "name": "Train",
         "opacity": 0.5,
         "type": "histogram",
         "x": [
          10,
          8,
          3,
          10,
          3,
          10,
          10,
          10,
          7,
          2,
          8,
          7,
          8,
          8,
          10,
          10,
          10,
          10,
          8,
          8,
          0,
          10,
          10,
          10,
          1,
          8,
          10,
          8,
          8,
          5,
          5,
          8,
          10,
          8,
          8,
          1,
          8,
          10,
          5,
          8,
          8,
          10,
          10,
          5,
          10,
          9,
          10,
          10,
          10,
          6,
          10,
          8,
          8,
          8,
          8,
          3,
          10,
          10,
          8,
          10,
          10,
          7,
          7,
          10,
          7,
          2,
          8,
          5,
          7,
          5,
          4,
          10,
          1,
          6,
          3,
          10,
          10,
          4,
          1,
          10,
          7,
          8,
          8,
          8,
          10,
          8,
          2,
          8,
          8,
          7,
          7,
          3,
          8,
          8,
          9,
          10,
          2,
          10,
          1,
          1,
          5,
          3,
          8,
          10,
          10,
          7,
          8,
          10,
          10,
          8,
          8,
          10,
          3,
          3,
          5,
          7,
          10,
          10,
          5,
          8,
          8,
          10,
          3,
          10,
          10,
          8,
          7,
          3,
          1,
          6,
          10,
          5,
          3,
          10,
          10,
          10,
          8,
          3,
          3,
          10,
          8,
          10,
          7,
          7,
          10,
          7,
          8,
          8,
          10,
          1,
          8,
          10,
          10,
          1,
          7,
          2,
          8,
          8,
          8,
          7,
          8,
          8,
          8,
          3,
          10,
          8,
          10,
          10,
          8,
          10,
          10,
          8,
          7,
          8,
          8,
          10,
          8,
          8,
          10,
          8,
          10,
          10,
          8,
          8,
          3,
          6,
          8,
          8,
          10,
          2,
          2,
          5,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          2,
          7,
          10,
          3,
          3,
          10,
          5,
          8,
          8,
          8,
          8,
          0,
          8,
          10,
          4,
          2,
          10,
          1,
          8,
          8,
          2,
          10,
          8,
          10,
          10,
          10,
          8,
          8,
          1,
          8,
          8,
          5,
          10,
          10,
          4,
          10,
          2,
          2,
          8,
          10,
          8,
          3,
          10,
          10,
          8,
          10,
          10,
          3,
          3,
          7,
          3,
          10,
          8,
          2,
          8,
          1,
          7,
          10,
          1,
          7,
          8,
          8,
          10,
          8,
          8,
          8,
          8,
          3,
          8,
          9,
          2,
          10,
          10,
          0,
          10,
          10,
          10,
          10,
          8,
          10,
          10,
          7,
          7,
          8,
          10,
          2,
          10,
          8,
          5,
          7,
          4,
          0,
          2,
          8,
          5,
          8,
          8,
          8,
          8,
          9,
          8,
          1,
          10,
          10,
          6,
          5,
          8,
          10,
          10,
          8,
          9,
          8,
          7,
          10,
          8,
          8,
          8,
          8,
          4,
          8,
          10,
          5,
          7,
          10,
          8,
          8,
          8,
          8,
          1,
          1,
          10,
          3,
          8,
          10,
          1,
          2,
          10,
          8,
          7,
          10,
          0,
          10,
          3,
          10,
          8,
          10,
          8,
          1,
          2,
          10,
          8,
          10,
          10,
          1,
          8,
          3,
          10,
          10,
          8,
          10,
          6,
          10,
          2,
          3,
          7,
          8,
          2,
          10,
          10,
          10,
          8,
          10,
          8,
          8,
          8,
          10,
          10,
          10,
          1,
          10,
          2,
          3,
          0,
          10,
          8,
          10,
          8,
          7,
          10,
          10,
          10,
          10,
          3,
          8,
          9,
          8,
          2,
          7,
          10,
          8,
          10,
          8,
          3,
          8,
          8,
          9,
          6,
          10,
          8,
          8,
          10,
          10,
          8,
          8,
          8,
          3,
          8,
          1,
          8,
          1,
          10,
          3,
          2,
          1,
          10,
          10,
          10,
          8,
          8,
          7,
          8,
          10,
          4,
          8,
          10,
          10,
          8,
          8,
          3,
          5,
          8,
          8,
          8,
          7,
          3,
          7,
          10,
          10,
          7,
          5,
          8,
          10,
          8,
          3,
          8,
          10,
          8,
          8,
          2,
          3,
          7,
          10,
          8,
          1,
          10,
          10,
          10,
          5,
          3,
          8,
          10,
          8,
          8,
          4,
          10,
          8,
          8,
          10,
          8,
          3,
          8,
          9,
          7,
          8,
          5,
          3,
          10,
          7,
          10,
          8,
          10,
          10,
          8,
          10,
          10,
          10,
          5,
          10,
          9,
          8,
          8,
          8,
          1,
          5,
          3,
          5,
          10,
          10,
          7,
          10,
          8,
          10,
          7,
          8,
          8,
          1,
          8,
          8,
          10,
          10,
          7,
          10,
          10,
          8,
          3,
          8,
          10,
          3,
          1,
          3,
          8,
          10,
          1,
          8,
          4,
          8,
          10,
          3,
          10,
          10,
          3,
          8,
          3,
          3,
          10,
          2,
          3,
          8,
          10,
          10,
          5,
          10,
          8,
          2,
          7,
          10,
          10,
          8,
          7,
          10,
          10,
          10,
          8,
          10,
          8,
          8,
          8,
          8,
          10,
          10,
          8,
          8,
          7,
          8,
          4,
          8,
          8,
          3,
          10,
          5,
          10,
          7,
          8,
          8,
          3,
          9,
          3,
          3,
          10,
          8,
          8,
          2,
          8,
          8,
          7,
          10,
          8,
          10,
          1,
          3,
          7,
          8,
          1,
          8,
          4,
          10,
          2,
          8,
          10,
          3,
          10,
          10,
          1,
          7,
          10,
          7,
          10,
          10,
          2,
          8,
          8,
          7,
          8,
          10,
          6,
          3,
          10,
          10,
          3,
          10,
          7,
          8,
          10,
          10,
          10,
          10,
          8,
          7,
          10,
          2,
          10,
          10,
          3,
          8,
          10,
          10,
          10,
          10,
          8,
          10,
          8,
          7,
          3,
          10,
          8,
          8,
          3,
          3,
          10,
          8,
          10,
          8,
          8,
          10,
          10,
          8,
          8,
          10,
          10,
          7,
          8,
          1,
          1,
          2,
          8,
          3,
          10,
          8,
          8,
          8,
          1,
          2,
          8,
          8,
          8,
          7,
          8,
          10,
          8,
          8,
          8,
          8,
          7,
          2,
          8,
          8,
          5,
          9,
          10,
          8,
          10,
          8,
          10,
          10,
          1,
          10,
          10,
          10,
          10,
          10,
          8,
          3,
          10,
          2,
          10,
          10,
          10,
          10,
          6,
          8,
          10,
          8,
          3,
          10,
          10,
          8,
          3,
          8,
          8,
          10,
          8,
          8,
          0,
          7,
          1,
          8,
          10,
          3,
          8,
          9,
          7,
          3,
          8,
          4,
          1,
          8,
          10,
          8,
          3,
          10,
          10,
          10,
          3,
          3,
          10,
          2,
          10,
          7,
          10,
          8,
          3,
          2,
          1,
          10,
          10,
          2,
          0,
          3,
          8,
          7,
          8,
          8,
          8,
          10,
          2,
          10,
          8,
          7,
          8,
          10,
          8,
          10,
          3,
          1,
          10,
          10,
          10,
          10,
          8,
          10,
          8,
          7,
          10,
          10,
          7,
          10,
          8,
          10,
          5,
          10,
          7,
          10,
          7,
          8,
          10,
          0,
          8,
          8,
          10,
          10,
          8,
          10,
          3,
          10,
          8,
          8,
          7,
          8,
          3,
          8,
          8,
          8,
          10,
          7,
          8,
          3,
          10,
          2,
          10,
          8,
          8,
          8,
          7,
          5,
          10,
          10,
          10,
          8,
          10,
          8,
          2,
          1,
          8,
          3,
          8,
          2,
          2,
          8,
          10,
          10,
          8,
          7,
          8,
          1,
          10,
          10,
          7,
          8,
          7,
          3,
          10,
          2,
          7,
          1,
          3,
          1,
          10,
          10,
          8,
          1,
          10,
          9,
          10,
          5,
          8,
          10,
          10,
          10,
          10,
          8,
          3,
          8,
          8,
          8,
          8,
          8,
          5,
          10,
          10,
          3,
          10,
          8,
          10,
          8,
          10,
          8,
          10,
          10,
          8,
          10,
          4,
          10,
          3,
          10,
          8,
          10,
          7,
          8,
          10,
          10,
          10,
          8,
          8,
          1,
          7,
          10,
          8,
          5,
          3,
          10,
          2,
          8,
          5,
          8,
          7,
          8,
          8,
          10,
          8,
          8,
          10,
          1,
          10,
          8,
          10,
          10,
          3,
          5,
          3,
          10,
          10,
          9,
          10,
          10,
          8,
          8,
          8,
          7,
          10,
          0,
          10,
          10,
          10,
          8,
          10,
          0,
          10,
          8,
          8,
          7,
          10,
          8,
          8,
          10,
          10,
          10,
          8,
          2,
          10,
          10,
          8,
          10,
          10,
          10,
          10,
          10,
          8,
          10,
          8,
          8,
          2,
          1,
          3,
          8,
          8,
          3,
          8,
          10,
          7,
          8,
          10,
          8,
          8,
          8,
          8,
          10,
          10,
          9,
          2,
          10,
          10,
          8,
          8,
          10,
          10,
          10,
          7,
          1,
          10,
          8,
          8,
          3,
          10,
          10,
          1,
          10,
          7,
          8,
          7,
          10,
          8,
          3,
          10,
          5,
          7,
          10,
          3,
          9,
          10,
          9,
          5,
          6,
          8,
          8,
          8,
          10,
          1,
          8,
          1,
          8,
          10,
          10,
          3,
          8,
          3,
          1,
          10,
          8,
          8,
          2,
          3,
          10,
          10,
          1,
          1,
          5,
          3,
          3,
          8,
          5,
          8,
          3,
          0,
          7,
          2,
          10,
          3,
          10,
          5,
          8,
          8,
          8,
          10,
          8,
          8,
          6,
          8,
          10,
          8,
          10,
          8,
          8,
          3,
          8,
          4,
          10,
          8,
          8,
          8,
          10,
          8,
          3,
          8,
          10,
          3,
          7,
          10,
          3,
          7,
          10,
          10,
          8,
          3,
          10,
          3,
          8,
          4,
          8,
          8,
          8,
          8,
          8,
          2,
          10,
          10,
          10,
          3,
          8,
          8,
          10,
          10,
          1,
          8,
          8,
          8,
          8,
          10,
          8,
          1,
          10,
          10,
          8,
          10,
          5,
          1,
          10,
          10,
          10,
          10,
          10,
          8,
          5,
          2,
          8,
          8,
          8,
          8,
          3,
          10,
          8,
          8,
          8,
          5,
          6,
          10,
          8,
          8,
          8,
          7,
          10,
          5,
          8,
          1,
          8,
          10,
          8,
          3,
          5,
          8,
          2,
          8,
          8,
          8,
          9,
          7,
          10,
          8,
          8,
          7,
          3,
          1,
          8,
          10,
          10,
          8,
          10,
          10,
          8,
          10,
          10,
          3,
          10,
          2,
          2,
          7,
          10,
          2,
          10,
          3,
          8,
          3,
          8,
          1,
          7,
          1,
          8,
          8,
          8,
          3,
          10,
          10,
          10,
          10,
          5,
          1,
          3,
          10,
          8,
          8,
          8,
          10,
          7,
          10,
          8,
          10,
          8,
          10,
          10,
          10,
          5,
          10,
          3,
          10,
          8,
          10,
          2,
          7,
          8,
          7,
          3,
          4,
          8,
          2,
          3,
          0,
          10,
          10,
          8,
          10,
          3,
          2,
          9,
          8,
          10,
          10,
          10,
          10,
          8,
          2,
          10,
          2,
          10,
          5,
          10,
          2,
          9,
          8,
          10,
          8,
          8,
          2,
          10,
          8,
          8,
          10,
          8,
          8,
          3,
          10,
          3,
          1,
          8,
          8,
          8,
          10,
          1,
          10,
          8,
          8,
          8,
          10,
          10,
          8,
          8,
          2,
          10,
          8,
          8,
          10,
          10,
          8,
          6,
          8,
          7,
          2,
          10,
          10,
          3,
          7,
          8,
          3,
          8,
          2,
          7,
          2,
          2,
          8,
          10,
          10,
          8,
          8,
          7,
          9,
          10,
          10,
          10,
          8,
          10,
          8,
          8,
          8,
          8,
          10,
          3,
          8,
          10,
          3,
          8,
          7,
          8,
          10,
          8,
          10,
          5,
          3,
          10,
          7,
          3,
          8,
          8,
          3,
          8,
          10,
          6,
          8,
          4,
          8,
          10,
          10,
          10,
          4,
          10,
          10,
          10,
          0,
          10,
          5,
          10,
          10,
          8,
          2,
          10,
          8,
          7,
          7,
          3,
          10,
          6,
          8,
          10,
          0,
          8,
          3,
          3,
          6,
          2,
          3,
          8,
          5,
          5,
          10,
          8,
          10,
          7,
          8,
          10,
          2,
          10,
          8,
          10,
          8,
          8,
          8,
          8,
          2,
          9,
          10,
          8,
          4,
          8,
          10,
          8,
          8,
          8,
          10,
          8,
          7,
          5,
          10,
          1,
          10,
          10,
          3,
          8,
          8,
          8,
          10,
          3,
          8,
          5,
          8,
          10,
          1,
          10,
          8,
          10,
          10,
          8,
          8,
          4,
          8,
          8,
          10,
          9,
          3,
          8,
          2,
          1,
          10,
          10,
          1,
          8,
          8,
          10,
          2,
          10,
          3,
          8,
          9,
          8,
          10,
          10,
          10,
          8,
          3,
          8,
          8,
          10,
          3,
          10,
          8,
          10,
          3,
          10,
          10,
          10,
          3,
          10,
          8,
          2,
          8,
          1,
          1,
          7,
          4,
          8,
          10,
          10,
          8,
          7,
          10,
          10,
          2,
          3,
          7,
          10,
          3,
          8,
          8,
          10,
          8,
          3,
          8,
          10,
          7,
          1,
          8,
          1,
          8,
          3,
          8,
          10,
          8,
          1,
          8,
          4,
          2,
          8,
          5,
          2,
          7,
          8,
          8,
          5,
          10,
          8,
          10,
          3,
          7,
          10,
          10,
          10,
          8,
          10,
          7,
          8,
          8,
          10,
          8,
          1,
          10,
          1,
          10,
          7,
          3,
          8,
          8,
          8,
          10,
          10,
          7,
          6,
          10,
          10,
          8,
          5,
          8,
          8,
          8,
          8,
          10,
          10,
          7,
          10,
          1,
          8,
          2,
          8,
          8,
          10,
          1,
          10,
          8,
          8,
          10,
          8,
          8,
          7,
          6,
          0,
          8,
          10,
          2,
          6,
          8,
          1,
          2,
          10,
          5,
          10,
          8,
          3,
          10,
          10,
          8,
          7,
          8,
          8,
          3,
          8,
          10,
          10,
          10,
          7,
          10,
          10,
          6,
          10,
          10,
          10,
          2,
          7,
          8,
          6,
          5,
          8,
          8,
          8,
          8,
          3,
          1,
          8,
          8,
          8,
          10,
          10,
          10,
          8,
          3,
          10,
          8,
          8,
          10,
          10,
          10,
          2,
          7,
          2,
          8,
          8,
          7,
          10,
          8,
          10,
          10,
          8,
          2,
          1,
          10,
          10,
          8,
          4,
          8,
          2,
          6,
          8,
          3,
          10,
          5,
          6,
          8,
          8,
          2,
          10,
          8,
          8,
          4,
          10,
          10,
          3,
          3,
          10,
          10,
          7,
          10,
          10,
          3,
          8,
          3,
          7,
          10,
          10,
          3,
          8,
          7,
          10,
          10,
          10,
          7,
          10,
          10,
          10,
          7,
          8,
          8,
          5,
          10,
          10,
          8,
          8,
          10,
          7,
          8,
          8,
          10,
          10,
          7,
          8,
          7,
          8,
          8,
          10,
          8,
          3,
          10,
          3,
          3,
          10,
          10,
          8,
          1,
          10,
          10,
          10,
          10,
          10,
          10,
          3,
          8,
          7,
          8,
          10,
          8,
          4,
          8,
          6,
          10,
          8,
          3,
          1,
          7,
          7,
          2,
          10,
          8,
          1,
          8,
          2,
          3,
          2,
          8,
          1,
          4,
          3,
          8,
          1,
          10,
          8,
          10,
          10,
          7,
          10,
          9,
          5,
          10,
          8,
          8,
          8,
          2,
          8,
          8,
          3,
          10,
          7,
          10,
          1,
          9,
          8,
          10,
          7,
          8,
          10,
          10,
          10,
          8,
          10,
          3,
          8,
          3,
          8,
          8,
          8,
          8,
          8,
          8,
          10,
          6,
          10,
          7,
          1,
          1,
          10,
          3,
          10,
          10,
          2,
          8,
          1,
          7,
          8,
          10,
          10,
          3,
          10,
          5,
          8,
          10,
          8,
          10,
          8,
          10,
          2,
          8,
          8,
          2,
          10,
          8,
          10,
          3,
          10,
          8,
          8,
          8,
          10,
          10,
          10,
          1,
          3,
          3,
          7,
          8,
          8,
          9,
          8,
          8,
          8,
          7,
          10,
          7,
          8,
          10,
          7,
          2,
          3,
          10,
          10,
          8,
          10,
          8,
          10,
          10,
          7,
          10,
          8,
          8,
          8,
          8,
          10,
          10,
          4,
          8,
          10,
          10,
          10,
          3,
          10,
          10,
          10,
          10,
          8,
          1,
          2,
          8,
          8,
          10,
          8,
          1,
          5,
          3,
          7,
          10,
          10,
          10,
          10,
          10,
          8,
          10,
          3,
          10,
          8,
          10,
          8,
          10,
          8,
          8,
          10,
          8,
          8,
          10,
          10,
          8,
          8,
          5,
          8,
          8,
          1,
          8,
          8,
          3,
          10,
          4,
          8,
          7,
          2,
          8,
          7,
          8,
          8,
          6,
          8,
          10,
          10,
          8,
          8,
          10,
          10,
          2,
          8,
          10,
          10,
          10,
          3,
          10,
          10,
          10,
          10,
          10,
          8,
          10,
          10,
          8,
          8,
          8,
          8,
          10,
          8,
          4,
          8,
          10,
          8,
          7,
          5,
          8,
          10,
          8,
          10,
          8,
          5,
          8,
          10,
          3,
          7,
          8,
          10,
          2,
          8,
          7,
          10,
          8,
          8,
          5,
          8,
          8,
          8,
          8,
          7,
          8,
          10,
          10,
          10,
          2,
          3,
          8,
          10,
          3,
          5,
          10,
          6,
          8,
          4,
          8,
          8,
          5,
          8,
          8,
          8,
          3,
          3,
          3,
          8,
          10,
          5,
          10,
          3,
          10,
          8,
          10,
          3,
          10,
          8,
          3,
          8,
          7,
          10,
          5,
          8,
          8,
          8,
          6,
          6,
          8,
          10,
          7,
          3,
          3,
          10,
          8,
          10,
          10,
          3,
          10,
          2,
          10,
          8,
          10,
          10,
          8,
          8,
          8,
          1,
          8,
          3,
          8,
          8,
          8,
          8,
          10,
          8,
          8,
          8,
          3,
          10,
          8,
          8,
          10,
          3,
          7,
          9,
          8,
          7,
          8,
          1,
          8,
          10,
          8,
          10,
          9,
          10,
          4,
          10,
          8,
          8,
          8,
          1,
          10,
          10,
          10,
          7,
          8,
          10,
          1,
          10,
          3,
          3,
          2,
          0,
          7,
          8,
          3,
          10,
          3,
          10,
          10,
          7,
          3,
          10,
          1,
          8,
          8,
          8,
          8,
          8,
          10,
          8,
          10,
          8,
          10,
          8,
          2,
          1,
          7,
          8,
          8,
          1,
          10,
          10,
          3,
          8,
          8,
          8,
          10,
          8,
          8,
          8,
          10,
          10,
          10,
          8,
          4,
          2,
          1,
          8,
          8,
          8,
          10,
          2,
          8,
          8,
          8,
          10,
          10,
          7,
          10,
          8,
          10,
          10,
          2,
          8,
          2,
          1,
          8,
          3,
          0,
          10,
          10,
          3,
          10,
          2,
          10,
          10,
          8,
          8,
          8,
          10,
          1,
          8,
          2,
          3,
          8,
          8,
          8,
          10,
          7,
          3,
          8,
          8,
          8,
          3,
          10,
          10,
          10,
          3,
          7,
          8,
          8,
          10,
          10,
          10,
          10,
          7,
          8,
          8,
          10,
          10,
          10,
          5,
          2,
          8,
          8,
          1,
          10,
          10,
          8,
          10,
          8,
          9,
          3,
          5,
          8,
          10,
          8,
          10,
          7,
          8,
          7,
          8,
          5,
          10,
          10,
          7,
          2,
          8,
          10,
          8,
          10,
          8,
          8,
          8,
          8,
          4,
          3,
          10,
          10,
          1,
          8,
          8,
          8,
          10,
          10,
          3,
          7,
          1,
          2,
          2,
          7,
          10,
          7,
          10,
          7,
          8,
          9,
          10,
          10,
          10,
          8,
          10,
          8,
          10,
          10,
          10,
          8,
          10,
          10,
          8,
          8,
          8,
          10,
          1,
          3,
          7,
          2,
          10,
          7,
          10,
          3,
          7,
          9,
          7,
          10,
          8,
          10,
          4,
          7,
          10,
          8,
          7,
          0,
          10,
          10,
          10,
          10,
          10,
          10,
          7,
          10,
          7,
          7,
          8,
          1,
          10,
          8,
          8,
          8,
          8,
          2,
          7,
          7,
          5,
          7,
          8,
          10,
          10,
          3,
          10,
          3,
          8,
          10,
          3,
          10,
          8,
          8,
          10,
          10,
          4,
          5,
          2,
          10,
          10,
          10,
          8,
          8,
          8,
          3,
          8,
          7,
          7,
          7,
          3,
          8,
          8,
          8,
          10,
          7,
          8,
          10,
          8,
          10,
          8,
          10,
          7,
          7,
          8,
          8,
          7,
          10,
          8,
          3,
          10,
          2,
          8,
          10,
          10,
          8,
          8,
          8,
          8,
          10,
          7,
          7,
          1,
          7,
          1,
          3,
          5,
          9,
          10,
          7,
          8,
          3,
          0,
          4,
          10,
          1,
          3,
          7,
          9,
          8,
          10,
          10,
          8,
          8,
          10,
          10,
          8,
          5,
          8,
          10,
          10,
          10,
          10,
          8,
          10,
          1,
          10,
          10,
          8,
          8,
          10,
          10,
          7,
          2,
          10,
          3,
          10,
          5,
          7,
          3,
          10,
          8,
          8,
          10,
          1,
          10,
          3,
          2,
          3,
          10,
          10,
          8,
          10,
          10,
          3,
          3,
          7,
          10,
          7,
          10,
          10,
          10,
          8,
          10,
          8,
          10,
          8,
          10,
          8,
          3,
          10,
          8,
          8,
          8,
          8,
          10,
          10,
          8,
          10,
          10,
          8,
          10,
          10,
          8,
          8,
          0,
          8,
          10,
          5,
          10,
          2,
          2,
          10,
          8,
          4,
          10,
          5,
          3,
          7,
          7,
          10,
          8,
          8,
          10,
          10,
          10,
          10,
          4,
          3,
          7,
          10,
          8,
          10,
          10,
          10,
          10,
          10,
          10,
          8,
          8,
          3,
          2,
          2,
          8,
          10,
          1,
          10,
          8,
          5,
          10,
          10,
          7,
          10,
          7,
          10,
          10,
          2,
          8,
          3,
          1,
          8,
          3,
          8,
          10,
          1,
          8,
          3,
          1,
          8,
          10,
          10,
          10,
          8,
          10,
          8,
          10,
          6,
          1,
          9,
          10,
          10,
          10,
          2,
          7,
          6,
          10,
          10,
          7,
          7,
          6,
          7,
          9,
          1,
          8,
          8,
          5,
          7,
          4,
          8,
          2,
          8,
          7,
          7,
          8,
          10,
          8,
          10,
          8,
          7,
          10,
          10,
          8,
          8,
          7,
          10,
          10,
          10,
          8,
          8,
          10,
          3,
          10,
          2,
          7,
          8,
          10,
          7,
          10,
          10,
          3,
          8,
          8,
          10,
          3,
          8,
          8,
          2,
          3,
          10,
          3,
          3,
          10,
          10,
          2,
          10,
          8,
          7,
          10,
          10,
          3,
          10,
          10,
          1,
          10,
          10,
          2,
          5,
          10,
          2,
          1,
          9,
          8,
          10,
          7,
          10,
          5,
          8,
          8,
          8,
          8,
          7,
          10,
          10,
          10,
          10,
          8,
          10,
          2,
          10,
          2,
          7,
          10,
          3,
          8,
          10,
          8,
          8,
          10,
          3,
          8,
          7,
          4,
          8,
          8,
          10,
          8,
          7,
          8,
          10,
          10,
          3,
          10,
          8,
          7,
          7,
          10,
          8,
          8,
          10,
          8,
          10,
          10,
          10,
          8,
          3,
          8,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          8,
          8,
          10,
          10,
          1,
          8,
          8,
          10,
          10,
          8,
          8,
          8,
          10,
          3,
          10,
          3,
          10,
          8,
          10,
          4,
          7,
          5,
          8,
          8,
          9,
          8,
          8,
          1,
          5,
          8,
          5,
          10,
          10,
          1,
          5,
          8,
          8,
          1,
          10,
          3,
          10,
          10,
          7,
          10,
          2,
          9,
          10,
          8,
          7,
          8,
          10,
          8,
          7,
          3,
          8,
          8,
          7,
          3,
          8,
          7,
          8,
          1,
          7,
          8,
          10,
          8,
          8,
          9,
          10,
          8,
          10,
          10,
          10,
          10,
          7,
          10,
          8,
          10,
          8,
          10,
          10,
          7,
          10,
          8,
          8,
          10,
          10,
          10,
          10,
          7,
          10,
          1,
          10,
          8,
          3,
          3,
          10,
          8,
          10,
          3,
          8,
          3,
          2,
          3,
          8,
          10,
          1,
          10,
          7,
          8,
          8,
          1,
          10,
          10,
          8,
          7,
          1,
          8,
          4,
          3,
          8,
          8,
          8,
          1,
          5,
          8,
          10,
          10,
          8,
          8,
          1,
          8,
          10,
          8,
          10,
          7,
          10,
          7,
          3,
          10,
          10,
          3,
          10,
          10,
          10,
          3,
          10,
          3,
          7,
          10,
          8,
          10,
          8,
          10,
          3,
          10,
          9,
          8,
          1,
          8,
          1,
          3,
          3,
          10,
          10,
          2,
          8,
          3,
          8,
          10,
          8,
          8,
          8,
          10,
          10,
          1,
          8,
          7,
          10,
          8,
          8,
          3,
          2,
          10,
          5,
          3,
          10,
          8,
          10,
          8,
          7,
          10,
          10,
          10,
          3,
          1,
          6,
          9,
          10,
          3,
          10,
          10,
          10,
          10,
          10,
          2,
          8,
          3,
          8,
          10,
          8,
          10,
          8,
          7,
          8,
          3,
          5,
          3,
          3,
          7,
          7,
          10,
          8,
          8,
          8,
          5,
          1,
          7,
          7,
          7,
          3,
          10,
          8,
          7,
          10,
          1,
          10,
          10,
          3,
          10,
          8,
          10,
          2,
          2,
          8,
          7,
          10,
          1,
          10,
          8,
          8,
          8,
          8,
          8,
          8,
          10,
          10,
          10,
          10,
          10,
          1,
          5,
          1,
          8,
          10,
          7,
          8,
          7,
          8,
          7,
          10,
          3,
          10,
          10,
          10,
          10,
          5,
          8,
          3,
          6,
          5,
          10,
          10,
          8,
          3,
          10,
          8,
          8,
          3,
          9,
          8,
          7,
          10,
          8,
          3,
          8,
          5,
          10,
          8,
          3,
          10,
          10,
          10,
          10,
          10,
          7,
          3,
          8,
          3,
          1,
          7,
          9,
          10,
          1,
          3,
          8,
          10,
          8,
          8,
          8,
          8,
          3,
          3,
          8,
          8,
          8,
          10,
          8,
          10,
          8,
          1,
          2,
          6,
          8,
          8,
          7,
          10,
          2,
          10,
          3,
          6,
          6,
          10,
          3,
          1,
          8,
          10,
          8,
          9,
          3,
          8,
          10,
          5,
          10,
          10,
          8,
          8,
          1,
          8,
          8,
          8,
          2,
          7,
          10,
          10,
          8,
          10,
          8,
          10,
          10,
          8,
          8,
          2,
          8,
          7,
          8,
          10,
          8,
          8,
          8,
          10,
          3,
          10,
          7,
          5,
          8,
          10,
          10,
          2,
          8,
          10,
          7,
          7,
          8,
          10,
          10,
          10,
          10,
          10,
          10,
          8,
          8,
          10,
          2,
          7,
          10,
          7,
          8,
          10,
          10,
          8,
          8,
          10,
          1,
          8,
          8,
          3,
          7,
          10,
          8,
          10,
          8,
          3,
          8,
          10,
          10,
          8,
          8,
          8,
          10,
          10,
          5,
          7,
          8,
          2,
          1,
          8,
          10,
          7,
          8,
          8,
          8,
          7,
          10,
          8,
          2,
          7,
          8,
          8,
          8,
          10,
          10,
          7,
          7,
          9,
          10,
          10,
          8,
          1,
          7,
          10,
          7,
          5,
          8,
          8,
          8,
          2,
          5,
          10,
          8,
          10,
          8,
          2,
          10,
          2,
          3,
          10,
          5,
          10,
          1,
          8,
          8,
          8,
          10,
          3,
          8,
          10,
          2,
          1,
          3,
          3,
          8,
          3,
          8,
          2,
          3,
          10,
          3,
          8,
          8,
          8,
          7,
          10,
          8,
          8,
          10,
          8,
          8,
          8,
          10,
          7,
          10,
          1,
          7,
          8,
          10,
          8,
          1,
          10,
          10,
          8,
          3,
          2,
          2,
          10,
          8,
          5,
          3,
          10,
          10,
          8,
          8,
          7,
          8,
          8,
          10,
          10,
          2,
          1,
          10,
          10,
          2,
          10,
          8,
          8,
          10,
          3,
          8,
          8,
          8,
          1,
          9,
          6,
          10,
          5,
          8,
          10,
          10,
          10,
          1,
          7,
          8,
          5,
          8,
          8,
          8,
          10,
          8,
          10,
          8,
          10,
          8,
          10,
          5,
          8,
          3,
          8,
          10,
          7,
          8,
          3,
          7,
          10,
          8,
          10,
          10,
          8,
          4,
          3,
          10,
          8,
          10,
          9,
          10,
          8,
          10,
          10,
          10,
          10,
          3,
          10,
          1,
          10,
          7,
          8,
          8,
          10,
          5,
          10,
          8,
          8,
          0,
          8,
          10,
          1,
          10,
          10,
          8,
          3,
          1,
          8,
          7,
          10,
          8,
          8,
          8,
          10,
          10,
          8,
          7,
          8,
          6,
          0,
          8,
          8,
          10,
          10,
          2,
          1,
          2,
          8,
          3,
          7,
          10,
          8,
          8,
          8,
          10,
          8,
          8,
          8,
          1,
          10,
          5,
          5,
          7,
          8,
          5,
          10,
          8,
          6,
          10,
          10,
          8,
          8,
          5,
          10,
          2,
          8,
          10,
          8,
          2,
          3,
          5,
          9,
          3,
          8,
          3,
          7,
          3,
          10,
          10,
          8,
          10,
          10,
          3,
          10,
          10,
          10,
          1,
          3,
          10,
          10,
          10,
          10,
          10,
          8,
          8,
          0,
          8,
          10,
          10,
          8,
          10,
          10,
          8,
          2,
          10,
          10,
          8,
          8,
          7,
          2,
          5,
          8,
          2,
          3,
          8,
          5,
          8,
          8,
          1,
          8,
          8,
          8,
          8,
          8,
          9,
          10,
          8,
          8,
          8,
          10,
          10,
          1,
          8,
          10,
          10,
          10,
          3,
          10,
          8,
          10,
          1,
          10,
          10,
          5,
          8,
          10,
          7,
          8,
          7,
          10,
          10,
          7,
          8,
          3,
          8,
          9,
          2,
          10,
          10,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          3,
          8,
          7,
          2,
          8,
          2,
          10,
          7,
          0,
          1,
          1,
          3,
          8,
          10,
          5,
          10,
          3,
          10,
          7,
          10,
          2,
          8,
          7,
          10,
          8,
          8,
          10,
          7,
          0,
          10,
          8,
          3,
          6,
          0,
          1,
          8,
          8,
          10,
          8,
          7,
          8,
          8,
          6,
          10,
          10,
          1,
          8,
          8,
          3,
          3,
          8,
          8,
          8,
          10,
          8,
          8,
          10,
          5,
          7,
          10,
          8,
          8,
          1,
          10,
          10,
          7,
          8,
          10,
          1,
          10,
          8,
          10,
          10,
          2,
          10,
          2,
          8,
          3,
          1,
          3,
          8,
          10,
          8,
          7,
          7,
          10,
          8,
          8,
          2,
          1,
          10,
          7,
          10,
          8,
          1,
          8,
          8,
          7,
          8,
          10,
          10,
          10,
          8,
          10,
          3,
          0,
          10,
          8,
          10,
          9,
          4,
          8,
          8,
          10,
          8,
          8,
          3,
          10,
          6,
          10,
          10,
          10,
          10,
          10,
          8,
          10,
          1,
          3,
          1,
          10,
          8,
          10,
          1,
          10,
          8,
          10,
          3,
          8,
          3,
          10,
          5,
          8,
          10,
          10,
          8,
          2,
          1,
          10,
          10,
          10,
          8,
          7,
          10,
          2,
          7,
          8,
          10,
          10,
          10,
          8,
          8,
          10,
          10,
          8,
          10,
          10,
          10,
          7,
          5,
          10,
          10,
          10,
          3,
          8,
          10,
          10,
          10,
          8,
          3,
          2,
          6,
          9,
          10,
          10,
          1,
          3,
          8,
          10,
          10,
          0,
          3,
          10,
          3,
          8,
          2,
          2,
          1,
          1,
          8,
          7,
          8,
          2,
          1,
          7,
          7,
          3,
          2,
          3,
          7,
          10,
          8,
          10,
          10,
          8,
          6,
          10,
          8,
          10,
          8,
          10,
          1,
          8,
          8,
          10,
          8,
          8,
          10,
          6,
          3,
          3,
          7,
          5,
          1,
          8,
          8,
          7,
          8,
          1,
          8,
          3,
          8,
          7,
          7,
          7,
          8,
          0,
          2,
          8,
          8,
          10,
          9,
          3,
          10,
          7,
          4,
          10,
          10,
          8,
          7,
          8,
          5,
          10,
          8,
          8,
          8,
          7,
          10,
          1,
          8,
          8,
          10,
          10,
          3,
          8,
          3,
          8,
          8,
          8,
          8,
          8,
          8,
          10,
          5,
          3,
          6,
          8,
          10,
          10,
          8,
          8,
          10,
          10,
          3,
          8,
          1,
          7,
          10,
          10,
          10,
          10,
          8,
          1,
          10,
          8,
          8,
          10,
          10,
          8,
          8,
          8,
          10,
          3,
          10,
          3,
          8,
          0,
          7,
          10,
          7,
          10,
          8,
          7,
          8,
          8,
          1,
          10,
          8,
          8,
          8,
          2,
          10,
          7,
          9,
          8,
          10,
          10,
          10,
          8,
          8,
          8,
          3,
          8,
          8,
          3,
          8,
          8,
          1,
          8,
          10,
          8,
          8,
          7,
          8,
          10,
          9,
          10,
          10,
          10,
          8,
          10,
          6,
          8,
          10,
          10,
          10,
          8,
          1,
          8,
          8,
          7,
          8,
          1,
          10,
          2,
          7,
          3,
          7,
          8,
          8,
          10,
          10,
          8,
          8,
          8,
          3,
          10,
          10,
          8,
          2,
          7,
          10,
          9,
          5,
          3,
          10,
          8,
          3,
          8,
          8,
          10,
          2,
          3,
          10,
          8,
          10,
          10,
          6,
          8,
          2,
          8,
          10,
          3,
          1,
          8,
          8,
          10,
          2,
          10,
          8,
          8,
          10,
          8,
          2,
          10,
          9,
          10,
          8,
          8,
          10,
          3,
          10,
          10,
          1,
          10,
          7,
          1,
          8,
          3,
          3,
          8,
          8,
          10,
          5,
          8,
          8,
          10,
          8,
          10,
          1,
          7,
          10,
          2,
          10,
          10,
          8,
          2,
          8,
          1,
          10,
          8,
          8,
          8,
          1,
          7,
          1,
          3,
          1,
          8,
          9,
          10,
          8,
          8,
          3,
          8,
          10,
          10,
          8,
          10,
          10,
          8,
          10,
          3,
          10,
          10,
          10,
          7,
          8,
          8,
          8,
          10,
          8,
          8,
          10,
          8,
          1,
          8,
          10,
          8,
          8,
          10,
          3,
          10,
          8,
          10,
          8,
          8,
          8,
          3,
          3,
          10,
          3,
          8,
          8,
          8,
          8,
          10,
          7,
          7,
          3,
          3,
          1,
          2,
          8,
          8,
          10,
          2,
          2,
          8,
          10,
          10,
          2,
          8,
          3,
          8,
          10,
          10,
          7,
          8,
          8,
          6,
          8,
          8,
          7,
          10,
          10,
          10,
          1,
          10,
          7,
          10,
          1,
          8,
          10,
          10,
          7,
          7,
          8,
          10,
          8,
          10,
          8,
          10,
          1,
          10,
          7,
          8,
          3,
          10,
          0,
          3,
          8,
          10,
          8,
          8,
          7,
          8,
          8,
          8,
          10,
          8,
          7,
          8,
          10,
          10,
          5,
          10,
          10,
          3
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "font": {
         "family": "Franklin Gothic",
         "size": 12
        },
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Prediction Distribution"
        },
        "uniformtext": {
         "minsize": 15,
         "mode": "hide"
        },
        "width": 700
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure(layout=plotly_template['layout'])\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=test_df[Config.target],\n",
    "        name=f'Prediction',\n",
    "        histnorm='probability',\n",
    "        marker=dict(color=color_palette['Bin'][0]),\n",
    "        #line=dict(color='black')\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_train[Config.target],\n",
    "        name=f'Train',\n",
    "        histnorm='probability',\n",
    "        marker=dict(color=color_palette['Bin'][1]),\n",
    "        opacity=0.5\n",
    "        #line=dict(color='black')\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Prediction Distribution',\n",
    "    barmode='overlay',\n",
    "    uniformtext_minsize=15,\n",
    "    uniformtext_mode='hide',\n",
    "    width=700)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(Config.submission_dir + f'nb{Config.NB}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証メモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[features].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc8a78a13283e3ba74119858067a74c2c7a55702e09c935fdd8fe4b244251524"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
